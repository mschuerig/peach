---
commit: "0a893291999b1242768426ca64a4e73cc0be4181"
date: "2026-02-12T13:21:06+01:00"
author: "Michael Sch√ºrig <michael@schuerig.de>"
subject: "Add UX design specification and update planning artifacts"
sessions: ["7ac4d6e9-97b7-46cb-b566-a9fab3420a45"]
prev: "a14387c1ee.md"
next: "7bb2a2e9e8.md"
---

[‚Üê Previous (a14387c1ee)](a14387c1ee.md) | [Index](index.md) | [Next (7bb2a2e9e8) ‚Üí](7bb2a2e9e8.md)

# Commit 0a89329199

**Date:** 2026-02-12 13:21:06 UTC+01:00  
**Author:** Michael Sch√ºrig <michael@schuerig.de>

## Commit message

Add UX design specification and update planning artifacts

Create comprehensive UX design spec covering experience principles
(disappearing UI, ears > fingers > eyes), emotional design (silence as
feedback, no opinions), comparison loop mechanics with timing diagram,
hub-and-spoke navigation model, stock SwiftUI/HIG-only design system,
component specs for profile visualization, and accessibility strategy.

Update PRD, glossary, and architecture to reflect design decisions:
remove Stop Button in favor of navigation-as-stop, add Info Screen,
add Settings/Profile buttons to Training Screen, add app backgrounding
behavior, and replace test-anxiety framing with practical critique of
score-driven design and slow round-trips.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>

## Changed files

```
docs/planning-artifacts/architecture.md            | 454 ++++++++++
 docs/planning-artifacts/glossary.md                |   8 +-
 docs/planning-artifacts/prd.md                     |  23 +-
 docs/planning-artifacts/ux-design-specification.md | 976 +++++++++++++++++++++
 4 files changed, 1450 insertions(+), 11 deletions(-)
```

## Session `7ac4d6e9‚Ä¶`

*2026-02-12 10:59:10 UTC ‚Üí 2026-02-12 12:21:14 UTC*

### üßë Human (10:59:10)

<command-message>bmad-bmm-create-ux-design</command-message>
<command-name>/bmad-bmm-create-ux-design</command-name>

### ü§ñ Assistant (10:59:18)

Let me initialize the UX design workflow. First, I'll check for an existing document and discover input documents.

### ü§ñ Assistant (10:59:23)

No existing UX design specification found ‚Äî this is a fresh workflow. Let me check for any sharded document folders as well.

### ü§ñ Assistant (10:59:29)

Good ‚Äî no sharded folders found. Here's what I discovered:

**Input Documents Found:**

- **PRD:** `docs/planning-artifacts/prd.md`
- **Glossary:** `docs/planning-artifacts/glossary.md`
- **Architecture:** `docs/planning-artifacts/architecture.md`
- **Brainstorming:** `docs/brainstorming/brainstorming-session-2026-02-11.md`
- **Product Brief:** None found
- **Project Context:** None found

Michael, before I proceed to load these and set up the workspace, I want to confirm:

1. Should I load all 4 documents listed above as context for the UX design process?
2. Do you have any other documents you'd like me to include?

### ü§ñ Assistant (10:59:45)

All documents loaded. Now let me create the initial UX design specification document from the template.

### ü§ñ Assistant (11:00:03)

Welcome Michael! I've set up your UX design workspace for Peach.

**Document Setup:**
- Created: `docs/planning-artifacts/ux-design-specification.md` from template
- Initialized frontmatter with workflow state

**Documents Found:**
- PRD: 1 (`prd.md`)
- Product brief: None found
- Brainstorming: 1 (`brainstorming-session-2026-02-11.md`)
- Other context: 2 (`glossary.md`, `architecture.md`)

**Files loaded:** `prd.md`, `glossary.md`, `architecture.md`, `brainstorming-session-2026-02-11.md`

I have rich context on Peach ‚Äî the pitch discrimination ear training app with its "training, not testing" philosophy, 4 screens (Start, Training, Profile, Settings), adaptive algorithm, and the overall architecture. This gives us a strong foundation for UX design decisions.

Do you have any other documents you'd like me to include, or shall we continue to the next step?

**[C]** Continue to UX discovery

### üßë Human (11:00:35)

c

### ü§ñ Assistant (11:01:15)

Based on the project documentation we've loaded, let me confirm what I'm understanding about Peach from a UX perspective.

**From the documents:**

Peach is a pitch discrimination ear training app for iOS. Its core philosophy ‚Äî "training, not testing" ‚Äî is the defining UX principle. Where existing apps like InTune escalate difficulty until failure and show a score, Peach builds a perceptual profile and relentlessly targets weak spots. No scores, no gamification, no sessions. Every comparison makes the user better; no single answer matters.

The interaction is radically simple: two notes play in sequence, user taps higher or lower. The intelligence lives entirely in the algorithm, not the UI. The app is designed for incidental use ‚Äî 30 seconds on the bus, a minute during a practice break.

**Target Users:**

Musicians (singers, string, woodwind, brass players) for whom intonation is a practical challenge. The primary persona is a working musician like Sarah the cellist, who wants to sharpen pitch perception without test anxiety. Users are musically sophisticated but not necessarily tech-savvy ‚Äî they want to train, not configure.

**Key Features/Goals:**

- 4 screens: Start, Training, Profile, Settings ‚Äî deliberately minimal
- Zero-friction onboarding (no account, no tutorial, tap and go)
- One-handed, imprecise-tap-friendly training loop
- Perceptual profile visualization (piano keyboard + confidence band)
- Summary statistics with trend (mean/std dev of detection thresholds)
- Adaptive algorithm with "Natural vs. Mechanical" slider
- Entirely on-device, iPhone + iPad, English + German

Does this match your understanding? Let me also surface the key UX challenges and opportunities I'm seeing:

**Design Challenges:**

1. **The "invisible intelligence" problem** ‚Äî The algorithm is the product's core value, but users can't see it working. The UX must make the adaptive behavior *feel* right without exposing its mechanics. If comparisons feel random, users won't sense progress; if they feel too patterned, it becomes boring.

2. **Sparse-data visualization** ‚Äî On day one, the perceptual profile has almost no data. The Profile Screen and Profile Preview must look meaningful and inviting even when mostly empty, without misleading the user about what the data represents.

3. **Designing for "no session" training** ‚Äî Most app UX patterns assume sessions with clear beginnings, endings, and summaries. Peach has none of that. The start/stop experience must feel natural without the conventional session framing that users expect.

4. **One-handed reflexive interaction** ‚Äî The Training Screen must support rapid, imprecise tapping while the user is standing on a bus or holding a cello. Button placement, sizing, and feedback timing are critical ‚Äî milliseconds matter for the "instinctive reflex" feel.

**Design Opportunities:**

1. **The anti-gamification advantage** ‚Äî By rejecting scores and streaks, Peach can create a calm, pressure-free aesthetic that feels fundamentally different from every other training app. This is a UX differentiator, not just a missing feature.

2. **The profile as motivation** ‚Äî The perceptual profile visualization can be the app's emotional hook. Watching the confidence band tighten over weeks is inherently satisfying without needing badges or points. The visualization *is* the reward.

3. **Liquid Glass & iOS 26 design language** ‚Äî As a greenfield iOS 26 app with no legacy, Peach can fully embrace Apple's latest design language from day one, creating a polished, native feel that's rare in music training apps.

---

**Here's what I'll add to the document:**

```markdown
## Executive Summary

### Project Vision

Peach is a pitch discrimination ear training app for iOS built on the philosophy of "training, not testing." Where existing apps like InTune escalate difficulty until failure to produce a score, Peach builds a perceptual profile of the user's hearing and relentlessly targets weak spots. No scores, no gamification, no sessions. Every comparison makes the user better; no single answer matters.

The interaction is radically simple: two notes play in sequence, the user taps higher or lower. The intelligence lives entirely in the adaptive algorithm, not the UI. The app is designed for incidental use ‚Äî 30 seconds on the bus, a minute during a practice break ‚Äî with zero friction between wanting to train and training.

### Target Users

Musicians (singers, string, woodwind, brass players) for whom intonation is a practical challenge. These users are musically sophisticated but not necessarily tech-savvy. They want a tool that fits into the cracks of their day ‚Äî practice breaks, commuting, waiting ‚Äî and makes them measurably better without demanding attention or emotional investment.

Primary persona: a working musician who knows their intonation needs work, has tried test-based apps and found them anxiety-inducing or demotivating, and wants training that feels like a reflex exercise rather than an exam.

### Key Design Challenges

1. **Invisible intelligence** ‚Äî The adaptive algorithm is the product's core value, but users can't see it working. The UX must make the adaptive behavior feel right ‚Äî not random, not mechanical ‚Äî without exposing its inner mechanics.

2. **Sparse-data visualization** ‚Äî On first use, the perceptual profile has almost no data. The Profile Screen and Profile Preview must look meaningful and inviting even when mostly empty, without misleading users about what sparse data represents.

3. **No-session training model** ‚Äî Most app UX patterns assume sessions with clear beginnings, endings, and summaries. Peach has none of that. Start and stop must feel natural without conventional session framing.

4. **One-handed reflexive interaction** ‚Äî The Training Screen must support rapid, imprecise tapping in mobile contexts (bus, standing, holding an instrument). Button placement, sizing, and feedback timing are critical for the "instinctive reflex" feel.

### Design Opportunities

1. **Anti-gamification as differentiator** ‚Äî By rejecting scores and streaks, Peach can create a calm, pressure-free aesthetic that feels fundamentally different from every other training app. This absence is a UX feature, not a missing feature.

2. **The profile as intrinsic motivation** ‚Äî The perceptual profile visualization can be the app's emotional hook. Watching the confidence band tighten over weeks is inherently satisfying without needing badges or points. The data itself is the reward.

3. **Native iOS 26 design language** ‚Äî As a greenfield app targeting iOS 26 exclusively, Peach can fully embrace Apple's latest Liquid Glass design language from day one, creating a polished, modern feel that's rare in music training apps.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî dig deeper into any of these areas
- **[P]** Party Mode ‚Äî bring multiple perspectives to challenge or enrich this understanding
- **[C]** Continue ‚Äî Save this to the document and move to core experience definition

### üßë Human (11:02:11)

c

### ü§ñ Assistant (11:02:28)

Content saved. Now loading the next step.

### ü§ñ Assistant (11:02:41)

Now let's dig into the heart of the user experience for Peach. I have strong context from the PRD and brainstorming, but I want to make sure I'm capturing your vision accurately.

**Core Experience Questions:**

From the documents, I'm reading the core action as: **the rapid-fire higher/lower comparison loop** ‚Äî two notes, one tap, next pair. The algorithm does the thinking; the user just reacts.

But let me check my understanding with you:

1. **What's the ONE thing that must feel perfect?** I'm assuming it's the rhythm of the training loop ‚Äî the cadence of notes playing and the user responding should feel almost musical in itself. Is that right, or is there something else?

2. **Where do current solutions frustrate you most?** You've mentioned InTune's test-anxiety feel. Is there anything else about existing pitch training tools that grates ‚Äî the UI, the flow, the feedback style?

3. **What would "nailed it" feel like?** When you imagine using Peach on a practice break and it's working exactly right ‚Äî what does that moment feel like? What are you *not* thinking about?

4. **What should happen completely automatically?** I'm assuming: algorithm adaptation, profile updates, session continuity, difficulty adjustment. Anything else the user should never have to think about?

### üßë Human (11:03:48)

I have nothing to add.

### ü§ñ Assistant (11:04:26)

Good ‚Äî the documents are rich enough to work from. Let me synthesize the core experience definition.

Based on everything from the PRD, brainstorming, and architecture docs, here are the core experience principles I'm extracting for Peach:

**Here's what I'll add to the document:**

```markdown
## Core User Experience

### Defining Experience

The core experience is the **comparison loop**: two notes play in sequence, the user taps higher or lower, feedback flashes, the next pair begins. This loop is the entire product. Everything else ‚Äî the profile, the settings, the Start Screen ‚Äî exists to support or reflect it.

The loop must feel **reflexive, not deliberative**. The user should be reacting to sounds, not thinking about an app. The ideal state is flow ‚Äî a rhythmic back-and-forth between listening and tapping where the app disappears and only the sounds and responses remain. If the user is ever thinking about the UI during training, the design has failed.

### Platform Strategy

- **Native iOS (Swift/SwiftUI, iOS 26+)** ‚Äî single-platform, no cross-platform considerations
- **iPhone primary, iPad supported** ‚Äî designed for the phone in your hand, scales up gracefully
- **Portrait primary, landscape supported** ‚Äî one-handed portrait use is the default context
- **Entirely offline** ‚Äî no network dependency, no loading states, no connectivity concerns
- **Audio output required** ‚Äî speaker or headphones; no microphone, no camera, no permissions dialogs
- **Haptic engine** ‚Äî wrong-answer feedback channel that works even when the user isn't looking at the screen
- **Liquid Glass design language** ‚Äî fully embrace iOS 26 aesthetics as a greenfield app

### Effortless Interactions

1. **Start training** ‚Äî one tap from app launch to hearing the first note. No onboarding, no account, no "welcome back," no session naming. The Start Training Button is the app.

2. **Stop training** ‚Äî one tap, immediate, no confirmation dialog, no session summary, no "are you sure?" The incomplete comparison is silently discarded. The user just puts their phone away.

3. **Answer a comparison** ‚Äî large, thumb-friendly buttons that don't require visual precision. Disabled during the first note (preventing premature answers), enabled the moment the second note begins playing. The transition from listening to answering must be seamless.

4. **Resume where you left off** ‚Äî there is no resume. There are no sessions. The user opens the app and starts training; the algorithm already knows their profile. Whether it's been 5 minutes or 5 weeks, the experience is identical.

5. **See progress** ‚Äî the Profile Preview on the Start Screen provides a glanceable snapshot without navigating anywhere. Tapping it opens the full profile. No digging through menus.

### Critical Success Moments

1. **First 10 seconds** ‚Äî The user taps Start Training and is immediately in a rhythm of listening and tapping. If this moment feels clunky, slow, or confusing, the app has lost. This is the moment where "training, not testing" must be felt, not explained.

2. **First wrong answer** ‚Äî A subtle haptic buzz and a thumbs-down that doesn't linger. The next comparison is already coming. The user learns that wrong answers don't matter ‚Äî they're just data. This moment establishes the emotional safety of the app.

3. **First profile check** ‚Äî The user opens the Profile Screen after a few days and sees their perceptual landscape taking shape. Even with limited data, it should feel like looking at something real and personal ‚Äî a map of their hearing, not a score sheet.

4. **The "it's working" realization** ‚Äî After weeks of incidental training, the user sees their mean detection threshold dropping. This isn't a celebration screen ‚Äî it's a quiet, factual confirmation that their perception is sharpening. The data speaks for itself.

5. **Mid-interruption stop** ‚Äî The user's bus stop comes. They tap stop mid-comparison and put their phone away in one motion. Zero friction, zero guilt, zero lost data. The app respects their time completely.

### Experience Principles

1. **Disappearing UI** ‚Äî The best training session is one where the user forgets they're using an app. Every design decision should reduce the distance between the user and the sounds. Controls, transitions, and feedback should be felt, not studied.

2. **Every answer improves you** ‚Äî No answer is wasted, no answer is punished. Wrong answers are information, not failure. The UX must never make the user feel judged ‚Äî no scores, no streaks, no "try again" language, no summary screens that highlight mistakes.

3. **Respect incidental time** ‚Äî The app is designed for the cracks in a musician's day. This means instant start, instant stop, no warm-up, no wind-down, no session overhead. 30 seconds of training is as valid as 30 minutes.

4. **Show, don't score** ‚Äî Progress is a perceptual profile that the user can see evolving, not a number going up. The visualization is factual and personal ‚Äî it shows what the user can hear, not how they rank.

5. **Sound first, pixels second** ‚Äî Audio quality, timing, and envelope shaping take absolute priority over visual polish. A beautiful screen with clicking audio artifacts is a failed product. A plain screen with pristine sound is a working one.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the core experience definition
- **[P]** Party Mode ‚Äî bring different perspectives on the user experience
- **[C]** Continue ‚Äî Save this to the document and move to emotional response definition

### üßë Human (11:04:49)

c

### ü§ñ Assistant (11:05:32)

Content saved. Loading the next step.

### ü§ñ Assistant (11:05:43)

Now let's think about how Peach should make users feel. The PRD and brainstorming gave strong emotional signals ‚Äî let me check my reading with you.

**Emotional Response Questions:**

From everything I've absorbed, the emotional core of Peach seems to be **calm competence** ‚Äî the feeling of sharpening a skill without pressure. But I want to validate:

1. **What should training *feel* like?** My read is: meditative and rhythmic ‚Äî closer to the feeling of warming up with scales than taking an exam. The sound-tap-sound-tap cadence should be almost soothing. Is that right, or do you want more energy/intensity?

2. **What about wrong answers?** The PRD says "no single answer matters," but emotionally ‚Äî should a wrong answer feel like *nothing*, or should there be a tiny productive sting (the haptic) that sharpens attention without creating anxiety?

3. **What would make you tell a fellow musician about this?** What's the feeling that would prompt you to say "you should try this app"?

### üßë Human (11:05:58)

BTW, the reason for the haptic feedback is that I'd like to be able to use the app with eyes closed.

### ü§ñ Assistant (11:06:06)

That's a significant insight ‚Äî eyes-closed training changes the design equation. The haptic isn't emotional weight, it's a **functional feedback channel for non-visual use**. This means the Training Screen needs to work as a purely audio-haptic experience where the visual layer is optional, not primary.

This reinforces the "disappearing UI" principle ‚Äî the UI literally disappears when your eyes are closed, and the app still works. Sound tells you what to listen to, thumb position tells you where to tap, haptic tells you the result.

Let me factor this in and anything else you want to add ‚Äî or should I synthesize the emotional response section now based on everything we have?

### üßë Human (11:06:50)

Go ahead.

### ü§ñ Assistant (11:07:27)

**Here's what I'll add to the document:**

```markdown
## Desired Emotional Response

### Primary Emotional Goals

1. **Calm focus** ‚Äî Training should feel meditative, not competitive. The rhythmic cadence of sound-tap-sound-tap creates a flow state closer to warming up with scales than taking a test. The user's mind is on the sounds, not on performance.

2. **Quiet confidence** ‚Äî Over time, the user develops a sense that their hearing is sharpening. This isn't announced or celebrated ‚Äî it's a growing inner certainty, confirmed when they check the profile and see the data matching what they've started to feel.

3. **Freedom from judgment** ‚Äî No answer carries weight. The user should feel the same emotional neutrality toward a wrong answer as toward a correct one. Both are just moments in a continuous flow. The app never evaluates the user ‚Äî it trains them.

### Emotional Journey Mapping

| Moment | Desired Feeling | Anti-Pattern to Avoid |
|---|---|---|
| **First launch** | Curiosity, ease ‚Äî "that's it?" | Overwhelm, obligation, setup fatigue |
| **First comparisons** | Playful alertness ‚Äî like a reflex game | Test anxiety, self-consciousness |
| **First wrong answer** | Nothing ‚Äî just a haptic tick and the next pair | Shame, frustration, "try again" pressure |
| **Stopping mid-session** | Neutral ‚Äî like putting down a cup of coffee | Guilt, loss aversion, "are you sure?" friction |
| **Checking the profile** | Honest curiosity ‚Äî "what does my hearing look like?" | Score anxiety, social comparison |
| **Seeing improvement** | Quiet satisfaction ‚Äî the data speaks for itself | Artificial celebration, badges, confetti |
| **Returning after a break** | Seamless continuity ‚Äî as if no time passed | Guilt trips, streak resets, "welcome back" banners |
| **Getting more wrong after a break** | Acceptance ‚Äî the algorithm adapts, no announcement | Decline warnings, skill degradation messages |

### Micro-Emotions

**Cultivate:**
- **Trust** ‚Äî the algorithm is working for you, even when you can't see how. Comparisons feel purposeful, not random.
- **Competence** ‚Äî the interaction is so simple that the user feels immediately capable. No learning curve, no confusion.
- **Ownership** ‚Äî the perceptual profile is *yours*. It's a personal map of your hearing, not a score assigned by the app.
- **Presence** ‚Äî during training, the user is fully in the moment with the sounds. Eyes can be closed. The world narrows to two notes and a thumb.

**Prevent:**
- **Anxiety** ‚Äî no time pressure, no scores, no failure states, no "you got worse" messages.
- **Guilt** ‚Äî no streaks, no missed-day tracking, no engagement mechanics that punish absence.
- **Boredom** ‚Äî the algorithm keeps comparisons at the edge of perception. Too easy is as bad as too hard.
- **Distrust** ‚Äî if comparisons feel random or pointless, the user loses faith. The "Natural vs. Mechanical" slider gives the user a sense of agency over the algorithm's behavior.

### Design Implications

| Emotional Goal | UX Design Approach |
|---|---|
| Calm focus | Minimal Training Screen ‚Äî no stats, no counters, no progress bars during training. Just the sounds, the buttons, and the feedback. |
| Freedom from judgment | Feedback Indicator (thumbs up/down) is brief and non-emphatic. Same visual weight for correct and incorrect. No cumulative score visible anywhere during training. |
| Eyes-closed training | Haptic feedback is a primary output channel, not a secondary one. Correct answer: no haptic (silence = confirmation). Wrong answer: single haptic tick. The Training Screen must function as a purely audio-haptic experience where visuals are optional. |
| Quiet confidence | Profile visualization uses calm, factual presentation. No celebratory animations. Trend indicators are understated ‚Äî a gentle directional signal, not a scoreboard. |
| Seamless continuity | No session boundaries means no session UI. No timers, no "session complete" screens, no "X comparisons today" counters. The app has no concept of today vs. yesterday. |
| Trust in the algorithm | The "Natural vs. Mechanical" slider gives users a tangible control that affects how training feels, building trust that the algorithm is responsive to their preferences. |

### Emotional Design Principles

1. **Silence is feedback** ‚Äî The absence of reaction is itself a response. No haptic after a correct answer means "yes, move on." No session summary means "your data is safe, nothing to review." No welcome-back screen means "nothing changed, pick up where you left off." Design with silence as deliberately as with sound.

2. **The app has no opinion about you** ‚Äî Peach never judges, congratulates, encourages, or admonishes. It plays sounds, records answers, and shows data. The emotional interpretation belongs entirely to the user. This neutrality is the core emotional contract.

3. **Sensory hierarchy: ears > fingers > eyes** ‚Äî Audio is primary (the training content), haptic is secondary (the result feedback), visual is tertiary (optional confirmation). The app must be fully functional with eyes closed. Design decisions that privilege visual feedback over audio-haptic feedback violate this hierarchy.

4. **Boredom is a bug** ‚Äî If the user feels bored, the algorithm is failing ‚Äî comparisons are too easy or too predictable. The emotional antidote to boredom is the constant edge-of-perception challenge, not gamification or visual novelty.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the emotional response definition
- **[P]** Party Mode ‚Äî bring different perspectives on user emotional needs
- **[C]** Continue ‚Äî Save this to the document and move to inspiration analysis

### üßë Human (11:08:02)

c

### ü§ñ Assistant (11:08:44)

Content saved. Loading the next step.

### ü§ñ Assistant (11:08:53)

Let's learn from products that resonate with the kind of experience we're designing for Peach.

**Inspiration Questions:**

1. **Are there apps you already love using** ‚Äî in music, training, or even completely unrelated ‚Äî where the UX just *feels right*? Apps where the interaction is so smooth you barely notice the interface?

2. **What about InTune specifically** ‚Äî beyond the test-anxiety problem, is there anything about its UX (interaction patterns, visuals, navigation) that works well and is worth learning from?

3. **Any non-app inspirations?** Sometimes the best UX references come from physical objects or experiences ‚Äî a metronome, a tuning fork, the feel of a well-designed instrument case. Anything like that inform how Peach should feel?

### üßë Human (11:13:20)

On InTune specifically: "test-anxiety" is a completely overblown way to call it. In my opinion, trying to determine a score gets in the way of training. It is not an emotional issue, but a practical one. Also, the round trip between comparisons (in our terminology) take much too long in InTune for my taste. If I have to wait several seconds for the next comparison, I get impatient and distracted from the task.

### ü§ñ Assistant (11:13:32)

Thank you for the correction ‚Äî that's an important distinction. The problem with InTune's scoring isn't that it creates anxiety, it's that **scoring is a different goal than training**, and pursuing it compromises the training loop. It's a design philosophy mismatch, not an emotional one. And the slow round-trip is a concrete throughput problem ‚Äî dead time between comparisons is wasted time where the user's attention drifts.

This sharpens two things for Peach:

1. **Comparison throughput is a UX requirement**, not just a performance metric. The time between answering one comparison and hearing the next note must be effectively zero.
2. **The absence of scoring is a practical choice** ‚Äî it removes a mechanism that interferes with the training purpose, not one that makes users feel bad.

I'll make sure the inspiration analysis reflects this precision. Any apps or experiences you want me to consider as positive references, or should I synthesize based on what we have?

### üßë Human (11:14:40)

Be sure to adapt any old documents as needed.

### ü§ñ Assistant (11:14:48)

Noted ‚Äî let me first fix the language in the existing document sections, then generate the inspiration analysis.

### ü§ñ Assistant (11:14:52)

I see several places that need correction. Let me fix them ‚Äî removing the "anxiety" framing and replacing it with the practical reasoning.

### ü§ñ Assistant (11:15:16)

Now let me also check the PRD for the same framing issue.

### ü§ñ Assistant (11:16:08)

Good ‚Äî all "anxiety" framing removed across all documents. The language now consistently reflects the practical issue: scoring gets in the way of training, and slow round-trips waste attention.

Now let me synthesize the inspiration analysis. You haven't named specific apps beyond InTune, so I'll work with what we know and frame the analysis around the UX patterns themselves.

**Here's what I'll add to the document:**

```markdown
## UX Pattern Analysis & Inspiration

### Inspiring Products Analysis

**InTune (Negative Reference)**

InTune is the primary reference point ‚Äî as a model of what *not* to do. Two concrete problems inform Peach's design:

1. **Scoring as purpose:** InTune treats each interaction as a test item contributing to a score. This is a fundamental goal mismatch ‚Äî scoring and training are different activities. When the app's purpose is to produce a score, the comparison selection optimizes for measurement accuracy, not for training effectiveness. Peach eliminates scoring entirely so that every comparison can be selected purely for its training value.

2. **Slow comparison round-trips:** InTune introduces multi-second delays between comparisons ‚Äî transition animations, result displays, difficulty adjustments visible to the user. This kills training throughput and causes the user's attention to drift. In the time InTune completes one comparison cycle, Peach should complete three or four.

**Metronome Apps (Positive Pattern)**

The best metronome apps (e.g., Pro Metronome, Tempo) share a key UX pattern with Peach: the core interaction is purely temporal and auditory. Tap to start, listen, tap to stop. No session framing, no results. The UI exists only to configure the experience, not to mediate it. This "configure then disappear" pattern is directly transferable.

**Meditation / Breathing Apps (Emotional Pattern)**

Apps like Apple's Mindfulness (Breathe) demonstrate that a calm, minimal interface can frame repetitive interaction as beneficial rather than tedious. The key lesson: visual restraint communicates that the *experience itself* is the point, not the screen content. Peach's Training Screen should have this quality ‚Äî a screen that says "listen" by showing almost nothing.

### Transferable UX Patterns

**Interaction Patterns:**

- **Zero-delay looping** (from rhythm games) ‚Äî the next event begins the instant the previous one resolves. No transition screens, no result pauses. The loop is continuous until the user breaks it.
- **Configure-then-disappear** (from metronome apps) ‚Äî settings exist on a separate screen. The active experience screen is stripped to the absolute minimum. Configuration and execution are fully separated.
- **Eyes-optional interaction** (from fitness/running apps) ‚Äî the app works through audio and haptic channels alone. The screen is a bonus, not a requirement. Large touch targets in predictable positions enable blind operation.

**Visual Patterns:**

- **Data as landscape** (from health/fitness apps like Apple Health) ‚Äî presenting personal data as a terrain to explore rather than a score to achieve. The perceptual profile visualization should feel like looking at a topographic map of your hearing.
- **Sparse-data grace** (from new Apple Watch health features) ‚Äî when data is limited, show what exists honestly with clear indication that the picture will fill in over time, rather than showing empty charts or placeholder data.

**Navigation Patterns:**

- **Hub-and-spoke** (iOS standard) ‚Äî Start Screen as the hub with direct paths to Training, Profile, and Settings. No deep navigation, no tabs, no hamburger menus. Every destination is one tap from home.

### Anti-Patterns to Avoid

1. **Score-driven design** ‚Äî Any UI element that frames training outcomes as a score, percentage, or pass/fail undermines Peach's core purpose. This includes hidden scores disguised as "levels" or "achievements."

2. **Transition theater** ‚Äî Animated transitions, loading indicators, result screens, and "preparing next challenge" delays between comparisons. Every second of non-training time is a design failure. The round-trip between comparisons must be effectively instantaneous.

3. **Engagement guilt mechanics** ‚Äî Streaks, daily goals, "you haven't trained in X days" notifications, declining statistics presented as warnings. These treat the user's absence as a problem to solve rather than a neutral fact.

4. **Complexity creep** ‚Äî Adding visible algorithm parameters, detailed per-comparison statistics, or "advanced mode" toggles to the Training Screen. The training experience must remain radically simple regardless of the algorithm's sophistication underneath.

5. **Onboarding tutorials** ‚Äî The interaction (two notes, tap higher or lower) is self-explanatory. A tutorial would imply complexity that doesn't exist and add friction to first launch.

### Design Inspiration Strategy

**Adopt:**
- Zero-delay comparison looping ‚Äî continuous flow with no dead time
- Hub-and-spoke navigation from Start Screen ‚Äî one tap to any destination
- Eyes-optional training via audio-haptic feedback channels
- Data-as-landscape visualization for the perceptual profile

**Adapt:**
- Metronome "configure then disappear" pattern ‚Äî applied to Settings vs. Training Screen separation
- Health app sparse-data presentation ‚Äî adapted for the perceptual profile's cold-start state
- Meditation app visual restraint ‚Äî Training Screen as a calm, minimal space

**Reject:**
- Score-driven interaction framing (InTune)
- Slow comparison round-trips with transition overhead (InTune)
- Gamification mechanics (streaks, badges, levels)
- Onboarding wizards and tutorial overlays
- Session-based framing with summaries and statistics screens
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî deepen the UX pattern analysis
- **[P]** Party Mode ‚Äî bring different perspectives on inspiration sources
- **[C]** Continue ‚Äî Save this to the document and move to design system choice

### üßë Human (11:16:17)

c

### ü§ñ Assistant (11:16:56)

Content saved. Loading the next step.

### ü§ñ Assistant (11:17:12)

For Peach, the design system choice is straightforward given the project context. This step's template is oriented toward web apps with Material Design / Tailwind options, but for a native iOS app the landscape is different. Let me frame it appropriately.

**The question for Peach is really:**

Since this is a native iOS app targeting iOS 26 exclusively, the design system foundation is Apple's Human Interface Guidelines (HIG) and SwiftUI's built-in component library ‚Äî including the new Liquid Glass design language. The real decision is about how much to customize on top of that.

**Three approaches:**

1. **Stock SwiftUI** ‚Äî Use Apple's standard components as-is. Fastest to build, fully accessible out of the box, automatically adopts Liquid Glass. Risk: may feel generic.

2. **Themed SwiftUI** ‚Äî Use Apple's components as the foundation but apply a cohesive visual identity through custom colors, typography choices, and selective component customization. Balances speed with personality.

3. **Custom component layer** ‚Äî Build bespoke UI components (especially for the Training Screen buttons and Profile visualization). More expressive, but more development work and accessibility responsibility.

Given that Peach has only 4 screens, the Training Screen needs large custom tap targets for eyes-closed use, and the Profile Screen needs a custom visualization (piano keyboard + confidence band), my read is that **option 2 (Themed SwiftUI) with custom components where needed** is the right fit. Stock SwiftUI for Settings and navigation, custom components for the Training Screen interaction and Profile visualization.

Does this match your thinking, or do you have a preference?

### üßë Human (11:19:12)

I want the UI to take the HIG as gospel. I hate apps that try to be cute and burden me with their own, non-standard UI ideas. So I'm enthusiastic about Stock SwiftUI.

### ü§ñ Assistant (11:19:38)

Clear and emphatic ‚Äî Stock SwiftUI it is. HIG as gospel, no custom UI cleverness. The custom work is limited to what SwiftUI simply doesn't provide out of the box (the perceptual profile visualization), not to "improving" on Apple's components.

**Here's what I'll add to the document:**

```markdown
## Design System Foundation

### Design System Choice

**Apple Human Interface Guidelines (HIG) + Stock SwiftUI** ‚Äî no customization layer, no theming, no bespoke component library.

Peach uses SwiftUI's built-in components exactly as Apple designed them. Standard buttons, standard navigation, standard layout patterns, standard Liquid Glass appearance on iOS 26. The app should look and feel like it belongs on the platform ‚Äî indistinguishable from a first-party Apple app in its interaction patterns.

### Rationale for Selection

1. **HIG compliance is a UX feature, not a constraint.** Users already know how iOS apps work. Every standard SwiftUI component carries years of learned behavior ‚Äî tap targets, gestures, navigation patterns, accessibility. Using stock components means zero learning curve for the app's chrome, so all cognitive attention goes to the training content (the sounds).

2. **"Disappearing UI" demands platform-native interaction.** The core experience principle is that the UI should disappear during training. Non-standard components draw attention to themselves. Stock components are invisible precisely because they're familiar.

3. **Solo developer, learning iOS.** Custom components require custom accessibility implementation, custom animation tuning, custom dark mode support, and custom Dynamic Type handling. Stock SwiftUI provides all of this for free. Building custom components would be effort spent fighting the platform instead of building the product.

4. **Four screens, minimal chrome.** Peach has a Start Screen, Training Screen, Profile Screen, and Settings Screen. Three of these (Start, Profile, Settings) are conventional enough for stock components. The Training Screen is minimal by design ‚Äî it needs large buttons and a feedback indicator, not a custom design system.

### Implementation Approach

- **Standard SwiftUI components everywhere:** Buttons, NavigationStack, Form (for Settings), standard layout containers
- **System colors and typography:** No custom color palette, no custom fonts. Use SwiftUI semantic colors (`.primary`, `.secondary`, `.accent`) and Dynamic Type
- **Liquid Glass:** Accept iOS 26's default Liquid Glass appearance without overriding it
- **Standard navigation patterns:** NavigationStack with standard push/pop for Start ‚Üí Profile, sheet presentation for Settings
- **Accessibility for free:** VoiceOver labels, Dynamic Type scaling, and contrast ratios handled by stock components automatically

### Custom Components (Only Where Necessary)

The only areas requiring custom implementation are where SwiftUI has no built-in equivalent:

1. **Perceptual profile visualization** ‚Äî The piano keyboard with confidence band overlay is a domain-specific data visualization. No stock component exists for this. Built with SwiftUI Canvas or Charts framework.

2. **Profile Preview** ‚Äî The stylized miniature profile on the Start Screen. A simplified rendering of the same visualization data.

3. **Training Screen button layout** ‚Äî While the buttons themselves are standard SwiftUI buttons, their sizing (large, thumb-friendly, eyes-closed operable) and positioning (optimized for one-handed use) require intentional layout work. The components are stock; the layout is considered.

These custom elements follow HIG principles (tap target sizes, accessibility labels, Dynamic Type awareness) even though they aren't stock components.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the design system decision
- **[P]** Party Mode ‚Äî bring technical perspectives on design systems
- **[C]** Continue ‚Äî Save this to the document and move to defining experience

### üßë Human (11:22:15)

c

### ü§ñ Assistant (11:22:33)

Content saved. Loading the next step.

### ü§ñ Assistant (11:22:42)

This step asks us to define the core interaction mechanics in detail ‚Äî the step-by-step flow of the comparison loop. We covered the high-level defining experience in step 3, so this step goes deeper into the mechanics.

Before I synthesize, one question that matters for the detailed mechanics:

**The moment between answering and the next comparison** ‚Äî after the user taps Higher/Lower:

- Should the feedback indicator (thumbs up/down) show *while* the next comparison's first note is already playing? Or should there be a brief visual-only feedback moment before the next note begins?
- Put another way: does the next comparison's first note begin *immediately* on answer, or is there a tiny gap (say 200-300ms) for the haptic/visual feedback to register before the next note?

This is the single most timing-critical UX decision in the whole app.

### üßë Human (11:25:42)

There needs to be a small gap. I.e., the feedback is shown immediately when the user answers and remains on screen, possibly as an overlay, for a short duration. During this time, also the haptic feedback occurs, if necessary. After that the next comparison ensues.

### ü§ñ Assistant (11:25:49)

Good ‚Äî that clarifies the loop timing. A brief feedback window (feedback appears instantly on answer, persists briefly, then the next comparison begins automatically). The feedback is a momentary confirmation, not a gate.

One more detail this raises: should the feedback indicator persist as an overlay into the next comparison's first note, or should it clear before the next note begins? In other words ‚Äî does the user see the thumbs up/down while already hearing the next first note, or is it gone by then?

### üßë Human (11:27:08)

The feedback indicator should clear before the next comparison.

### ü§ñ Assistant (11:27:54)

Clear ‚Äî the sequence is: answer ‚Üí feedback appears + haptic (if wrong) ‚Üí feedback clears ‚Üí next comparison's first note begins. No overlap between feedback and the next comparison. Clean transitions.

**Here's what I'll add to the document:**

```markdown
## Defining Experience

### Core Interaction

**"Two notes. Higher or lower. Next."**

The defining experience is the comparison loop ‚Äî a continuous, rhythmic cycle of listening and responding. The user hears two sequential notes, judges whether the second was higher or lower than the first, and the next comparison follows. The intelligence is invisible; the interaction is instinctive.

This is Peach's equivalent of Tinder's swipe or Spotify's play button ‚Äî the single interaction that *is* the product. If this loop feels right, everything else is secondary. If it doesn't, nothing else matters.

### User Mental Model

The user's mental model is **reflexive discrimination, not analytical comparison**. They are not thinking "that was 440Hz and that was 445Hz." They are hearing two sounds and reacting ‚Äî higher or lower ‚Äî the way a musician reacts to intonation in real time. The interaction should feel closer to catching a ball than solving a math problem.

**What users bring from existing solutions:**
- From InTune: the basic concept of comparing two pitches. But InTune wraps this in scoring and slow transitions that interrupt the reflex. Users who've used InTune expect overhead between comparisons ‚Äî Peach's zero-gap loop will feel surprisingly fast and liberating.
- From musical practice: the concept of ear training as repetitive, focused listening. Musicians already understand that pitch discrimination improves through volume of exposure, not through testing.

**Key mental model shift:** There is no "session" and no "result." The user is not completing something or achieving something ‚Äî they are *doing* something. Training is the activity, not the means to an outcome.

### Success Criteria

The comparison loop succeeds when:

1. **The user stops thinking about the app** ‚Äî they are reacting to sounds, not operating a UI. The buttons, the feedback, the transitions all fade from conscious attention.
2. **Throughput feels fast but not rushed** ‚Äî comparisons flow at the pace of the user's reflexes, not faster and not slower. The app matches the user's rhythm, not the other way around.
3. **Eyes-closed operation works** ‚Äî the user can close their eyes, listen, tap in the right area of the screen, feel the haptic (or not), and continue. The visual layer adds nothing essential during active training.
4. **Stopping feels neutral** ‚Äî the user can stop at any point without friction, summary, or consequence. Stopping mid-loop is as natural as lifting your fingers off piano keys.
5. **The loop is instantly resumable** ‚Äî reopening the app and tapping Start Training puts the user back into the same rhythm within seconds, regardless of how long they've been away.

### Novel UX Patterns

The comparison loop uses **established patterns combined in an uncommon way:**

- **Binary choice buttons** (established) ‚Äî Higher/Lower is a simple A/B input, familiar from countless apps
- **Continuous looping without session boundaries** (uncommon) ‚Äî most training apps have sessions, rounds, or levels. Peach's sessionless continuous loop is unusual and requires no user education ‚Äî it simply never stops until the user stops it
- **Audio-haptic primary feedback** (uncommon for training apps) ‚Äî the sensory hierarchy (ears > fingers > eyes) is atypical. Most apps treat visual feedback as primary. Peach inverts this for eyes-closed operation
- **Stateful button disabling** (established) ‚Äî Higher/Lower buttons disabled during the first note, enabled when the second note plays. Prevents premature answers without explanation ‚Äî the user discovers this naturally in the first comparison

No novel patterns require user education. The interaction is self-evident: two sounds play, two buttons are available, tap one. The only learning is that the buttons are disabled during the first note, which the user discovers implicitly.

### Experience Mechanics

**The Comparison Loop ‚Äî Step by Step:**

**1. Initiation:**
- User taps Start Training Button on Start Screen
- Training Screen appears
- First comparison begins immediately ‚Äî no countdown, no "get ready," no transition animation
- Higher/Lower buttons are visible but disabled

**2. First Note:**
- System plays the first note (the reference note, always an exact MIDI note)
- Higher/Lower buttons remain disabled ‚Äî visually indicated per stock SwiftUI disabled state
- Duration: configurable (default ~1 second), with smooth attack/release envelope

**3. Second Note:**
- System plays the second note (same MIDI note shifted by a cent difference)
- Higher/Lower buttons become enabled the moment the second note begins playing
- The user can answer at any point during or after the second note
- Same duration and envelope as the first note

**4. Answer:**
- User taps Higher or Lower
- Both buttons disable immediately to prevent double-tap
- Feedback phase begins instantly

**5. Feedback:**
- Feedback Indicator appears immediately (thumbs up for correct, thumbs down for incorrect)
- If incorrect: single haptic tick fires simultaneously with the visual feedback
- If correct: no haptic (silence = confirmation)
- Feedback persists for a brief duration (tunable, ~300-500ms)
- No other information shown ‚Äî no score, no streak, no comparison details

**6. Clear and Loop:**
- Feedback Indicator clears completely
- The comparison result is written to the data store
- The algorithm selects the next comparison
- The next first note begins playing ‚Äî return to step 2
- The loop continues indefinitely until the user stops it

**7. Stopping:**
- User taps Stop Button at any point during the loop
- If mid-comparison (during notes or awaiting answer): the incomplete comparison is silently discarded
- If during feedback: feedback clears, no comparison is lost (the answer was already recorded)
- Training Screen dismisses, user returns to Start Screen
- No session summary, no statistics, no confirmation dialog

**Timing Diagram:**

```
[Note 1 ~~~] [Note 2 ~~~] [Answer] [Feedback ¬∑¬∑] [Note 1 ~~~] [Note 2 ~~~] ...
 buttons off   buttons on   tap!     brief show    buttons off   buttons on
                                     + haptic(?)
```
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the core experience definition
- **[P]** Party Mode ‚Äî bring different perspectives on the defining interaction
- **[C]** Continue ‚Äî Save this to the document and move to visual foundation

### üßë Human (11:37:57)

I don't think we need an explicit stop button. In addition to the big Higher/Lower buttons, put two more buttons on the training screen (as well as on the start screen): One button shows the settings screen, the other shows Profile Screen. Also, unless I'm mistaken, this means the app needs to detect when the user leaves and returns, without quitting the app. In that case, the Start Screen should be shown again. If you agree, ask further questions or just update existing documents as needed.

### ü§ñ Assistant (11:38:22)

This is a clean simplification ‚Äî stopping is just *leaving*. No dedicated stop action, no "are you sure?" The user either keeps tapping Higher/Lower, or they do something else. I like it.

Let me confirm the navigation model this creates:

**From Training Screen:**
- Tap Higher/Lower ‚Üí continues the loop
- Tap Settings ‚Üí training stops (incomplete comparison discarded), Settings Screen opens
- Tap Profile ‚Üí training stops (incomplete comparison discarded), Profile Screen opens
- Background the app ‚Üí training stops, when the user returns they see the Start Screen

**Key question:** When the user finishes looking at Settings or Profile (having arrived from Training Screen), where do they land ‚Äî back on Training Screen (auto-resuming), or on Start Screen (requiring a tap to restart training)?

Given your statement that backgrounding returns to Start Screen, I'd expect navigating away from Training also returns to Start Screen afterward. The Training Screen is only entered via Start Training. Does that match your thinking?

### üßë Human (11:39:24)

Yes, exactly.

### ü§ñ Assistant (11:39:29)

Good. This gives us a simple, consistent navigation model:

- **Training Screen is only entered via Start Training** ‚Äî always a fresh start
- **Leaving Training (any way) = stopping** ‚Äî navigating to Settings, Profile, or backgrounding the app all stop training and discard any incomplete comparison
- **Settings and Profile always return to Start Screen** ‚Äî regardless of where you came from

Let me update all the documents to reflect this. The Stop Button is removed everywhere, the navigation model changes, and the Training Screen gets Settings/Profile buttons.

### ü§ñ Assistant (11:39:41)

Now let me update all the documents. Starting with the glossary.

### ü§ñ Assistant (11:39:51)

Now update the PRD.

### ü§ñ Assistant (11:40:09)

Now update the FR section ‚Äî remove Stop Button FR, update Training Screen description, add navigation FRs.

### ü§ñ Assistant (11:40:17)

Now update the MVP feature set and Journey Requirements Summary.

### ü§ñ Assistant (11:40:25)

Now update the Journey Requirements Summary table.

### ü§ñ Assistant (11:40:33)

Now update the Settings journey ‚Äî the opening scene mentions navigating from Start Screen.

### ü§ñ Assistant (11:40:37)

The Settings journey is fine ‚Äî it already says "from the Start Screen" which is correct. Now update the Training Screen description in the PRD's screen list.

### ü§ñ Assistant (11:40:41)

Good ‚Äî no Stop Button mention there. Now update the FR42 area and check for remaining Stop Button references in PRD.

### ü§ñ Assistant (11:40:47)

The brainstorming document is a historical record of the session. I'll leave it as-is since it captures what was discussed at the time ‚Äî the design has evolved since then. Now let me update the architecture doc where it references the Stop Button.

### ü§ñ Assistant (11:40:59)

Now update the architecture doc's UI boundaries and the TrainingSession description to reflect navigation-based stopping.

### ü§ñ Assistant (11:41:07)

Now let me also check the UX design spec for Stop Button references.

### ü§ñ Assistant (11:41:11)

Good ‚Äî the UX spec is clean. Now let me also update the architecture's Start Screen description.

### ü§ñ Assistant (11:42:10)

All documents updated. Here's a summary of changes across all files:

**Glossary:** Removed Stop Button entry. Updated Training Screen and Start Screen definitions to reflect Settings/Profile buttons on both screens. Updated Profile Screen to note it's accessible from both screens and always returns to Start.

**PRD:** Updated Journey 1 (Start Screen description), Journey 2 (stop mechanism), Journey Requirements Summary (added two new rows). Updated FR6 (navigation-based stopping), FR7 (expanded interruption triggers), added FR7a (backgrounding returns to Start Screen). Added two capabilities to MVP feature set.

**Architecture:** Updated TrainingScreen comment, app lifecycle behavior, UI boundary description, StartScreen comment.

**Brainstorming:** Left as historical record (captures what was discussed at the time).

Now let me generate the defining experience content with the corrected mechanics. **Here's what I'll add to the document:**

```markdown
## Defining Experience

### Core Interaction

**"Two notes. Higher or lower. Next."**

The defining experience is the comparison loop ‚Äî a continuous, rhythmic cycle of listening and responding. The user hears two sequential notes, judges whether the second was higher or lower than the first, and the next comparison follows. The intelligence is invisible; the interaction is instinctive.

### User Mental Model

The user's mental model is **reflexive discrimination, not analytical comparison**. They are not thinking "that was 440Hz and that was 445Hz." They are hearing two sounds and reacting ‚Äî higher or lower ‚Äî the way a musician reacts to intonation in real time. The interaction should feel closer to catching a ball than solving a math problem.

**What users bring from existing solutions:**
- From InTune: the basic concept of comparing two pitches. But InTune wraps this in scoring and slow round-trips that interrupt the training flow. Users who've used InTune expect overhead between comparisons ‚Äî Peach's rapid loop will feel surprisingly fast and liberating.
- From musical practice: the concept of ear training as repetitive, focused listening. Musicians already understand that pitch discrimination improves through volume of exposure, not through testing.

**Key mental model shift:** There is no "session" and no "result." The user is not completing something or achieving something ‚Äî they are *doing* something. Training is the activity, not the means to an outcome.

### Success Criteria

The comparison loop succeeds when:

1. **The user stops thinking about the app** ‚Äî they are reacting to sounds, not operating a UI. The buttons, the feedback, the transitions all fade from conscious attention.
2. **Throughput feels fast but not rushed** ‚Äî comparisons flow at the pace of the user's reflexes, not faster and not slower. The app matches the user's rhythm, not the other way around.
3. **Eyes-closed operation works** ‚Äî the user can close their eyes, listen, tap in the right area of the screen, feel the haptic (or not), and continue. The visual layer adds nothing essential during active training.
4. **Stopping feels like leaving, not quitting** ‚Äî the user navigates to Profile or Settings, or simply backgrounds the app. There is no "stop" action ‚Äî just doing something else. Training ends as naturally as it began.
5. **The loop is instantly resumable** ‚Äî reopening the app and tapping Start Training puts the user back into the same rhythm within seconds, regardless of how long they've been away.

### Novel UX Patterns

The comparison loop uses **established patterns combined in an uncommon way:**

- **Binary choice buttons** (established) ‚Äî Higher/Lower is a simple A/B input, familiar from countless apps
- **Continuous looping without session boundaries** (uncommon) ‚Äî most training apps have sessions, rounds, or levels. Peach's sessionless continuous loop is unusual and requires no user education ‚Äî it simply never stops until the user leaves
- **Audio-haptic primary feedback** (uncommon for training apps) ‚Äî the sensory hierarchy (ears > fingers > eyes) is atypical. Most apps treat visual feedback as primary. Peach inverts this for eyes-closed operation
- **Navigation-as-stop** (uncommon) ‚Äî there is no stop/exit button. The user stops training by navigating elsewhere (Settings, Profile) or leaving the app. Training is the default state of the Training Screen; everything else is leaving
- **Stateful button disabling** (established) ‚Äî Higher/Lower buttons disabled during the first note, enabled when the second note plays. Prevents premature answers without explanation ‚Äî the user discovers this naturally in the first comparison

No novel patterns require user education. The interaction is self-evident: two sounds play, two buttons are available, tap one.

### Experience Mechanics

**The Comparison Loop ‚Äî Step by Step:**

**1. Initiation:**
- User taps Start Training Button on Start Screen
- Training Screen appears with Higher/Lower buttons (disabled) and Settings/Profile buttons
- First comparison begins immediately ‚Äî no countdown, no "get ready," no transition animation

**2. First Note:**
- System plays the first note (the reference note, always an exact MIDI note)
- Higher/Lower buttons remain disabled ‚Äî visually indicated per stock SwiftUI disabled state
- Duration: configurable (default ~1 second), with smooth attack/release envelope

**3. Second Note:**
- System plays the second note (same MIDI note shifted by a cent difference)
- Higher/Lower buttons become enabled the moment the second note begins playing
- The user can answer at any point during or after the second note
- Same duration and envelope as the first note

**4. Answer:**
- User taps Higher or Lower
- Both buttons disable immediately to prevent double-tap
- Feedback phase begins instantly

**5. Feedback:**
- Feedback Indicator appears immediately (thumbs up for correct, thumbs down for incorrect)
- If incorrect: single haptic tick fires simultaneously with the visual feedback
- If correct: no haptic (silence = confirmation)
- Feedback persists for a brief duration (tunable, ~300-500ms)
- No other information shown ‚Äî no score, no streak, no comparison details

**6. Clear and Loop:**
- Feedback Indicator clears completely
- The comparison result is written to the data store
- The algorithm selects the next comparison
- The next first note begins playing ‚Äî return to step 2
- The loop continues indefinitely until the user navigates away

**7. Leaving:**
- User taps Settings or Profile button on Training Screen, or backgrounds the app
- If mid-comparison: the incomplete comparison is silently discarded
- If during feedback: feedback clears; the answered comparison was already recorded
- Training stops, user arrives at the selected destination (Settings/Profile) or Start Screen (on foreground after backgrounding)
- Settings and Profile always return to Start Screen when dismissed
- No session summary, no statistics, no confirmation dialog

**Navigation Model:**

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Start Screen ‚îÇ
                    ‚îÇ              ‚îÇ
                    ‚îÇ [Start]      ‚îÇ
                    ‚îÇ [Settings]   ‚îÇ
                    ‚îÇ [Profile]    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
          Start Training‚îÇ   ‚îÇ   ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îê  ‚îÇ   ‚îÇ
                    ‚îÇTrain‚îÇ  ‚îÇ   ‚îÇ
                    ‚îÇScreen‚îÇ ‚îÇ   ‚îÇ
                    ‚îÇ     ‚îÇ  ‚îÇ   ‚îÇ
                    ‚îÇ[H/L]‚îÇ  ‚îÇ   ‚îÇ
                    ‚îÇ[Set] ‚îÇ  ‚îÇ   ‚îÇ
                    ‚îÇ[Prof]‚îÇ  ‚îÇ   ‚îÇ
                    ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îò  ‚îÇ   ‚îÇ
                      ‚îÇ  ‚îÇ   ‚îÇ   ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚ñº‚îê  ‚îÇ
              ‚îÇ   Settings    ‚îÇ  ‚îÇ
              ‚îÇ   Screen      ‚îÇ‚îÄ‚îÄ‚îò‚óÑ‚îÄ‚îÄ always returns
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      to Start Screen
                      ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Profile        ‚îÇ‚îÄ‚îÄ‚îò‚óÑ‚îÄ‚îÄ always returns
              ‚îÇ   Screen         ‚îÇ      to Start Screen
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  App backgrounded during training ‚Üí returns to Start Screen
```
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the core experience definition
- **[P]** Party Mode ‚Äî bring different perspectives on the defining interaction
- **[C]** Continue ‚Äî Save this to the document and move to visual foundation

### üßë Human (11:44:25)

c

### ü§ñ Assistant (11:44:55)

Content saved. Loading the next step.

### ü§ñ Assistant (11:45:05)

This step asks about colors, typography, and spacing ‚Äî but given your commitment to stock SwiftUI and HIG as gospel, most of these decisions are already made: system fonts, system colors, system spacing. The question is really about what little remains to decide.

**Visual Foundation Questions:**

1. **Color:** Do you have a brand color or accent color in mind for Peach, or should the app just use the system default accent color (blue)? A custom accent color is the one place where even stock SwiftUI apps typically express identity ‚Äî it's just one color that tints interactive elements.

2. **App icon / branding:** Any thoughts on visual identity (peach-colored accent, music-related imagery), or is that out of scope for this UX spec?

3. **Dark mode:** iOS 26 supports dark mode by default with stock SwiftUI. Any preference on whether Peach should respect the system setting (automatic), or do you have a preference for one mode?

### üßë Human (11:48:26)

Just use the defaults. It's probably good practice to add a button to the Start Screen that shows an info screen containing at least app name, developer, copyright, and version. Please update all documents accordingly.

### ü§ñ Assistant (11:48:31)

Stock defaults across the board, plus a new Info Screen. Let me update all documents first.

### ü§ñ Assistant (11:48:39)

Now update the PRD.

### ü§ñ Assistant (11:48:47)

Now add an FR for the Info Screen.

### ü§ñ Assistant (11:48:55)

Now update the architecture doc ‚Äî add Info Screen to the project structure.

### ü§ñ Assistant (11:49:03)

Now update the second (complete) project structure in the architecture doc.

### ü§ñ Assistant (11:49:11)

Now update the FR-to-structure mapping table.

### ü§ñ Assistant (11:49:41)

All documents updated. Now let me synthesize the visual foundation content.

**Here's what I'll add to the document:**

```markdown
## Visual Design Foundation

### Color System

**System defaults throughout.** No custom color palette, no custom accent color.

- **Accent color:** SwiftUI system default (blue)
- **Semantic colors:** `.primary`, `.secondary`, `.tertiary` for text hierarchy
- **Background colors:** System background colors (`.background`, `.secondarySystemBackground`)
- **Feedback colors:** System green for correct, system red for incorrect (Feedback Indicator only)
- **Dark mode:** Automatic ‚Äî respects system setting. Stock SwiftUI handles all color adaptation.

No brand colors. The app's identity comes from its behavior, not its color scheme.

### Typography System

**San Francisco (system font) at all system-defined sizes.** No custom fonts, no custom type scale.

- **Dynamic Type:** Fully supported via stock SwiftUI. All text scales with the user's accessibility settings.
- **Text styles:** Standard SwiftUI text styles (`.largeTitle`, `.title`, `.headline`, `.body`, `.caption`, etc.) used according to information hierarchy.
- **No custom font weights or sizes.** If SwiftUI's semantic text styles don't provide the right emphasis, use a different text style ‚Äî don't override font metrics.

### Spacing & Layout Foundation

**SwiftUI default spacing and layout.** No custom spacing system, no custom grid.

- **Spacing:** SwiftUI's default padding and spacing values. Use `.padding()` without custom values wherever possible.
- **Layout:** Standard SwiftUI layout containers (`VStack`, `HStack`, `ZStack`, `Form`, `List`) with default spacing.
- **Safe areas:** Respect all system safe areas. No custom insets.
- **Adaptive layout:** SwiftUI's built-in support for iPhone/iPad, portrait/landscape, and Dynamic Type scaling handles all layout adaptation.

The only layout area requiring intentional design is the Training Screen button placement ‚Äî positioning Higher/Lower buttons for comfortable one-handed, eyes-closed thumb reach. Even here, the buttons themselves are stock SwiftUI; only their size and position are considered.

### Accessibility Considerations

**Stock SwiftUI provides the accessibility baseline for free:**

- **VoiceOver:** All stock components are automatically labeled. Custom components (profile visualization, profile preview) require explicit accessibility labels.
- **Dynamic Type:** All text scales automatically with system font size settings.
- **Color contrast:** System colors meet accessibility contrast ratios in both light and dark mode.
- **Tap targets:** Stock SwiftUI buttons meet Apple's 44x44pt minimum. Training Screen buttons will exceed this significantly for eyes-closed operation.
- **Haptic feedback:** Provides non-visual feedback channel, supporting the sensory hierarchy (ears > fingers > eyes).
- **Reduce Motion:** Stock SwiftUI respects the system Reduce Motion setting automatically.

### Info Screen

A simple informational screen accessible from the Start Screen via a standard info button (e.g., SwiftUI `.buttonStyle` with `Image(systemName: "info.circle")`).

**Contents:**
- App name (Peach)
- Developer name
- Copyright notice
- App version number (pulled from bundle)

Presented as a standard SwiftUI sheet. Minimal content, stock presentation.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the visual foundation
- **[P]** Party Mode ‚Äî bring design perspectives on visual choices
- **[C]** Continue ‚Äî Save this to the document and move to design directions

### üßë Human (11:52:08)

c

### ü§ñ Assistant (11:52:37)

Content saved. Loading the next step.

### ü§ñ Assistant (11:52:57)

This step is designed for projects that need visual design exploration ‚Äî generating 6-8 HTML mockup variations with different color applications, layout densities, and visual weights.

For Peach, this step doesn't apply in its intended form. You've committed to stock SwiftUI with system defaults ‚Äî no custom colors, no custom fonts, no custom spacing. There are no visual design directions to explore. The "design direction" is: **look and behave like a standard iOS 26 app.**

The meaningful design decisions that remain are about **layout and content placement** on each screen ‚Äî not visual styling. Those are better addressed in the next step (user journey flows) and screen-by-screen design.

I'd suggest we document this decision clearly and move on rather than generate artificial variations. Here's what I'd add:

```markdown
## Design Direction

### Design Directions Explored

No visual design direction exploration was performed. Peach uses stock SwiftUI with all system defaults (colors, typography, spacing, Liquid Glass). There are no custom visual design decisions to make ‚Äî the design direction is iOS 26 itself.

This is a deliberate choice, not an omission. See [Design System Foundation](#design-system-foundation) for the full rationale.

### Chosen Direction

**Stock iOS 26 / Liquid Glass** ‚Äî the app should be visually indistinguishable from a first-party Apple app in its use of standard components, system colors, and platform conventions.

### Design Rationale

1. **HIG as gospel** ‚Äî the user explicitly requires strict adherence to Apple's Human Interface Guidelines with no custom UI embellishments.
2. **Disappearing UI principle** ‚Äî visual customization draws attention to the app's chrome. Stock appearance is invisible, keeping focus on the training content (sounds).
3. **Development efficiency** ‚Äî no custom design system to build, maintain, or test. All visual behavior comes from the platform for free.

### Remaining Design Work

The design work that matters for Peach is not visual styling but **screen layout and interaction flow**:

- Training Screen: button sizing and placement for one-handed, eyes-closed operation
- Start Screen: information hierarchy and element arrangement
- Profile Screen: perceptual profile visualization (the one truly custom visual element)
- Navigation flow between all five screens (Start, Training, Profile, Settings, Info)

These are addressed in subsequent sections.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî explore visual directions after all
- **[P]** Party Mode ‚Äî bring different perspectives
- **[C]** Continue ‚Äî Save this and move to user journey flows

### üßë Human (11:55:27)

c

### ü§ñ Assistant (11:55:54)

Content saved. Loading the next step.

### ü§ñ Assistant (11:56:04)

The PRD defines 5 user journeys. We've already designed the comparison loop mechanics in detail (step 7). Now let me map all journeys as interaction flows, incorporating everything we've decided ‚Äî the navigation model, the navigation-as-stop pattern, the Info Screen, and the updated screen set.

Before I synthesize, one question: the PRD's Journey 3 (Checking Progress) has Sarah navigating to the Profile Screen from the Start Screen. But with our new navigation model, she could also reach Profile *from* the Training Screen mid-training. Is there a scenario you envision where a user checks their profile during training and then wants to resume? Or is the expectation always: if you leave training to check profile, you're done training (and need to tap Start Training again)?

### üßë Human (11:59:21)

Yes, the assumption is that if you leave training, the way to get their again always goes through the start screen.

### ü§ñ Assistant (12:00:01)

Clear ‚Äî that's already consistent with everything we've documented. Let me synthesize the journey flows.

**Here's what I'll add to the document:**

```markdown
## User Journey Flows

### Journey 1: First Launch

```mermaid
flowchart TD
    A[App opens] --> B[Start Screen]
    B --> C{User action}
    C -->|Tap Start Training| D[Training Screen]
    C -->|Tap Profile| E[Profile Screen - empty/cold start]
    C -->|Tap Settings| F[Settings Screen]
    C -->|Tap Info| G[Info Screen]
    D --> H[Comparison loop begins immediately]
    H --> I{User action during training}
    I -->|Higher/Lower| H
    I -->|Tap Settings| F
    I -->|Tap Profile| E
    I -->|Background app| B
    E --> B
    F --> B
    G --> B
```

**Key UX decisions:**
- No onboarding, no tutorial, no welcome screen. The Start Screen *is* the onboarding.
- Profile Preview on Start Screen is visible but sparse (cold start state). Tapping it shows the full Profile Screen with honest empty-state presentation.
- The user discovers the comparison loop by doing it. The first comparison is self-explanatory: two sounds, two buttons.

### Journey 2: Daily Training

```mermaid
flowchart TD
    A[App opens] --> B[Start Screen]
    B -->|Tap Start Training| C[Training Screen]
    C --> D[Note 1 plays - buttons disabled]
    D --> E[Note 2 plays - buttons enabled]
    E --> F{User taps}
    F -->|Higher or Lower| G[Feedback shown + haptic if wrong]
    G --> H[Feedback clears]
    H --> D
    F -->|Settings button| I[Training stops - Settings Screen]
    F -->|Profile button| J[Training stops - Profile Screen]
    I --> B
    J --> B

    C -->|App backgrounded| K[Training stops - incomplete comparison discarded]
    K --> B
    D -->|App backgrounded| K
    E -->|App backgrounded| K
    G -->|App backgrounded| L[Training stops - answered comparison already saved]
    L --> B
```

**Key UX decisions:**
- The loop has no exit point ‚Äî it only has departure points (navigating elsewhere or leaving the app).
- Backgrounding at any point returns to Start Screen on foreground.
- Audio interruptions (phone call, headphone disconnect) behave identically to backgrounding ‚Äî training stops, incomplete comparison discarded.

### Journey 3: Checking Progress

```mermaid
flowchart TD
    A[Start Screen] --> B{User action}
    B -->|Tap Profile Preview| C[Profile Screen]
    C --> D[View perceptual profile visualization]
    C --> E[View summary statistics - mean, std dev, trend]
    D --> F{User action}
    E --> F
    F -->|Back / swipe| A
    A -->|Tap Start Training| G[Training Screen - new training]
```

**Key UX decisions:**
- Profile Screen is read-only ‚Äî no interactions beyond viewing and navigating back.
- Summary statistics show trend direction (improving/stable/declining) as an understated indicator.
- Returning from Profile always goes to Start Screen, making it natural to start a new training session afterward.

### Journey 4: Return After Break

```mermaid
flowchart TD
    A[App opens after weeks] --> B[Start Screen - identical to last visit]
    B -->|Tap Start Training| C[Training Screen]
    C --> D[Algorithm uses existing profile]
    D --> E[Comparisons calibrated to last known thresholds]
    E --> F{Performance}
    F -->|Some wrong answers| G[Algorithm widens intervals naturally]
    F -->|Correct answers| H[Algorithm continues narrowing]
    G --> E
    H --> E
```

**Key UX decisions:**
- No "welcome back" messaging. No streak reset. No skill degradation warning.
- The Start Screen is identical regardless of time elapsed since last use.
- The algorithm handles reacclimation silently ‚Äî it widens intervals when the user gets more wrong, without announcement.

### Journey 5: Tweaking Settings

```mermaid
flowchart TD
    A[Start Screen] -->|Tap Settings| B[Settings Screen]
    B --> C[Adjust Natural vs. Mechanical slider]
    B --> D[Configure note range]
    B --> E[Configure note duration]
    B --> F[Configure reference pitch]
    B --> G[Select sound source]
    C --> H[Settings auto-saved]
    D --> H
    E --> H
    F --> H
    G --> H
    H -->|Back / swipe| A
    A -->|Tap Start Training| I[Training Screen - settings applied immediately]
```

**Key UX decisions:**
- Settings are persisted immediately (no save button). Standard iOS pattern via `@AppStorage`.
- Settings Screen uses stock SwiftUI `Form` ‚Äî standard iOS settings presentation.
- Changes take effect on the next comparison after returning to training.

### Journey Patterns

**Navigation pattern:** All roads lead back to Start Screen. Settings, Profile, and Info all return to Start Screen when dismissed. Training Screen is only entered via Start Training. This creates a simple, predictable hub-and-spoke model with no deep navigation.

```
Start Screen ‚îÄ‚îÄ‚ñ∫ Training Screen (via Start Training only)
Start Screen ‚îÄ‚îÄ‚ñ∫ Profile Screen ‚îÄ‚îÄ‚ñ∫ Start Screen
Start Screen ‚îÄ‚îÄ‚ñ∫ Settings Screen ‚îÄ‚îÄ‚ñ∫ Start Screen
Start Screen ‚îÄ‚îÄ‚ñ∫ Info Screen ‚îÄ‚îÄ‚ñ∫ Start Screen
Training Screen ‚îÄ‚îÄ‚ñ∫ Profile Screen ‚îÄ‚îÄ‚ñ∫ Start Screen
Training Screen ‚îÄ‚îÄ‚ñ∫ Settings Screen ‚îÄ‚îÄ‚ñ∫ Start Screen
App backgrounded during training ‚îÄ‚îÄ‚ñ∫ Start Screen
```

**Feedback pattern:** The comparison loop uses a consistent feedback cycle: action ‚Üí immediate feedback ‚Üí brief hold ‚Üí clear ‚Üí next action. This pattern never varies ‚Äî correct and incorrect answers follow the same timing, with the only difference being the haptic tick on incorrect.

**Interruption pattern:** Any interruption during training (navigation, backgrounding, phone call, headphone disconnect) follows the same rule: stop audio, discard incomplete comparison, leave Training Screen. No special cases, no confirmation dialogs, no state to recover.

### Flow Optimization Principles

1. **Minimum taps to value:** App launch ‚Üí Start Screen ‚Üí one tap ‚Üí training. Two taps from cold launch to hearing the first note.

2. **No dead ends:** Every screen has a clear path forward or back. No screen requires a specific action to leave. The user is never trapped.

3. **Consistent dismissal:** Every non-training screen returns to Start Screen via standard iOS back navigation (swipe or back button). No custom dismiss patterns.

4. **Stateless navigation:** No screen depends on how you arrived. Profile Screen shows the same content whether reached from Start Screen or Training Screen. Settings Screen doesn't know or care if training was interrupted to get there.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the user journey designs
- **[P]** Party Mode ‚Äî bring different perspectives on user flows
- **[C]** Continue ‚Äî Save this to the document and move to component strategy

### üßë Human (12:01:46)

c

### ü§ñ Assistant (12:02:13)

Content saved. Loading the next step.

### ü§ñ Assistant (12:02:20)

Given stock SwiftUI as our foundation, the component analysis is straightforward ‚Äî almost everything is covered by the platform. Let me map what's stock vs. custom, and spec out the few custom components in detail.

Any thoughts on the perceptual profile visualization before I synthesize? Specifically ‚Äî the PRD describes a piano keyboard X-axis with a confidence band overlay. Do you have a mental image of what this should look like, or should I propose an approach?

### üßë Human (12:04:43)

Go ahead.

### ü§ñ Assistant (12:05:32)

**Here's what I'll add to the document:**

```markdown
## Component Strategy

### Design System Components (Stock SwiftUI)

Every screen in Peach is built primarily from stock SwiftUI components. The following covers all standard component usage across the app:

| Component | SwiftUI Implementation | Used On |
|---|---|---|
| Start Training button | `Button` with `.buttonStyle(.borderedProminent)` | Start Screen |
| Settings button | `Button` with `Image(systemName:)` | Start Screen, Training Screen |
| Profile button | `Button` with `Image(systemName:)` | Start Screen, Training Screen |
| Info button | `Button` with `Image(systemName: "info.circle")` | Start Screen |
| Higher/Lower buttons | `Button` with `.disabled()` state | Training Screen |
| Navigation | `NavigationStack` | App-wide |
| Settings form | `Form` with `Slider`, `Stepper`, `Picker` | Settings Screen |
| Sheet presentation | `.sheet()` modifier | Info Screen, potentially Settings |
| Text hierarchy | `Text` with `.font(.largeTitle)`, `.title`, `.body`, etc. | All screens |
| Back navigation | Standard NavigationStack back button / swipe | Profile, Settings, Info |

**Coverage assessment:** Stock SwiftUI covers approximately 90% of Peach's UI needs. The remaining 10% is domain-specific visualization that no design system would provide.

### Custom Components

#### Perceptual Profile Visualization

**Purpose:** Display the user's pitch discrimination ability across their training range as an intuitive, glanceable landscape.

**Visual Design:**
- **X-axis:** Piano keyboard representation ‚Äî a horizontal strip of alternating white and black keys spanning the training range. Keys are stylized (not photorealistic) ‚Äî simple rectangles with standard piano proportions. Note names shown at octave boundaries (C2, C3, C4, etc.).
- **Y-axis:** Detection threshold in cents ‚Äî lower is better. The axis is inverted so that improvement (smaller cent differences) visually moves the band *downward* toward the keyboard, creating the intuitive metaphor of "getting closer to the notes."
- **Confidence band:** A filled area chart overlaid above the keyboard, showing the detection threshold at each note. The band's width represents uncertainty ‚Äî wider where data is sparse, narrower where many comparisons have been answered. Uses system colors (`.blue` or `.tint` for the band fill, with opacity for the confidence range).
- **Empty state (cold start):** The keyboard renders fully. The confidence band is either absent or shown as a wide, uniform band at the 100-cent level with high transparency, communicating "no data yet" without looking broken. A brief text label ("Start training to build your profile") appears centered above the keyboard.
- **Sparse data state:** The confidence band renders where data exists and fades out where it doesn't. No interpolation across large gaps ‚Äî honest representation of what's known.

**Implementation:** SwiftUI `Canvas` for the keyboard rendering, Swift Charts `AreaMark` for the confidence band overlay. Both are first-party frameworks requiring no dependencies.

**States:**
- Empty (cold start) ‚Äî keyboard only, no band or minimal placeholder band
- Sparse ‚Äî partial band with visible gaps and wide confidence intervals
- Populated ‚Äî continuous band with narrowing confidence intervals in trained regions
- All states render identically in light and dark mode using system semantic colors

**Accessibility:**
- VoiceOver summary: "Perceptual profile showing detection thresholds from [lowest note] to [highest note]. Average threshold: [X] cents."
- Not individually navigable per note (would be overwhelming) ‚Äî provide aggregate summary
- Sufficient contrast via system colors in both light and dark mode

#### Profile Preview

**Purpose:** Provide a glanceable miniature of the perceptual profile on the Start Screen, inviting the user to tap for detail.

**Visual Design:**
- A compact, simplified version of the full profile visualization ‚Äî same confidence band shape, no axis labels, no note names, no numerical values
- Sized to fit as a secondary element on the Start Screen (roughly the width of the screen, ~60-80pt tall)
- Acts as a button ‚Äî tappable to navigate to the full Profile Screen
- Empty state: shows a placeholder shape or subtle empty-state treatment that still looks intentional

**Implementation:** Same rendering logic as the full visualization, scaled down and stripped of labels. SwiftUI `Canvas` with a `Button` or `NavigationLink` wrapper.

**Accessibility:**
- VoiceOver label: "Your pitch profile. Tap to view details."
- If data exists: "Your pitch profile. Average threshold: [X] cents. Tap to view details."

#### Feedback Indicator

**Purpose:** Show immediate visual confirmation of correct/incorrect after each comparison answer.

**Visual Design:**
- Thumbs up (`Image(systemName: "hand.thumbsup.fill")`) for correct, thumbs down (`Image(systemName: "hand.thumbsdown.fill")`) for incorrect
- Uses system green (correct) and system red (incorrect) ‚Äî standard semantic meaning
- Appears as a centered overlay on the Training Screen, large enough to be visible in peripheral vision but not obstructing the Higher/Lower buttons
- Brief appearance (~300-500ms, tunable), then fades or disappears
- No animation on appearance (respects Reduce Motion by default); simple opacity transition if motion is enabled

**Implementation:** SF Symbols with `.foregroundStyle()` color, shown/hidden via SwiftUI state. Standard `.transition(.opacity)` for appearance/disappearance.

**States:**
- Hidden (default during note playback and awaiting answer)
- Correct (thumbs up, green)
- Incorrect (thumbs down, red)

**Accessibility:**
- VoiceOver announcement: "Correct" or "Incorrect" (automatic via SF Symbol labels)
- Haptic feedback on incorrect is the primary non-visual channel ‚Äî already specified in emotional design principles

### Component Implementation Strategy

**Principle: stock first, custom only when forced.**

1. **Use stock SwiftUI components exactly as provided** ‚Äî no subclassing, no custom styles, no appearance overrides. If a stock component doesn't look exactly right, reconsider the layout before customizing the component.

2. **Custom components use first-party frameworks only** ‚Äî SwiftUI Canvas and Swift Charts. No third-party visualization libraries.

3. **Custom components follow stock patterns** ‚Äî even custom components use system colors, Dynamic Type, and standard accessibility APIs. They should *feel* like stock components that Apple just hasn't built yet.

4. **Single implementation shared across contexts** ‚Äî the profile visualization logic is written once and used at two scales (full Profile Screen and Start Screen preview). No separate implementations.

### Implementation Roadmap

**Phase 1 ‚Äî Training Loop (MVP Core):**
- Higher/Lower buttons with disabled state (stock `Button`)
- Feedback Indicator (SF Symbols + state management)
- Settings/Profile navigation buttons on Training Screen (stock `Button`)

**Phase 2 ‚Äî Screens (MVP Complete):**
- Start Screen layout with Start Training button, Profile Preview, navigation buttons (stock components + Profile Preview custom)
- Settings Screen (stock `Form`)
- Info Screen (stock layout in `.sheet()`)
- Profile Screen with full visualization (custom `Canvas` + Swift Charts)
- Profile Preview on Start Screen (shared rendering, scaled down)

**Phase 3 ‚Äî Polish (MVP Refinement):**
- Empty/sparse state handling for profile visualization
- Feedback Indicator timing tuning
- Training Screen button sizing optimization for eyes-closed operation
- Accessibility label refinement for custom components
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the component strategy
- **[P]** Party Mode ‚Äî bring technical perspectives on component design
- **[C]** Continue ‚Äî Save this to the document and move to UX patterns

### üßë Human (12:08:36)

c

### ü§ñ Assistant (12:09:06)

Content saved. Loading the next step.

### ü§ñ Assistant (12:09:13)

For Peach, the relevant UX pattern categories are narrow ‚Äî no forms to validate (Settings uses stock `Form`), no search, no filtering. The patterns that matter are specific to the training loop, feedback, navigation, and states. Let me synthesize what we've already established plus fill in any gaps.

Anything you want to flag before I draft this, or should I go ahead?

### üßë Human (12:09:27)

Go ahead.

### ü§ñ Assistant (12:10:09)

**Here's what I'll add to the document:**

```markdown
## UX Consistency Patterns

### Button Hierarchy

**Primary action (one per screen):**
- Start Training Button on Start Screen ‚Äî `.buttonStyle(.borderedProminent)`, prominent size
- Higher and Lower buttons on Training Screen ‚Äî large, prominent, filling most of the lower screen area

**Secondary actions (navigation):**
- Settings, Profile, Info buttons ‚Äî icon-only using SF Symbols, standard size, consistent placement across screens
- On Start Screen: Settings, Profile, Info buttons in a consistent location (e.g., toolbar or grouped near the top)
- On Training Screen: Settings and Profile buttons in the same relative position as on Start Screen, but visually subordinate to Higher/Lower

**Button state rules:**
- Disabled buttons use stock SwiftUI `.disabled()` ‚Äî no custom disabled appearance
- Higher/Lower buttons transition between disabled and enabled states during the comparison loop. This is the only dynamic button state in the app.
- All other buttons are always enabled when visible

### Feedback Patterns

Peach has exactly one feedback pattern, used consistently throughout:

**Comparison feedback (the only feedback in the app):**

| Aspect | Correct | Incorrect |
|---|---|---|
| Visual | Thumbs up (SF Symbol), system green | Thumbs down (SF Symbol), system red |
| Haptic | None (silence = confirmation) | Single haptic tick (`UIImpactFeedbackGenerator`) |
| Audio | None | None |
| Duration | ~300-500ms (tunable) | ~300-500ms (tunable) |
| Timing | Appears instantly on answer | Appears instantly on answer |
| Dismissal | Clears automatically before next comparison | Clears automatically before next comparison |

**What Peach does NOT have:**
- No success/error/warning/info alerts
- No toast notifications
- No banners or snackbars
- No confirmation dialogs (including for stopping training)
- No progress indicators or loading spinners (everything is local and instant)

This radical simplicity is intentional. The only feedback the user ever receives during training is the comparison result. Everything else is silent.

### Form Patterns

**Settings Screen only.** Stock SwiftUI `Form` with standard controls:

| Setting | Control | SwiftUI Component |
|---|---|---|
| Natural vs. Mechanical | Continuous slider | `Slider` |
| Note range (lower bound) | Value picker | `Picker` or `Stepper` |
| Note range (upper bound) | Value picker | `Picker` or `Stepper` |
| Note duration | Value selector | `Stepper` or `Slider` |
| Reference pitch | Value input | `Stepper` (default 440Hz) |
| Sound source | Selection list | `Picker` (MVP: sine wave only) |

**Form behavior rules:**
- All changes auto-save via `@AppStorage` ‚Äî no save/cancel buttons
- No form validation needed ‚Äî all controls are bounded (sliders have min/max, steppers have ranges)
- No confirmation for changes ‚Äî settings take effect on the next comparison
- Standard `Form` section grouping for related settings

### Navigation Patterns

**Hub-and-spoke, one level deep.** No exceptions.

| Rule | Implementation |
|---|---|
| Start Screen is always the hub | `NavigationStack` root |
| All secondary screens return to Start Screen | Standard back navigation |
| Training Screen is entered only via Start Training | `NavigationLink` or programmatic navigation |
| Training Screen is exited only by navigating away | Settings/Profile buttons, or app backgrounding |
| Sheets for lightweight screens | Info Screen presented as `.sheet()` |
| Push navigation for content screens | Profile, Settings via `NavigationStack` push |
| No deep navigation | Maximum depth is always 1 level from Start Screen |
| No tabs | Single navigation stack, no `TabView` |

**Transition rules:**
- All navigation uses stock SwiftUI transitions (push/pop, sheet present/dismiss)
- No custom transition animations
- No transition interrupts the comparison loop ‚Äî navigation *is* stopping the loop

### Empty States

Peach has two empty-state scenarios:

**1. Profile visualization ‚Äî cold start (no training data):**
- Piano keyboard renders fully
- Confidence band absent or shown as a faint, uniform placeholder at 100 cents
- Text: "Start training to build your profile"
- The empty state should look like the beginning of something, not a broken screen
- No call-to-action button in the empty state (the Start Training button is on the Start Screen)

**2. Summary statistics ‚Äî cold start (no training data):**
- Statistics area shows dashes or "‚Äî" instead of numbers
- Trend indicator hidden (not enough data for a trend)
- No "you haven't trained yet" messaging ‚Äî just the absence of data

**What Peach does NOT have empty states for:**
- Training Screen ‚Äî never empty, the loop starts immediately
- Settings Screen ‚Äî always populated with current values (defaults on first launch)
- Start Screen ‚Äî always shows all elements; Profile Preview shows its own empty state

### Loading States

**Peach has no loading states.** Everything is local and instantaneous:
- Training data is loaded from SwiftData at app startup (< 2 seconds for launch-to-interactive)
- Profile computation is in-memory
- Audio generation is real-time
- Settings are read from `@AppStorage` (synchronous)

If app launch takes noticeable time as the dataset grows, the system splash screen covers it. No custom loading indicators.

### Error States

**Peach has no user-visible error states.** Per the architecture document:
- Audio failure ‚Üí training stops silently (user returns to Start Screen)
- Data write failure ‚Üí logged internally, training continues (one comparison's data may be lost)
- The user never sees an error screen, error alert, or error message

This is a deliberate design choice: errors are handled by the system (TrainingSession as error boundary), not by the user.

### Orientation & Device Patterns

| Pattern | Rule |
|---|---|
| Portrait | Primary orientation. Training Screen optimized for one-handed portrait use. |
| Landscape | Supported. Layout adapts via SwiftUI automatic layout. Training Screen buttons reflow to horizontal arrangement. |
| iPhone | Primary device. All screens designed for iPhone-sized viewport first. |
| iPad | Supported. Layouts scale naturally. No iPad-specific layouts or split views. |
| iPad windowed mode | Supported via SwiftUI adaptive layout. No minimum window size requirements. |
| Dynamic Type | All text scales. Custom components (profile visualization) handle text scaling for labels. |
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the UX patterns
- **[P]** Party Mode ‚Äî bring different perspectives on consistency patterns
- **[C]** Continue ‚Äî Save this to the document and move to responsive design & accessibility

### üßë Human (12:14:55)

c

### ü§ñ Assistant (12:15:29)

Content saved. Loading the next step.

### ü§ñ Assistant (12:16:08)

This step is heavily web-oriented (breakpoints, CSS units, WCAG levels, browser testing). For a native iOS app using stock SwiftUI, most of this is handled by the platform. But there are Peach-specific accessibility considerations worth documenting ‚Äî particularly around the audio-haptic sensory hierarchy and eyes-closed operation. Let me synthesize.

**Here's what I'll add to the document:**

```markdown
## Responsive Design & Accessibility

### Responsive Strategy

**SwiftUI handles responsive layout automatically.** No breakpoints, no media queries, no manual layout adaptation.

**Device adaptation:**
- **iPhone (all sizes):** SwiftUI adaptive layout. Training Screen buttons scale proportionally. Profile visualization fills available width.
- **iPad:** Same layouts, more space. No split views, no sidebar, no iPad-specific layouts. The app runs as a simple, spacious single-column experience.
- **iPad windowed/compact mode:** SwiftUI handles gracefully. Layouts compress the same way they do on smaller iPhones.

**Orientation adaptation:**
- **Portrait (primary):** All screens designed for portrait first. Training Screen has Higher/Lower stacked vertically with Settings/Profile buttons above.
- **Landscape:** SwiftUI reflows automatically. Training Screen buttons may arrange horizontally. Profile visualization gains width for more keyboard detail. No orientation lock ‚Äî both are supported.

**Dynamic Type adaptation:**
- All stock SwiftUI text scales automatically with the user's preferred text size.
- Custom components (profile visualization) use system font for labels, which scales with Dynamic Type.
- Layout must not break at the largest accessibility text sizes ‚Äî SwiftUI's adaptive layout handles this, but profile visualization labels may need to hide or abbreviate at extreme sizes.

### Accessibility Strategy

**Compliance target:** Apple's accessibility best practices (equivalent to WCAG AA for native apps). Stock SwiftUI provides the foundation; custom components fill in accessibility labels and summaries.

**Peach-specific accessibility considerations:**

**1. Sensory hierarchy is an accessibility feature:**
The design principle "ears > fingers > eyes" means the app is inherently more accessible than visually-dependent training apps. A user who cannot see the screen can still train effectively:
- Audio provides the training content (the two notes)
- Haptic provides the result feedback (tick on wrong, silence on correct)
- VoiceOver provides navigation and screen context

**2. Eyes-closed operation as accessibility baseline:**
The Training Screen is designed to work with eyes closed. This means it already meets many accessibility requirements by default:
- Large, fixed-position buttons usable without visual precision
- Non-visual feedback (haptic) as the primary result channel
- No visual-only information during active training

**3. Audio dependency:**
Peach requires audio output to function. This is an inherent constraint ‚Äî the app trains pitch discrimination through sound. Users who are deaf or hard of hearing cannot use the core training functionality. This is acknowledged as a fundamental limitation of the domain, not a design oversight.

### Accessibility Implementation

| Area | Stock SwiftUI (Free) | Custom Implementation Required |
|---|---|---|
| VoiceOver labels on buttons | Automatic | None |
| VoiceOver for profile visualization | ‚Äî | Custom `.accessibilityLabel()` with aggregate summary |
| VoiceOver for profile preview | ‚Äî | Custom `.accessibilityLabel()` with threshold summary |
| VoiceOver for feedback indicator | Automatic (SF Symbol labels) | None |
| Dynamic Type | Automatic | Profile visualization label scaling |
| Color contrast | Automatic (system colors) | None |
| Tap target sizes | Automatic (44x44pt minimum) | Training buttons exceed minimum by design |
| Haptic feedback | ‚Äî | `UIImpactFeedbackGenerator` on incorrect answer |
| Reduce Motion | Automatic | Feedback Indicator transition respects setting |
| Dark mode | Automatic | Profile visualization uses system semantic colors |
| Bold Text | Automatic | None |
| Button Shapes | Automatic | None |

### Testing Strategy

**Accessibility testing:**
- VoiceOver walkthrough of all five screens ‚Äî verify all elements are labeled and navigable
- Dynamic Type testing at all size categories including the five accessibility sizes
- Test with Bold Text enabled
- Test with Reduce Motion enabled
- Test with Dark Mode ‚Äî verify profile visualization contrast

**Device testing:**
- iPhone SE (smallest current screen) ‚Äî verify Training Screen buttons are reachable and large enough
- iPhone 16 Pro Max (largest current screen) ‚Äî verify layout doesn't feel empty or sparse
- iPad (any model) ‚Äî verify layouts scale appropriately
- Both orientations on all devices

**Functional accessibility testing:**
- Complete a training session with eyes closed ‚Äî verify the audio-haptic loop works without visual feedback
- Navigate all five screens using VoiceOver only
- Verify Settings Screen is fully operable with VoiceOver

### Implementation Guidelines

**For AI agents building this app:**

1. **Never override stock accessibility.** SwiftUI's built-in accessibility labels, traits, and behaviors are correct by default for stock components. Don't add custom accessibility modifiers to stock components unless the default is wrong.

2. **Always add accessibility to custom components.** The profile visualization, profile preview, and feedback indicator need explicit `.accessibilityLabel()` and `.accessibilityValue()` modifiers because they're custom-rendered.

3. **Test VoiceOver during development.** Run VoiceOver on every screen as you build it, not as a final pass. Catching accessibility issues early is cheaper than retrofitting.

4. **Respect system settings.** Use `@Environment(\.dynamicTypeSize)`, `@Environment(\.colorScheme)`, and `@Environment(\.accessibilityReduceMotion)` where relevant in custom components.

5. **Don't add accessibility theater.** Don't add accessibility features that don't serve a real user need (e.g., sonification of the profile chart, haptic feedback for navigation). Focus on making the real workflows work with assistive technology.
```

**What would you like to do?**

- **[A]** Advanced Elicitation ‚Äî refine the responsive/accessibility strategy
- **[P]** Party Mode ‚Äî bring different perspectives on inclusive design
- **[C]** Continue ‚Äî Save this to the document and complete the workflow

### üßë Human (12:18:45)

c

### ü§ñ Assistant (12:19:13)

Content saved. Loading the final step.

### ü§ñ Assistant (12:19:22)

Now let me check for the help file for next steps guidance.

### ü§ñ Assistant (12:19:48)

**UX Design Complete, Michael!**

We've collaboratively built a comprehensive UX design specification for Peach. Here's what we accomplished:

- Executive summary, target users, and design challenges
- Core experience definition with the "disappearing UI" and "ears > fingers > eyes" principles
- Emotional response design with the "silence is feedback" and "the app has no opinion about you" principles
- UX pattern analysis (InTune as negative reference, metronome/meditation apps as positive patterns)
- Design system: Stock SwiftUI, HIG as gospel, no customization
- Defining experience mechanics with the full comparison loop timing and navigation-as-stop model
- Visual foundation: all system defaults
- User journey flows with Mermaid diagrams for all 5 journeys
- Component strategy with specs for the 3 custom components (profile visualization, profile preview, feedback indicator)
- UX consistency patterns covering feedback, forms, navigation, empty/loading/error states
- Responsive design and accessibility strategy with the sensory hierarchy as an accessibility feature

**The complete specification is at:** `docs/planning-artifacts/ux-design-specification.md`

Along the way, we also updated the PRD, glossary, and architecture documents to reflect design decisions (removing Stop Button, adding Info Screen, fixing the "test-anxiety" framing, adding navigation model changes).

---

**Recommended next steps** (run each in a fresh context window):

1. **Create Epics and Stories** (required) ‚Äî `/bmad-bmm-create-epics-and-stories`
   John, the Product Manager, will break down the PRD, UX spec, and architecture into implementable epics and stories.

2. **Check Implementation Readiness** (required) ‚Äî `/bmad-bmm-check-implementation-readiness`
   Winston, the Architect, will verify that PRD, UX, architecture, and epics/stories are aligned and ready for development.

**Optional quality checks before moving forward:**
- **Adversarial Review** ‚Äî `/bmad-review-adversarial-general` ‚Äî Critical review of the UX spec to find gaps or weaknesses
- **Validate PRD** ‚Äî `/bmad-bmm-validate-prd` ‚Äî Verify the PRD is comprehensive after our updates

### üßë Human (12:20:28)

Commit everything with a meaningful message.

### ü§ñ Assistant (12:21:14)

Committed successfully. 4 files changed, 1450 insertions ‚Äî clean working tree. The commit is on `main`, one ahead of origin (not pushed).

---

[‚Üê Previous (a14387c1ee)](a14387c1ee.md) | [Index](index.md) | [Next (7bb2a2e9e8) ‚Üí](7bb2a2e9e8.md)
