---
commit: "4f4e10c795f2ab0c3d07352fe495034b003f5532"
date: "2026-02-17T10:03:04+01:00"
author: "Michael SchÃ¼rig <michael@schuerig.de>"
subject: "Lower min cent difference to 0.1, document seamless playback concern"
sessions: ["f43bf0a1-015b-4d56-836b-dda1d374479c"]
prev: "777304f439.md"
next: "afa5dccda9.md"
---

[â† Previous (777304f439)](777304f439.md) | [Index](index.md) | [Next (afa5dccda9) â†’](afa5dccda9.md)

# Commit 4f4e10c795

**Date:** 2026-02-17 10:03:04 UTC+01:00  
**Author:** Michael SchÃ¼rig <michael@schuerig.de>

## Commit message

Lower min cent difference to 0.1, document seamless playback concern

Lower the default minCentDifference from 1.0 to 0.1 cents to remove
the artificial floor on difficulty convergence.

Add future-work note to investigate whether seamless (gapless) tone
playback makes pitch comparison perceptually easier than gap-separated
tones, which could explain why Peach achieves finer discrimination
than comparable apps like InTune.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>

## Changed files

```
Peach/Core/Algorithm/NextNoteStrategy.swift  |  8 ++++----
 docs/implementation-artifacts/future-work.md | 27 +++++++++++++++++++++++++++
 2 files changed, 31 insertions(+), 4 deletions(-)
```

## Session `f43bf0a1â€¦`

*2026-02-17 08:28:22 UTC â†’ 2026-02-17 09:03:18 UTC*

### ğŸ§‘ Human (08:28:22)

<command-message>bmad-party-mode</command-message>
<command-name>/bmad-party-mode</command-name>
<command-args>The last changes have been an improvement, but they are still far from perfect. Now the algorithm quickly increases the difficulty, but even though I only give correct answers, the cent difference jumps around in the range from 9 to 22 cents. It never goes below 9 cents. For my personal training at my current level, the interesting training range is from 3 to 10 cents. So, with the algorithm as it is, I never get there.</command-args>

### ğŸ¤– Assistant (08:29:58)

Let me read the key algorithm files to give the agents informed context.

### ğŸ¤– Assistant (08:31:01)

ğŸ‰ **PARTY MODE ACTIVATED!** ğŸ‰

Welcome Michael! All BMAD agents are here and ready for a dynamic group discussion. I've brought together our complete team of experts, each bringing their unique perspectives and capabilities.

For your algorithm convergence challenge, I've invited the most relevant minds to the table:

- ğŸ—ï¸ **Winston** (Architect) â€” Calm, pragmatic system design thinker
- ğŸ’» **Amelia** (Developer) â€” Ultra-precise, code-level analysis
- ğŸ”¬ **Dr. Quinn** (Creative Problem Solver) â€” Root cause detective

Let's dive right in with your topic â€” the difficulty algorithm converging too slowly and never reaching the 3-10 cent range.

---

ğŸ”¬ **Dr. Quinn**: AHA! I've examined the crime scene â€” your `AdaptiveNoteStrategy.swift` â€” and the root cause is beautifully clear. You don't have *one* convergence problem. You have *two* conspiring together.

**Root Cause #1: Note scattering defeats per-note convergence.** The algorithm randomly selects notes from a 25-note range (Â±12 semitones). Each MIDI note tracks its *own* difficulty. So while note 60 might converge to 9 cents after 3 correct answers, the algorithm then picks note 65 â€” untrained, bootstrapped at maybe 20 cents from neighbors â€” and you're back up. You keep getting served *different* notes that haven't individually converged yet.

**Root Cause #2: The Kazez formula has diminishing returns at low values.** Look at the math: `N = P Ã— (1 - 0.08 Ã— âˆšP)`. At P=9 cents, the reduction factor is `0.08 Ã— âˆš9 = 0.24`, so N = `9 Ã— 0.76 = 6.84`. That's a single step from 9 to 6.8. But you only get that step if the *same note* is picked again â€” and with 25+ notes in rotation, that could take many rounds.

The real culprit? You're watching a *portfolio* of 25 independent convergence curves, each advancing one step at a time, while only one note gets picked per round.

---

ğŸ—ï¸ **Winston**: Dr. Quinn has identified the structural issue precisely. Let me frame what this means architecturally.

The current design couples two independent concerns:
1. **Note selection** (which note to train next)
2. **Difficulty tracking** (how hard that note's comparison should be)

These two systems are fighting each other. Note selection wants variety â€” it spreads training across the range to build broad perception. But difficulty tracking needs *repetition on the same note* to converge. The result: the user perceives a system that "jumps around" because they're seeing the difficulty of *whichever note happens to be drawn*, not a steady convergence curve.

The question is: should we decouple these? Or change how one feeds the other? I see three architectural approaches:

1. **Global difficulty with per-note refinement** â€” track a *global* difficulty that converges consistently, and use per-note data only for fine adjustments
2. **Sticky note selection** â€” once a note starts converging, keep training it until it reaches a threshold before moving on
3. **Shared convergence propagation** â€” when one note converges, immediately propagate that difficulty to untrained neighbors

Each has trade-offs. As Winston says: what ships matters more than what's theoretically elegant.

---

ğŸ’» **Amelia**: `AdaptiveNoteStrategy.swift:210-213`. The issue is right here:

```swift
let p = stats.currentDifficulty != DifficultyParameters.defaultDifficulty
    ? stats.currentDifficulty
    : weightedEffectiveDifficulty(...)
```

New note â†’ `weightedEffectiveDifficulty` â†’ neighbors at 9-20 cents â†’ weighted average ~15 â†’ Kazez step â†’ 10.6. Stored. Next visit: 10.6 â†’ 7.8. But that's 2 visits to *one* note out of 25+.

Winston's option 1 â€” global difficulty â€” is simplest. One variable tracks convergence. All notes use it. Per-note offsets optional. `TrainingSession` already has state access. Minimal diff.

---

ğŸ”¬ **Dr. Quinn**: I want to build on what Winston and Amelia are pointing at. The *simplest* fix that preserves the existing architecture: **use the last comparison's actual cent difference as `p` instead of the target note's stored difficulty**. This is actually closer to what `KazezNoteStrategy` does at line 58:

```swift
let p = last.comparison.centDifference
```

The *original* Kazez strategy uses the previous comparison's cent difference â€” a single chain of values that converges smoothly regardless of which note is picked. The `AdaptiveNoteStrategy` replaced this with per-note stored difficulty, which introduced the scattering problem.

A hybrid approach: maintain per-note tracking for weak spot identification, but for the *actual difficulty presented to the user*, track a **single converging chain** â€” the Kazez value from the last comparison. This preserves the adaptive note selection while giving the user a smooth, continuously narrowing experience.

---

ğŸ—ï¸ **Winston**: That's the elegant middle ground. Let me be specific about what this looks like:

- **Keep** per-note `currentDifficulty` for weak spot analysis and profile data
- **Add** a single `sessionDifficulty` that follows the Kazez chain from `lastComparison.centDifference`
- **Use** `sessionDifficulty` as the actual cent difference presented to the user
- **Update** the per-note `currentDifficulty` to match, so the profile data stays useful

This means: correct answer â†’ difficulty drops from whatever it was â†’ next comparison (regardless of note) uses the lower value. The user sees a smooth convergence curve: 100 â†’ 20 â†’ 12.8 â†’ 9.1 â†’ 6.9 â†’ 5.5 â†’ 4.5 â†’ 3.8. You'd hit the 3-10 cent range within about 5-7 correct answers.

---

ğŸ’» **Amelia**: Clean approach. `determineCentDifference` change is ~5 lines. Still update per-note difficulty for profile tracking. `lastComparison?.comparison.centDifference` is already available at call site. AC met: smooth convergence, 3-10 cent range reachable.

---

**Michael, the team converges on a clear diagnosis and solution.** The core issue: per-note difficulty tracking causes the cent difference to scatter as the algorithm jumps between notes. The fix: use the previous comparison's actual cent difference as the Kazez input (like the original `KazezNoteStrategy` does), so the user sees a single smooth convergence chain regardless of which note is selected.

**Dr. Quinn asks: Does this diagnosis match what you're experiencing â€” seeing the difficulty bounce when the algorithm switches notes? And does the "single converging chain" approach sound right for your training goals?**

_[Awaiting your response...]_

`[E] Exit Party Mode - End the collaborative session`

### ğŸ§‘ Human (08:38:02)

Ok, let's give it a try.

### ğŸ¤– Assistant (08:38:12)

Clean working tree. Let me read the test file to understand the existing test expectations before making the change.

### ğŸ¤– Assistant (08:39:42)

The change is straightforward â€” use the last comparison's actual cent difference as the Kazez input instead of per-note stored difficulty. This creates a single smooth convergence chain.

### ğŸ¤– Assistant (08:40:27)

Also update the class-level doc comment to reflect the new design.

### ğŸ¤– Assistant (08:40:34)

Those are just SourceKit indexing warnings, not real errors. Now let me run the full test suite as required.

### ğŸ¤– Assistant (08:43:41)

**TEST SUCCEEDED** â€” all tests pass. Now let me commit this change.

### ğŸ¤– Assistant (08:44:02)

Done. Let me bring the agents back to wrap up.

---

ğŸ”¬ **Dr. Quinn**: AHA! The fix is in. Let me summarize what changed and what you should experience now:

**The diagnosis was confirmed:** per-note difficulty tracking caused the algorithm to "reset" whenever it picked a different MIDI note, bouncing you between 9-22 cents endlessly.

**The fix:** `AdaptiveNoteStrategy.swift:210` â€” the Kazez formula now uses the *previous comparison's actual cent difference* as input, not the per-note stored difficulty. This creates a single converging chain:

| Correct answers | Cent difference |
|:-:|:-:|
| 0 | 100.0 |
| 1 | 20.0 |
| 2 | 12.8 |
| 3 | 9.1 |
| 4 | **6.9** |
| 5 | **5.5** |
| 6 | **4.5** |
| 7 | **3.8** |

You should now reach your 3-10 cent training range within 4-7 correct answers, regardless of which notes the algorithm selects.

---

ğŸ—ï¸ **Winston**: Clean architectural change. Per-note difficulty is still updated for profile tracking and weak spot analysis â€” that data isn't lost. The bootstrap path (first comparison in a session) is unchanged. All 90+ tests pass. Minimal diff, maximum impact.

---

ğŸ’» **Amelia**: 1 file changed. 14 insertions, 13 deletions. All tests green. Ship it.

---

Give it a try and let me know how the convergence feels now!

`[E] Exit Party Mode - End the collaborative session`

### ğŸ§‘ Human (08:59:11)

Ok, that seems to have worked well. I have one concern: When using the app now, I got down to consistently identify differences below 2 cents. That seems too good to be true for my ability, compared to what I can achieve in InTune. There I have achieved below 3 cents just a couple of times in hundreds of training sessions. Usually, I only get to around 5 cents. So, in effect, I'm a bit suspicious about this. I have an idea that the seemless playing of the two notes we're using makes the comparison easier. Please add a note to investigate this further in the future. Also, change the lower bound for the difficulty from 1.0 to 0.1.

Any comments?

### ğŸ¤– Assistant (08:59:26)

Now let me make both changes. First, the min cent difference, then the investigation note.

### ğŸ¤– Assistant (08:59:39)

Now let me check which tests explicitly assert against the 1.0 floor to see if any need updating.

### ğŸ¤– Assistant (08:59:48)

Good â€” all those tests explicitly pass `minCentDifference: 1.0`, so they won't be affected by the default change. Now let me add the investigation note to future-work.md.

### ğŸ¤– Assistant (09:00:01)

Now let me run the full test suite.

### ğŸ¤– Assistant (09:03:00)

All tests pass. Let me commit.

### ğŸ¤– Assistant (09:03:18)

Both changes committed. Now for the agents' commentary:

---

ğŸ”¬ **Dr. Quinn**: Your suspicion has excellent scientific basis. This is a well-documented psychoacoustic phenomenon. The **inter-stimulus interval (ISI)** â€” the gap between two tones â€” has a significant effect on pitch discrimination thresholds. When tones are played back-to-back (zero ISI), the auditory system can compare them using **sensory memory** with minimal decay. Add even a 500ms gap, and the task shifts toward **working memory** comparison, which is measurably harder. Literature from Micheyl et al. and others shows discrimination thresholds can degrade by a factor of 2-3x with moderate gaps.

So sub-2-cent performance with seamless playback and ~5-cent with gaps (InTune) is *entirely consistent* with the psychoacoustics. You're not fooling yourself â€” you're measuring a different cognitive task.

---

ğŸ—ï¸ **Winston**: Good instinct to document this rather than act on it prematurely. The investigation note captures the hypothesis, impact, and research directions. When you're ready to explore it, the cleanest approach would be a configurable ISI parameter in `TrainingSettings` â€” you could then A/B test yourself at different gap durations and see exactly where your threshold shifts.

The floor change from 1.0 to 0.1 is sensible â€” removes an arbitrary limit and lets the algorithm find your actual threshold, whatever that turns out to be.

---

ğŸ’» **Amelia**: 2 files, 31 insertions. All tests green. Floor lowered, concern documented. Clean.

---

`[E] Exit Party Mode - End the collaborative session`

---

[â† Previous (777304f439)](777304f439.md) | [Index](index.md) | [Next (afa5dccda9) â†’](afa5dccda9.md)
