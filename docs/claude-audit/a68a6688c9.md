---
commit: "a68a6688c989c062a5f00151c89b003d47406a69"
date: "2026-02-21T14:52:30+01:00"
author: "Michael Sch√ºrig <michael@schuerig.de>"
subject: "Generate project-context.md and slim down CLAUDE.md"
sessions: ["83a661aa-fe37-45d1-9062-78010ec876db"]
prev: "49010d9468.md"
next: "90d2b88768.md"
---

[‚Üê Previous (49010d9468)](49010d9468.md) | [Index](index.md) | [Next (90d2b88768) ‚Üí](90d2b88768.md)

# Commit a68a6688c9

**Date:** 2026-02-21 14:52:30 UTC+01:00  
**Author:** Michael Sch√ºrig <michael@schuerig.de>

## Commit message

Generate project-context.md and slim down CLAUDE.md

Create comprehensive AI agent project context with 85 rules across
7 sections (technology stack, language rules, framework patterns,
testing, code quality, workflow, critical don't-miss rules).
Consolidate all implementation rules into project-context.md as
single source of truth. Trim CLAUDE.md to a pointer plus
Claude-Code-specific tool scripts rule.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>

## Changed files

```
CLAUDE.md               |  14 +--
 docs/project-context.md | 242 ++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 244 insertions(+), 12 deletions(-)
```

## Session `83a661aa‚Ä¶`

*2026-02-21 13:11:02 UTC ‚Üí 2026-02-21 13:52:34 UTC*

### üßë Human (13:11:02)

<command-message>bmad-bmm-generate-project-context</command-message>
<command-name>/bmad-bmm-generate-project-context</command-name>

### ü§ñ Assistant (13:11:23)

Let me start the discovery process by analyzing the project.

### ü§ñ Assistant (13:13:35)

Good, I've now completed the full discovery phase. The existing `project-context.md` at `_bmad-output/` is essentially empty (just a blank line). Let me present the discovery summary.

---

Welcome Michael! I've analyzed your **Peach** project to discover the context that AI agents need.

**Technology Stack Discovered:**
- Swift 6.0 with strict concurrency (Xcode 26, iOS 26.0 deployment target)
- SwiftUI (100% declarative UI, no UIKit views)
- SwiftData for persistence (`ComparisonRecord` @Model)
- AVAudioEngine + AVAudioPlayerNode for real-time sine wave synthesis
- Swift Testing framework (`@Test`, `@Suite`, `#expect()`)
- @Observable (modern observation, not ObservableObject)
- @AppStorage for user settings (UserDefaults)
- String Catalogs for localization (English + German)
- Zero third-party dependencies

**Existing Patterns Found:**
- 12+ implementation patterns (protocol-based DI, observer pattern, state machine, Welford's algorithm, Kazez convergence, environment key injection, etc.)
- 8 coding conventions (PascalCase types, camelCase properties, Screen/View suffixes, Mock prefixes, feature-based organization)
- 15+ critical rules (MainActor isolation, thin views, typed error enums, no ObservableObject, etc.)

**Key Areas for Context Rules:**
- Swift concurrency & @MainActor isolation patterns
- Protocol-based dependency injection and mock testing
- State machine architecture (TrainingSession)
- Observer pattern for decoupled notifications
- SwiftUI view patterns (@Observable, environment injection, thin views)
- Testing conventions (Swift Testing, mock patterns, fixture helpers)

**Existing Context:** Found a previous `project-context.md` at `_bmad-output/` but it is empty. I also noted the `CLAUDE.md` which contains workflow rules (full test suite before commits, tool scripts in `tools/`, git workflow conventions) ‚Äî these will be incorporated into the project context.

**CLAUDE.md rules to incorporate:**
- Always run full test suite before committing: `xcodebuild test -scheme Peach -destination 'platform=iOS Simulator,name=iPhone 17'`
- Never run only specific test files
- Tool scripts go in `tools/` directory, not inline
- Commit after each meaningful task; descriptive messages referencing story/task context
- No pushing to remote unless explicitly asked

Ready to create your project context. This will help AI agents implement code consistently with your project's standards.

**[C] Continue to context generation**

### üßë Human (13:16:50)

c

### ü§ñ Assistant (13:16:59)

Let me initialize the project context file and start generating rules category by category.

### ü§ñ Assistant (13:18:00)

Now let's work through the categories. Starting with **Category 1: Technology Stack & Versions**.

I found your technology stack:

**Core Technologies:**
- Swift 6.0 with strict concurrency ‚Äî Xcode 26.3, iOS 26.0 deployment target
- SwiftUI (latest iteration, declarative lifecycle)
- SwiftData (persistence, SQLite-backed)
- AVAudioEngine + AVAudioPlayerNode (real-time audio synthesis)
- Swift Testing framework (`@Test`, `@Suite`, `#expect()`)
- Swift Package Manager (zero third-party dependencies)

**Key Dependencies:**
- None ‚Äî fully first-party Apple stack, zero external packages

**Here's what I'll add to the project context:**

```markdown
## Technology Stack & Versions

- **Swift 6.0** with strict concurrency checking enabled (Xcode 26.3)
- **iOS 26.0** deployment target ‚Äî no backward compatibility, use latest APIs freely
- **SwiftUI** ‚Äî declarative UI, SwiftUI lifecycle (@main App), no UIKit views
- **SwiftData** ‚Äî persistence layer (SQLite-backed), `@Model` for entities
- **AVAudioEngine** + `AVAudioPlayerNode` ‚Äî real-time sine wave synthesis, sub-10ms latency
- **Swift Testing** ‚Äî `@Test`, `@Suite`, `#expect()` for all unit tests (NOT XCTest)
- **@Observable** macro ‚Äî modern observation (NOT `ObservableObject`/`@Published`)
- **@AppStorage** ‚Äî user preferences via UserDefaults
- **String Catalogs** ‚Äî localization (English + German)
- **Zero third-party dependencies** ‚Äî entirely first-party Apple frameworks
- **Universal app** ‚Äî iPhone + iPad, portrait + landscape
```

Are there any version constraints or compatibility notes agents should know about?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to next category

### üßë Human (13:18:22)

P

### ü§ñ Assistant (13:19:07)

Party Mode activated! Let me bring in the right agents to review the Technology Stack & Versions section from multiple implementation perspectives.

---

üèóÔ∏è **Winston (Architect):** The stack listing is accurate, but I see an opportunity to make it more *useful* for agents. Right now it reads like a shopping list. What agents actually need are the **constraints** ‚Äî things they might otherwise assume wrong. For instance:

- "Swift 6.0 with strict concurrency" ‚Äî good, but agents need to know this means **`@MainActor` isolation is required on all UI-facing types and `Sendable` conformance is enforced at compile time**. That's the rule that trips up every agent.
- "SwiftData" is listed but agents need the critical detail: **`TrainingDataStore` is the sole accessor** ‚Äî no other component should create `ModelContext` instances or query SwiftData directly.
- I'd also add: **No UIKit** isn't just a preference ‚Äî it's a hard rule. If an agent needs haptic feedback, they use `UIImpactFeedbackGenerator` through the existing `HapticFeedback` protocol, not by importing UIKit into views.

The version numbers are correct. I'd trim the "zero third-party dependencies" line ‚Äî that's discoverable. Instead, add the constraint that **new third-party dependencies must not be added without explicit approval**.

---

üíª **Amelia (Dev):** `Core/Audio/FrequencyCalculation.swift` ‚Äî agents need to know that MIDI-to-Hz conversion already exists. Also: `AVAudioEngine` setup lives in `SineWaveNotePlayer` ‚Äî agents should never instantiate a second engine. One engine, one player, injected at app startup via `PeachApp.swift`.

Stack list should mention: **`@Observable` not `ObservableObject`** ‚Äî yes it's there, but it's the single most common mistake agents make. Elevate it. Bold it. Repeat it. `@Observable` + `@Environment` for injection. Period.

Also missing: **`@AppStorage` keys are centralized in `SettingsKeys.swift`** ‚Äî agents must use existing keys, not create new string literals.

---

üß™ **Murat (Test Architect):** From a testing perspective, the stack section should explicitly call out: **Swift Testing, not XCTest**. Agents default to XCTest patterns ‚Äî `XCTAssertEqual`, `setUp/tearDown`, `XCTestCase` subclasses. All wrong for this project. The correct patterns are `@Test`, `@Suite`, `#expect()`, and struct-based test suites.

Also critical: **all mocks are `@MainActor` isolated** because the services they mock are. An agent that forgets this will hit concurrency errors immediately.

I'd propose this refined version:

```markdown
## Technology Stack & Versions

- **Swift 6.0** ‚Äî strict concurrency enforced; all UI-facing types require `@MainActor`; `Sendable` checked at compile time
- **iOS 26.0** deployment target ‚Äî use latest APIs freely, no backward compatibility
- **SwiftUI** ‚Äî declarative UI with SwiftUI lifecycle; **no UIKit in views** (UIKit only through protocol abstractions like `HapticFeedback`)
- **SwiftData** ‚Äî `@Model` for persistence; **only `TrainingDataStore` accesses SwiftData** ‚Äî no direct `ModelContext` usage elsewhere
- **AVAudioEngine** ‚Äî single engine instance in `SineWaveNotePlayer`, created at app startup; never instantiate a second engine
- **Swift Testing** ‚Äî `@Test`, `@Suite`, `#expect()` for all tests; **never use XCTest** (`XCTAssertEqual`, `XCTestCase`, `setUp/tearDown` are all wrong)
- **@Observable** ‚Äî modern observation macro; **never use `ObservableObject`/`@Published`**
- **@AppStorage** ‚Äî user preferences; keys centralized in `SettingsKeys.swift`
- **String Catalogs** ‚Äî English + German localization via `Localizable.xcstrings`
- **Zero third-party dependencies** ‚Äî do not add external packages without explicit approval
- **Universal app** ‚Äî iPhone + iPad, portrait + landscape
```

---

üèóÔ∏è **Winston:** Murat's version is substantially better. Every line now carries an implementation constraint, not just a technology name. That's what agents need ‚Äî the "don't do this" alongside the "use this."

üíª **Amelia:** `+1`. Ship it.

---

Michael, the agents have proposed a refined version that shifts from a technology *list* to technology *constraints*. Each bullet now tells agents not just what to use, but what to avoid.

Accept these enhanced rules for the Technology Stack & Versions category? (y/n)

### üßë Human (13:23:06)

y

### ü§ñ Assistant (13:23:30)

Technology Stack saved. Moving to **Category 2: Language-Specific Rules** (Swift).

Based on your codebase, I found these Swift-specific patterns that agents need to follow:

**Here's what I'll add:**

```markdown
### Language-Specific Rules (Swift 6)

- **`@MainActor` on all service classes** ‚Äî `TrainingSession`, `PerceptualProfile`, `TrendAnalyzer`, and all mock implementations must be `@MainActor` isolated
- **`async/await` for all asynchronous work** ‚Äî no completion handlers, no Combine; use structured concurrency with `Task` and `withCheckedThrowingContinuation` for bridging callbacks
- **Task cancellation** ‚Äî long-running operations (audio playback sequences) must check for cancellation and clean up gracefully; used for headphone disconnect and app backgrounding
- **Typed error enums per service** ‚Äî each service defines its own `enum XError: Error` (e.g., `AudioError`, `DataStoreError`); errors are specific (`AudioError.engineStartFailed`, not `.failed`)
- **Protocol-first design** ‚Äî define a protocol for any new service before the implementation; protocols enable test mocking without third-party frameworks
- **Value types by default** ‚Äî use `struct` for data carriers (`Comparison`, `TrainingSettings`); `class` only when reference semantics or `@Observable` is needed
- **No force unwrapping** ‚Äî never use `!` except for `@IBOutlet` (which shouldn't exist in this project anyway)
- **`final class`** ‚Äî mark classes `final` unless inheritance is explicitly needed
```

Any Swift-specific rules I'm missing that agents should know about?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to next category

### üßë Human (13:23:57)

c

### ü§ñ Assistant (13:24:22)

Language-Specific Rules saved. Moving to **Category 3: Framework-Specific Rules** (SwiftUI + SwiftData + AVAudioEngine).

**Here's what I'll add:**

```markdown
### Framework-Specific Rules

**SwiftUI Views:**
- **Views are thin** ‚Äî observe state, render, send actions; no business logic in views
- **`@Environment` for dependency injection** ‚Äî services injected via custom environment keys (e.g., `@Environment(\.trainingSession)`), not passed as init parameters
- **Extract subviews at ~40 lines** ‚Äî when a view body exceeds ~40 lines, extract child views
- **Responsive layout** ‚Äî detect `@Environment(\.verticalSizeClass)` for compact/regular height; extract layout parameters to `static` methods for testability
- **No navigation logic in views** ‚Äî use `NavigationDestination` enum for type-safe routing

**SwiftData:**
- **`TrainingDataStore` is the sole data accessor** ‚Äî all CRUD goes through this single service
- **`ComparisonRecord` is the only `@Model`** ‚Äî flat structure with explicit fields: `note1`, `note2`, `note2CentOffset`, `isCorrect`, `timestamp`
- **`ModelContainer` initialized once in `PeachApp.swift`** ‚Äî passed via SwiftUI environment, never created elsewhere

**AVAudioEngine:**
- **Single `SineWaveNotePlayer` instance** ‚Äî created at app startup, injected everywhere
- **Protocol boundary: `NotePlayer`** ‚Äî knows only frequencies (Hz), durations, and envelopes; has no concept of MIDI notes, comparisons, or training
- **MIDI-to-Hz conversion** ‚Äî use existing `FrequencyCalculation.swift`, never reimplement
- **Audio interruption handling** ‚Äî `SineWaveNotePlayer` reports interruptions; `TrainingSession` discards the current comparison

**State Management:**
- **`TrainingSession` is the central state machine** ‚Äî states: `idle` ‚Üí `playingNote1` ‚Üí `playingNote2` ‚Üí `awaitingAnswer` ‚Üí `showingFeedback` ‚Üí (loop)
- **Observer pattern for decoupled notifications** ‚Äî `ComparisonObserver` protocol; observers: `TrainingDataStore`, `PerceptualProfile`, `HapticFeedbackManager`, `TrendAnalyzer`
- **Settings read live** ‚Äî `TrainingSession` reads `@AppStorage` on each comparison, not cached
```

Any framework-specific rules I'm missing?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to next category

### üßë Human (13:24:55)

P

### ü§ñ Assistant (13:25:36)

Bringing in the agents to review the Framework-Specific Rules.

---

üèóÔ∏è **Winston:** Solid coverage. Three observations:

First, the **dependency injection section** needs sharpening. Right now it says "`@Environment` for dependency injection" but doesn't explain the actual mechanism. Agents need to know there are **custom `EnvironmentKey` types** ‚Äî e.g., `TrainingSessionKey` ‚Äî with a default value pattern. When adding a new injectable service, agents must create a new `EnvironmentKey` struct, extend `EnvironmentValues`, and wire it in `PeachApp.swift`. That's a multi-step pattern agents will get wrong if they just see "@Environment."

Second, the **`TrainingSession` state machine** description is good, but the critical rule is that **state transitions are guarded** ‚Äî you can't jump from `idle` to `awaitingAnswer`. Each transition has preconditions. Agents adding new states or transitions must respect the existing guards.

Third, I'd add an **architectural boundary** rule: **Views never call services directly** ‚Äî they interact only with `TrainingSession` and read `PerceptualProfile`. A view should never import or reference `NotePlayer`, `NextNoteStrategy`, or `TrainingDataStore`.

---

üíª **Amelia:** Winston's right on the environment keys. Let me be specific ‚Äî the actual file pattern:

```swift
// In the service file or a dedicated key file:
private struct TrainingSessionKey: EnvironmentKey {
    static let defaultValue: TrainingSession = ... 
}
extension EnvironmentValues {
    var trainingSession: TrainingSession { ... }
}
```

Agents must follow this exact pattern. I've seen agents try `@EnvironmentObject` ‚Äî that's the old way and won't work with `@Observable`.

One more thing missing: **`PeachApp.swift` is the composition root**. All service wiring happens there. Agents must not create service instances anywhere else. If a new service is needed, it gets instantiated in `PeachApp.swift` and injected via environment. That's the single source of truth for the dependency graph.

Also on SwiftData ‚Äî the rule says `ComparisonRecord` is the only `@Model`, but agents need to know: **if a new model is needed, it must be registered in the `ModelContainer` schema in `PeachApp.swift`**. Missing that step causes silent data loss.

---

üß™ **Murat:** Framework rules have testing implications that agents will miss:

The **observer pattern** rule is incomplete without the testing angle. When an agent adds a new `ComparisonObserver`, they need to know: **observers are injected as an array into `TrainingSession`** ‚Äî `observers: [ComparisonObserver]`. In tests, you pass only the mock observers you need. Agents must never hardcode observer lists inside `TrainingSession`.

On the state machine: **tests use a `waitForState` helper** to assert state transitions asynchronously. Agents writing new state-related tests must use this pattern, not poll or sleep.

On responsive layout: the `static` method extraction for layout parameters isn't just a style preference ‚Äî **it exists specifically so layout logic can be unit tested without instantiating views**. Agents must continue this pattern for any new layout calculations.

I'd propose restructuring slightly ‚Äî group the "what agents must do when adding new things" together:

```markdown
**When Adding New Components:**
- New injectable service ‚Üí create `EnvironmentKey`, extend `EnvironmentValues`, wire in `PeachApp.swift`
- New `ComparisonObserver` ‚Üí add to observer array in `PeachApp.swift`; inject only needed mocks in tests
- New SwiftData `@Model` ‚Üí register in `ModelContainer` schema in `PeachApp.swift`
- New layout logic ‚Üí extract to `static` methods for unit testability
- New state transitions ‚Üí respect existing guards in `TrainingSession`; use `waitForState` helper in tests
```

That's the stuff agents actually mess up. The rest they can figure out from context.

---

üèóÔ∏è **Winston:** Murat's "When Adding New Components" block is excellent. That's the highest-value addition ‚Äî it's a checklist agents can follow mechanically. I'd keep the existing framework rules as-is and append that block.

üíª **Amelia:** Agreed. Also add the view boundary rule Winston mentioned ‚Äî `Views never import or reference NotePlayer, NextNoteStrategy, or TrainingDataStore`. That's a hard architectural line.

---

Michael, the agents propose two enhancements:

1. **Sharpen existing rules** ‚Äî add `PeachApp.swift` as composition root, views never reference internal services, `@EnvironmentObject` is wrong
2. **Add a "When Adding New Components" checklist** ‚Äî the mechanical steps agents must follow when extending the codebase

Here's the refined version:

```markdown
### Framework-Specific Rules

**SwiftUI Views:**
- **Views are thin** ‚Äî observe state, render, send actions; no business logic in views
- **Views only interact with `TrainingSession` and `PerceptualProfile`** ‚Äî never import or reference `NotePlayer`, `NextNoteStrategy`, or `TrainingDataStore` from views
- **`@Environment` for dependency injection** ‚Äî custom `EnvironmentKey` types (e.g., `TrainingSessionKey`); **never use `@EnvironmentObject`** (incompatible with `@Observable`)
- **Extract subviews at ~40 lines** ‚Äî when a view body exceeds ~40 lines, extract child views
- **Responsive layout** ‚Äî detect `@Environment(\.verticalSizeClass)` for compact/regular; extract layout parameters to `static` methods for unit testability
- **`NavigationDestination` enum** for type-safe routing ‚Äî no string-based navigation

**SwiftData:**
- **`TrainingDataStore` is the sole data accessor** ‚Äî all CRUD goes through this single service
- **`ComparisonRecord` is the only `@Model`** ‚Äî flat structure: `note1`, `note2`, `note2CentOffset`, `isCorrect`, `timestamp`
- **`ModelContainer` initialized once in `PeachApp.swift`** ‚Äî passed via SwiftUI environment; new models must be registered in the schema there

**AVAudioEngine:**
- **Single `SineWaveNotePlayer` instance** ‚Äî created at app startup, injected everywhere
- **Protocol boundary: `NotePlayer`** ‚Äî knows only frequencies (Hz), durations, envelopes; no concept of MIDI notes, comparisons, or training
- **MIDI-to-Hz conversion** ‚Äî use existing `FrequencyCalculation.swift`, never reimplement
- **Audio interruption handling** ‚Äî `SineWaveNotePlayer` reports interruptions; `TrainingSession` discards current comparison

**State Management:**
- **`TrainingSession` is the central state machine** ‚Äî `idle` ‚Üí `playingNote1` ‚Üí `playingNote2` ‚Üí `awaitingAnswer` ‚Üí `showingFeedback` ‚Üí (loop)
- **State transitions are guarded** ‚Äî preconditions enforced; never skip states
- **Observer pattern** ‚Äî `ComparisonObserver` protocol; observers injected as array into `TrainingSession`
- **Settings read live** ‚Äî `TrainingSession` reads `@AppStorage` on each comparison, not cached

**Composition Root (`PeachApp.swift`):**
- **All service instantiation happens in `PeachApp.swift`** ‚Äî this is the single dependency graph source of truth
- **Never create service instances elsewhere** ‚Äî new services get wired here and injected via environment

**When Adding New Components:**
- New injectable service ‚Üí create `EnvironmentKey`, extend `EnvironmentValues`, wire in `PeachApp.swift`
- New `ComparisonObserver` ‚Üí add to observer array in `PeachApp.swift`; inject only needed mocks in tests
- New SwiftData `@Model` ‚Üí register in `ModelContainer` schema in `PeachApp.swift`
- New layout logic ‚Üí extract to `static` methods for unit testability
- New state transitions ‚Üí respect existing guards in `TrainingSession`; use `waitForState` helper in tests
```

Accept these enhanced rules for Framework-Specific Rules? (y/n)

### üßë Human (13:26:47)

y

### ü§ñ Assistant (13:27:17)

Framework-Specific Rules saved. Moving to **Category 4: Testing Rules**.

**Here's what I'll add:**

```markdown
### Testing Rules

**Framework & Structure:**
- **Swift Testing only** ‚Äî `@Test("description")` for tests, `@Suite("name")` for grouping, `#expect()` for assertions
- **Struct-based test suites** ‚Äî not class-based; no `setUp`/`tearDown`; use factory methods like `makeTrainingSession()` for fixtures
- **All tests are `@MainActor`** ‚Äî because all services are `@MainActor` isolated
- **`async` tests** ‚Äî most tests are `async` to support the async service layer

**Test Organization:**
- **Mirror source structure** ‚Äî `PeachTests/Core/Audio/` mirrors `Peach/Core/Audio/`
- **One test file per source file** ‚Äî `SineWaveNotePlayer.swift` ‚Üí `SineWaveNotePlayerTests.swift`
- **Mock files live in test target** ‚Äî `MockNotePlayer.swift`, `MockTrainingDataStore.swift`, etc.

**Mock Patterns:**
- **Explicit mock classes conforming to protocols** ‚Äî no third-party mocking frameworks
- **Mocks track calls** ‚Äî `playCallCount`, `lastFrequency`, `playHistory` for verification
- **Mocks support error injection** ‚Äî `shouldThrowError`, `errorToThrow` properties
- **Mocks provide synchronous callbacks** ‚Äî `onPlayCalled`, `onStopCalled` for test coordination
- **`instantPlayback` mode** ‚Äî mocks skip timing delays for deterministic tests
- **Mocks have `reset()` method** ‚Äî for cleanup between test cases

**Test Helpers:**
- **`waitForState` helper** ‚Äî async helper for asserting `TrainingSession` state transitions; never poll or sleep
- **Factory methods** ‚Äî `makeTrainingSession(...)` returns configured session + mocks for each test
- **Layout tests use `static` methods** ‚Äî test layout logic directly without instantiating SwiftUI views

**Coverage:**
- **All new code requires tests** ‚Äî test-first development workflow
- **Run full suite before committing** ‚Äî `xcodebuild test -scheme Peach -destination 'platform=iOS Simulator,name=iPhone 17'`
- **Never run only specific test files** ‚Äî always run the complete test suite
```

Any testing rules I'm missing?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to next category

### üßë Human (13:28:12)

p

### ü§ñ Assistant (13:28:54)

Bringing in the testing-focused agents for this one.

---

üß™ **Murat (Test Architect):** This is my domain. The rules are solid but I see gaps that will cause agents to write broken tests on the first attempt.

**Missing critical rule: SwiftData testing.** Agents will try to use the production `ModelContainer` in tests. Wrong. Tests must create an **in-memory `ModelContainer`** with `ModelConfiguration(isStoredInMemoryOnly: true)`. This is the single most common SwiftData testing mistake. If it's not documented here, every agent will hit it.

Second: the mock patterns section lists what mocks *have* but not the **contract agents must follow when creating new mocks**. The rule is:
- Mock must conform to the same protocol as the production implementation
- Mock must be `@MainActor`
- Mock must track all method calls with counters and captured parameters
- Mock must support error injection via a `shouldThrowError` / `errorToThrow` pair
- Mock must provide synchronous callback hooks (`onXCalled`) that fire *before* any async delays

That's the template. Agents deviate from it and then tests become flaky.

Third: **test naming**. I see in the codebase that `@Test` descriptions are natural language ‚Äî `@Test("starts in idle state")`, `@Test("plays note 1 after starting")`. The rule should state: **test descriptions are behavioral, not implementation-focused** ‚Äî describe *what should happen*, not *what method is called*.

---

üíª **Amelia (Dev):** Murat nailed the SwiftData testing gap. Let me add one more: **`@Test` functions are free functions inside the `@Suite` struct, not methods on a class.** The naming pattern is:

```swift
@Suite("TrainingSession Tests")
struct TrainingSessionTests {
    @Test("description of behavior")
    @MainActor
    func behaviorBeingTested() async { }
}
```

Agents trained on XCTest will write `func testSomething()` with the `test` prefix. In Swift Testing, the `@Test` attribute is what marks it ‚Äî **the `test` prefix is unnecessary and inconsistent with the codebase**. Looking at the actual tests, function names describe the behavior directly: `func startsInIdleState()`, `func playsFirstNoteAfterStarting()`.

Also: the `makeTrainingSession` factory ‚Äî agents need to know it returns a **tuple** of the session plus all its mock dependencies. Pattern:

```swift
func makeTrainingSession() -> (session: TrainingSession, notePlayer: MockNotePlayer, ...) 
```

This lets each test access the specific mocks it needs for verification. Agents that don't follow this pattern end up with no way to verify mock interactions.

---

üß™ **Quinn (QA):** Practical angle here. Two things agents mess up immediately:

1. **Async test timing.** The `waitForState` helper exists because `TrainingSession` state changes happen asynchronously after audio playback completes. Agents will write `session.start()` followed immediately by `#expect(session.state == .playingNote1)` ‚Äî that assertion races against the async state change and fails intermittently. **Always `await waitForState`**.

2. **Test isolation.** Each `@Test` function gets a fresh `@Suite` struct instance ‚Äî that's automatic. But agents must **create fresh mocks in each test** via the factory method, not share mocks across tests. Swift Testing runs tests in parallel by default. Shared mutable state = flaky tests.

One more: **the full test suite command** from CLAUDE.md belongs in this section prominently. Agents must run `xcodebuild test -scheme Peach -destination 'platform=iOS Simulator,name=iPhone 17'` ‚Äî not Xcode's GUI, not a subset. It's already there but should be higher up, not buried under "Coverage."

---

üß™ **Murat:** Quinn's point about test parallelism is critical. Swift Testing runs tests concurrently by default. That's why `@MainActor` on every test function is non-negotiable ‚Äî without it, you get data races against the `@MainActor`-isolated services. Agents that forget `@MainActor` will see tests pass individually but fail when run together.

Let me propose the refined version:

```markdown
### Testing Rules

**Run the full suite before every commit:**
`xcodebuild test -scheme Peach -destination 'platform=iOS Simulator,name=iPhone 17'`
Never run only specific test files ‚Äî always the complete suite.

**Framework & Structure:**
- **Swift Testing only** ‚Äî `@Test("behavioral description")`, `@Suite("name")`, `#expect()`
- **Struct-based suites** ‚Äî no classes, no `setUp`/`tearDown`; use factory methods for fixtures
- **Every `@Test` function must be `@MainActor async`** ‚Äî Swift Testing runs tests in parallel; without `@MainActor`, data races against isolated services
- **No `test` prefix on function names** ‚Äî `@Test` attribute marks the test; name describes behavior: `func startsInIdleState()`, not `func testStartsInIdleState()`
- **Behavioral test descriptions** ‚Äî `@Test("plays note 1 after starting")`, not `@Test("test playNote1 method")`

**Test Organization:**
- **Mirror source structure** ‚Äî `PeachTests/Core/Audio/` mirrors `Peach/Core/Audio/`
- **One test file per source file** ‚Äî `SineWaveNotePlayer.swift` ‚Üí `SineWaveNotePlayerTests.swift`
- **Mock files live in test target** ‚Äî `MockNotePlayer.swift`, `MockTrainingDataStore.swift`, etc.
- **Fresh mocks per test** ‚Äî create via factory method in each test; never share mocks across tests (parallel execution)

**SwiftData in Tests:**
- **In-memory `ModelContainer`** ‚Äî tests must use `ModelConfiguration(isStoredInMemoryOnly: true)`; never use the production container

**Mock Contract (all new mocks must follow):**
- Conform to the same protocol as the production implementation
- `@MainActor` isolated
- Track all method calls with counters and captured parameters (`playCallCount`, `lastFrequency`, `playHistory`)
- Support error injection (`shouldThrowError`, `errorToThrow`)
- Provide synchronous callback hooks (`onPlayCalled`, `onStopCalled`) that fire before any async delays
- Include `instantPlayback` mode for deterministic timing
- Provide `reset()` method for cleanup

**Test Helpers:**
- **`waitForState` helper** ‚Äî async assertion for `TrainingSession` state transitions; **never use raw `#expect` immediately after an async action** ‚Äî the state change races
- **Factory methods return tuples** ‚Äî `makeTrainingSession() -> (session:, notePlayer:, strategy:, ...)` so each test accesses specific mocks for verification
- **Layout tests use `static` methods** ‚Äî test layout logic without instantiating SwiftUI views

**Coverage:**
- **All new code requires tests** ‚Äî test-first development workflow
```

---

Michael, the agents have significantly tightened the testing rules ‚Äî adding the SwiftData in-memory container rule, the mock contract template, parallel execution warnings, the `test` prefix prohibition, and the `waitForState` racing pattern.

Accept these enhanced rules for Testing Rules? (y/n)

### üßë Human (13:30:06)

In think I was a bit to quick with "Category 2: Language-Specific Rules". Can we go back there?

### ü§ñ Assistant (13:30:10)

Of course! Let me first save the Testing Rules as approved, then we'll revisit Language-Specific Rules.

### ü§ñ Assistant (13:30:17)

Here's the current **Language-Specific Rules (Swift 6)** section as it stands:

```markdown
### Language-Specific Rules (Swift 6)

- **`@MainActor` on all service classes** ‚Äî `TrainingSession`, `PerceptualProfile`, `TrendAnalyzer`, and all mock implementations must be `@MainActor` isolated
- **`async/await` for all asynchronous work** ‚Äî no completion handlers, no Combine; use structured concurrency with `Task` and `withCheckedThrowingContinuation` for bridging callbacks
- **Task cancellation** ‚Äî long-running operations (audio playback sequences) must check for cancellation and clean up gracefully; used for headphone disconnect and app backgrounding
- **Typed error enums per service** ‚Äî each service defines its own `enum XError: Error` (e.g., `AudioError`, `DataStoreError`); errors are specific (`AudioError.engineStartFailed`, not `.failed`)
- **Protocol-first design** ‚Äî define a protocol for any new service before the implementation; protocols enable test mocking without third-party frameworks
- **Value types by default** ‚Äî use `struct` for data carriers (`Comparison`, `TrainingSettings`); `class` only when reference semantics or `@Observable` is needed
- **No force unwrapping** ‚Äî never use `!` except for `@IBOutlet` (which shouldn't exist in this project anyway)
- **`final class`** ‚Äî mark classes `final` unless inheritance is explicitly needed
```

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Keep as-is and move on

### üßë Human (13:30:33)

p

### ü§ñ Assistant (13:31:11)

Bringing in agents to scrutinize the Language-Specific Rules.

---

üèóÔ∏è **Winston (Architect):** Looking at this with fresh eyes ‚Äî the rules are *correct* but they mix two concerns. Some are genuine Swift 6 language rules (`@MainActor`, `async/await`, `Sendable`), while others are *project design decisions* (`protocol-first`, `typed error enums`, `value types by default`). An agent reading this section will treat "protocol-first design" as a Swift language requirement rather than an architectural choice. That matters because the enforcement weight is different.

I'd split this more cleanly. The language rules should be things the **Swift 6 compiler will reject or warn about** if you get wrong. The design decisions belong in a separate section or could be folded into the framework rules.

Also missing: **access control**. The codebase uses `private` and `internal` deliberately. Properties that shouldn't be accessed outside their type are `private`. Agents love making everything `internal` (the default) or even `public`. The rule should be: **default to `private`; only use `internal` when cross-file access within the module is needed; never use `public` or `open`** ‚Äî this is a single-module app.

---

üíª **Amelia (Dev):** Winston's access control point is spot-on. I've seen agents dump `public` on everything "just in case." In a single-target app that's noise.

More things I've noticed agents get wrong with Swift 6 specifically:

1. **`nonisolated` keyword** ‚Äî sometimes needed when conforming to protocols like `Hashable` or `Codable` on `@MainActor` types. Agents either forget it (compiler error) or sprinkle it everywhere (defeats isolation). Rule: **use `nonisolated` only when the compiler requires it for protocol conformance on isolated types**.

2. **Closures capturing `self`** ‚Äî in `@MainActor` classes, closures passed to non-isolated contexts need explicit `@MainActor` or `@Sendable` annotations. Agents will write closures that capture `self` without thinking about isolation boundaries ‚Äî Swift 6 won't let that slide silently.

3. **`withCheckedThrowingContinuation`** ‚Äî it's listed but the critical rule is: **the continuation must be resumed exactly once**. Agents writing callback bridges frequently forget the error path, leaving the continuation hanging forever. That's a runtime crash, not a compiler warning.

4. The **"no Combine"** rule ‚Äî worth being explicit that this also means **no `PassthroughSubject`, no `CurrentValueSubject`, no `sink`**. Agents familiar with pre-async/await patterns default to Combine for event streams.

---

üß™ **Murat (Test Architect):** From a testability lens, two language rules have testing implications that should be stated explicitly:

**`Task` creation in services** ‚Äî when `TrainingSession` spawns a `Task`, that's fire-and-forget from the caller's perspective. Tests can't `await` a detached task. The codebase handles this with the callback hooks on mocks (`onPlayCalled`) to synchronize. The language rule should be: **when a service method spawns a `Task`, ensure there's an observable side effect (state change or callback) that tests can wait on**. Otherwise you get untestable async behavior.

**`CancellationError` handling** ‚Äî Task cancellation throws `CancellationError`. The codebase catches this specifically and treats it as a graceful stop, not an error. Agents must not catch `CancellationError` in a generic `catch` block and log it as a failure. Rule: **always check for `CancellationError` before generic error handling**.

---

üèóÔ∏è **Winston:** Good contributions all around. Let me propose a clean restructure. I'd rename this section to make its scope clear and tighten every bullet:

```markdown
### Language-Specific Rules (Swift 6)

**Concurrency (compiler-enforced):**
- **`@MainActor` on all service classes and mocks** ‚Äî the compiler enforces isolation boundaries; UI-facing types must be explicitly isolated
- **`Sendable` conformance enforced** ‚Äî types crossing isolation boundaries must be `Sendable`; use value types to satisfy this naturally
- **`nonisolated` only when compiler requires it** ‚Äî needed for protocol conformance (`Hashable`, `Codable`) on `@MainActor` types; do not use it to bypass isolation
- **Closures crossing isolation boundaries** ‚Äî closures from `@MainActor` contexts passed to non-isolated APIs need explicit `@Sendable` annotation; Swift 6 rejects implicit captures

**Async/Await:**
- **`async/await` for all asynchronous work** ‚Äî no completion handlers, no Combine (`PassthroughSubject`, `sink`, etc.); structured concurrency only
- **`withCheckedThrowingContinuation`** for bridging callback APIs ‚Äî **continuation must be resumed exactly once** on every code path, including errors
- **Task cancellation** ‚Äî check for `CancellationError` before generic error handling; cancellation is a graceful stop, not a failure
- **Spawned `Task`s must produce observable side effects** ‚Äî state changes or callbacks that tests can synchronize on; no fire-and-forget without test hooks

**Access Control:**
- **Default to `private`** ‚Äî only use `internal` when cross-file access within the module is needed
- **Never use `public` or `open`** ‚Äî single-module app, no external consumers

**Type Design:**
- **Value types by default** ‚Äî `struct` for data carriers; `class` only for `@Observable` or reference semantics
- **`final class`** ‚Äî mark classes `final` unless inheritance is explicitly designed for
- **No force unwrapping (`!`)** ‚Äî no `@IBOutlet`, no implicit unwraps

**Error Handling:**
- **Typed error enums per service** ‚Äî `enum AudioError: Error`, `enum DataStoreError: Error`; errors are specific and descriptive
- **Protocol-first design** ‚Äî define protocol before implementation; enables test mocking without frameworks
```

---

üíª **Amelia:** Much better structure. The compiler-enforced vs. design-choice split is clear now. `+1`.

üß™ **Murat:** The `Task` observability rule and `CancellationError` handling are in. I'm satisfied. Ship it.

---

Michael, the agents restructured the Language-Specific Rules into clearer subcategories (Concurrency, Async/Await, Access Control, Type Design, Error Handling) and added several missing rules: `nonisolated` usage, `Sendable` closures, continuation safety, `CancellationError` handling, access control defaults, and the no-Combine specifics.

Accept these enhanced rules for Language-Specific Rules? (y/n)

### üßë Human (13:32:19)

y

### ü§ñ Assistant (13:32:34)

Language-Specific Rules updated. Now let me save the Testing Rules that were approved earlier from the Party Mode session.

### ü§ñ Assistant (13:33:13)

Both sections saved. Moving to **Category 5: Code Quality & Style Rules**.

**Here's what I'll add:**

```markdown
### Code Quality & Style Rules

**Naming Conventions:**
- **Types & protocols:** `PascalCase` ‚Äî `TrainingSession`, `NotePlayer`, `ComparisonRecord`
- **Properties, methods, parameters:** `camelCase` ‚Äî `isCorrect`, `playNote(frequency:)`, `detectionThreshold`
- **Protocols:** noun describing capability ‚Äî `NotePlayer`, `NextNoteStrategy` (not `NotePlayable`, not `NoteStrategyProtocol`)
- **Protocol implementations:** descriptive prefix ‚Äî `SineWaveNotePlayer`, `AdaptiveNoteStrategy`
- **SwiftData models:** singular noun ‚Äî `ComparisonRecord`, not `ComparisonRecords`
- **Files:** match primary type ‚Äî `TrainingSession.swift`, `NotePlayer.swift`
- **Screens:** `{Name}Screen.swift` ‚Äî `TrainingScreen.swift`, `SettingsScreen.swift`
- **Subviews:** `{Name}View.swift` ‚Äî `PianoKeyboardView.swift`, `FeedbackIndicator.swift`
- **Mocks:** `Mock{ClassName}.swift` ‚Äî `MockNotePlayer.swift`

**Project Organization (by feature):**
- `App/` ‚Äî entry point, composition root, root navigation
- `Core/` ‚Äî shared services and models (Audio/, Algorithm/, Data/, Profile/)
- Feature directories (`Training/`, `Profile/`, `Settings/`, `Start/`, `Info/`) ‚Äî screen + supporting views
- `Resources/` ‚Äî assets, localization

**Documentation:**
- **No unnecessary comments** ‚Äî code should be self-explanatory; only comment where logic isn't self-evident
- **No docstrings on obvious methods** ‚Äî don't add documentation to code you didn't change
```

Any code quality or style rules I'm missing?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to next category

### üßë Human (13:33:38)

p

### ü§ñ Assistant (13:34:15)

Bringing in agents to review Code Quality & Style.

---

üèóÔ∏è **Winston (Architect):** The naming conventions are thorough ‚Äî that's the easy part. What's missing is the **structural rules that prevent drift**.

The project organization listing is informative but not *enforcing*. Agents need to know **where new files go** ‚Äî not just where existing files are. The decision tree:

- Is it a protocol or service used by multiple features? ‚Üí `Core/{subdomain}/`
- Is it a screen the user navigates to? ‚Üí `{FeatureName}/{FeatureName}Screen.swift`
- Is it a subview only used within one screen? ‚Üí Same feature directory as the screen
- Is it a shared UI component used across screens? ‚Üí This doesn't exist yet, but if needed, it would go in a new `Shared/` directory ‚Äî **don't create it preemptively**

That last point matters. Agents love creating `Utils/`, `Helpers/`, `Shared/`, `Common/` directories on day one. The codebase has none. The rule: **don't create abstraction directories until there are concrete reusable components to put in them**.

Also: **file count per directory**. If a feature directory grows beyond ~5-6 files, that's a signal to consider subdirectories. But currently every feature is lean. Agents should not preemptively create subdirectories within feature folders.

---

üíª **Amelia (Dev):** Naming section is good but missing a subtle one: **enum cases are `lowerCamelCase`**. Agents coming from other languages sometimes PascalCase enum cases.

```swift
// Correct:
enum TrainingState {
    case idle
    case playingNote1
    case awaitingAnswer
}

// Wrong:
enum TrainingState {
    case Idle
    case PlayingNote1
}
```

Also: **naming for boolean properties** ‚Äî the codebase uses `is`/`has`/`should` prefixes consistently: `isCorrect`, `isCompact`, `shouldThrowError`. Agents sometimes write `correct`, `compact`, `throwError`. Follow the existing prefix pattern.

On documentation ‚Äî the "no unnecessary comments" rule should also state: **no `// MARK:` comments in small files**. `MARK` is useful in 200+ line files for Xcode navigation, but agents scatter them everywhere in 30-line files. Use `// MARK:` only when a file has multiple distinct sections that benefit from Xcode's jump bar.

One more critical style rule: **trailing closures**. Swift convention is to use trailing closure syntax for the last closure parameter, and the codebase follows this. But agents sometimes put *all* closures as trailing closures when there are multiple closure parameters ‚Äî that's unreadable. Rule: **trailing closure syntax for single closure parameters only; use labeled parameters when multiple closures are involved**.

---

üìö **Paige (Technical Writer):** Looking at this through the lens of someone who'll actually *read* this document ‚Äî the naming conventions table is dense. Let me suggest a structural improvement.

The naming rules are actually two things: **Swift language conventions** (which any Swift developer knows) and **project-specific conventions** (which are the ones agents actually need). `PascalCase` for types and `camelCase` for properties ‚Äî that's Swift 101. Every agent knows that. What they *don't* know:

- Protocol names use capability nouns, not `-able`/`-Protocol` suffixes
- Screens are `{Name}Screen`, not `{Name}View` or `{Name}ViewController`
- Mocks are `Mock{Name}`, not `{Name}Mock` or `Fake{Name}` or `Stub{Name}`
- Boolean properties use `is`/`has`/`should` prefixes

I'd trim the obvious Swift conventions and keep only the project-specific naming decisions. That saves context tokens and puts agent attention on what actually matters.

The documentation rule is also worth expanding: **don't add comments, docstrings, or type annotations to code you didn't write or change.** Agents are notorious for "improving" existing code with documentation drive-bys. That generates noise in pull requests and obscures the actual changes.

---

üèóÔ∏è **Winston:** Paige makes an excellent point about trimming the obvious. Let me propose a refined version that focuses only on what agents would get wrong:

```markdown
### Code Quality & Style Rules

**Project-Specific Naming (non-obvious conventions):**
- **Protocols:** capability nouns ‚Äî `NotePlayer`, `NextNoteStrategy` (not `-able`, not `-Protocol` suffix)
- **Protocol implementations:** descriptive prefix ‚Äî `SineWaveNotePlayer`, `AdaptiveNoteStrategy`
- **Screens:** `{Name}Screen.swift` ‚Äî not `{Name}View` or `{Name}ViewController`
- **Subviews:** `{Name}View.swift` ‚Äî `PianoKeyboardView.swift`, `FeedbackIndicator.swift`
- **Mocks:** `Mock{Name}.swift` ‚Äî not `{Name}Mock`, `Fake{Name}`, or `Stub{Name}`
- **Boolean properties:** `is`/`has`/`should` prefix ‚Äî `isCorrect`, `isCompact`, `shouldThrowError`
- **Enum cases:** `lowerCamelCase` ‚Äî `case playingNote1`, not `case PlayingNote1`
- **SwiftData models:** singular noun ‚Äî `ComparisonRecord`, not `ComparisonRecords`

**File Placement (decision tree):**
- Protocol or service used across features ‚Üí `Core/{subdomain}/`
- Screen the user navigates to ‚Üí `{Feature}/{Feature}Screen.swift`
- Subview used by one screen ‚Üí same feature directory as the screen
- **Do not create `Utils/`, `Helpers/`, `Shared/`, `Common/` directories** ‚Äî none exist and agents must not create them preemptively

**Code Style:**
- **Trailing closure syntax for single closures only** ‚Äî use labeled parameters when multiple closures are involved
- **`// MARK:` only in files with multiple distinct sections** ‚Äî don't scatter in small files
- **No documentation drive-bys** ‚Äî don't add comments, docstrings, or type annotations to code you didn't write or change
- **No unnecessary comments** ‚Äî code should be self-explanatory; only comment where logic isn't self-evident
```

üíª **Amelia:** Clean. Focused on the mistakes agents actually make. `+1`.

üìö **Paige:** Much leaner. The context token savings are real ‚Äî agents will actually read this. Approved.

---

Michael, the agents trimmed the obvious Swift conventions and focused on project-specific decisions that agents get wrong: the naming suffixes, the file placement decision tree, the no-preemptive-directories rule, and several style rules (trailing closures, MARK usage, documentation drive-bys).

Accept these enhanced rules for Code Quality & Style? (y/n)

### üßë Human (13:39:39)

y

### ü§ñ Assistant (13:39:59)

Code Quality & Style saved. Moving to **Category 6: Development Workflow Rules**.

**Here's what I'll add:**

```markdown
### Development Workflow Rules

**Git Workflow:**
- **Commit after each meaningful task completion** ‚Äî story created, sprint status updated, code implemented
- **Descriptive commit messages referencing story/task context** ‚Äî not generic "fix bug" or "update code"
- **Do not batch unrelated changes** into a single commit
- **Do not push to remote** unless explicitly asked

**Tool Scripts:**
- **Analysis/processing code goes in `tools/` directory** ‚Äî never write inline Python/Shell/Ruby snippets for direct shell execution
- **Create named script files** (e.g., `tools/analyze-convergence.py`) ‚Äî ask for review before execution
- **Commit tool scripts** alongside the work that introduced them

**Pre-Commit Checklist:**
- Run full test suite: `xcodebuild test -scheme Peach -destination 'platform=iOS Simulator,name=iPhone 17'`
- All tests must pass ‚Äî do not commit with failing tests
- Never run only specific test files
```

Any workflow rules I'm missing?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to next category

### üßë Human (13:40:10)

p

### ü§ñ Assistant (13:40:43)

Bringing in agents with workflow expertise.

---

üèÉ **Bob (Scrum Master):** Workflow rules ‚Äî my bread and butter. The git and tooling rules are solid because they come straight from CLAUDE.md. But I see gaps in the *development process* that agents need to follow.

**Story-driven development.** This project uses BMAD ‚Äî there are stories, epics, sprints. Agents don't just "write code." They implement *stories*. The workflow is:

1. Read the story file (from `docs/implementation-artifacts/`)
2. Understand acceptance criteria before writing a line of code
3. Implement against the ACs
4. Verify all ACs are met
5. Commit referencing the story

Agents that skip step 1 and just start coding based on a vague description produce work that doesn't match the spec. The rule: **always read and reference the story file before implementing**.

Also missing: **uncommitted changes check.** CLAUDE.md says "Before starting a new task, ensure that there are no uncommitted changes in the working directory." That's a gate. Agents must run `git status` before starting work and refuse to proceed if there's uncommitted work.

---

üíª **Amelia (Dev):** Bob's right on the story-driven flow. Let me add the practical implementation details:

**Branch strategy** ‚Äî looking at the git log, all work happens on `main`. There are no feature branches. That's fine for a solo dev project, but agents need to know: **commit directly to `main`**, don't create feature branches unless explicitly asked.

**Commit granularity** ‚Äî the existing commits show a clear pattern: one commit per story or meaningful sub-task. Examples from the log:
- `Implement story 7.5: App Icon Design and Implementation`
- `Code review fixes for Story 7.5: strip alpha channel, fix docs, close Epic 7`

The pattern: **`{verb} story {id}: {description}`** for implementation commits. Fix-up commits reference the story too. Agents should follow this pattern.

**The test suite timing issue** ‚Äî running `xcodebuild test` takes real time on the simulator. The pre-commit rule says "run ALL tests." But agents sometimes interpret this as "run tests only for the files I changed." The rule is absolute: **full suite, every time, no exceptions**. It's already in the Testing Rules section but worth reinforcing here as a workflow gate.

---

üß™ **Murat (Test Architect):** One workflow gap from the testing side: **test-first means write the test before the implementation**. Agents default to writing code first and tests after. The workflow for new functionality should be:

1. Read story and ACs
2. Write failing tests that encode the ACs
3. Implement until tests pass
4. Refactor if needed (tests still pass)
5. Run full suite
6. Commit

That's textbook TDD and the architecture document explicitly calls it out as a project constraint. If agents write implementation first, the tests become "confirm what I wrote works" rather than "verify the behavior matches the spec." Different mindset, different test quality.

Also: **when fixing a bug, write a failing test first that reproduces the bug**, then fix it. This ensures the bug can't regress silently.

---

üèÉ **Bob:** Good additions all around. Let me consolidate. I'd also flag: the CLAUDE.md rules about tool scripts are workflow rules that already appear in the draft. But the **story-driven development** and **TDD workflow** are the high-value additions here. Those are the process rules agents violate most often.

```markdown
### Development Workflow Rules

**Before Starting Any Task:**
- **Check for uncommitted changes** ‚Äî run `git status`; do not start new work with a dirty working tree
- **Read the story file** ‚Äî find the relevant story in `docs/implementation-artifacts/`; understand all acceptance criteria before writing code

**Test-Driven Development (TDD):**
1. Read story and acceptance criteria
2. Write failing tests that encode the ACs
3. Implement until tests pass
4. Refactor if needed (tests must still pass)
5. Run full test suite
6. Commit

- **Bug fixes:** write a failing test that reproduces the bug before fixing it

**Git Workflow:**
- **Commit directly to `main`** ‚Äî no feature branches unless explicitly asked
- **Commit after each meaningful task** ‚Äî one commit per story or sub-task
- **Commit message format:** `{Verb} story {id}: {description}` ‚Äî e.g., `Implement story 7.5: App Icon Design and Implementation`
- **Do not batch unrelated changes** into a single commit
- **Do not push to remote** unless explicitly asked

**Pre-Commit Gate:**
- Run full test suite: `xcodebuild test -scheme Peach -destination 'platform=iOS Simulator,name=iPhone 17'`
- **All tests must pass** ‚Äî do not commit with failing tests
- **Never run only specific test files** ‚Äî always the complete suite

**Tool Scripts:**
- Analysis/processing code goes in `tools/` directory as named script files
- Ask for review before execution; commit scripts alongside the work that introduced them
```

üíª **Amelia:** Clean. The TDD sequence and the "read the story first" gate are the two additions that'll change agent behavior most. `+1`.

üß™ **Murat:** The "bug fix = failing test first" rule is in. Satisfied.

---

Michael, the agents added three key workflow rules: the pre-task uncommitted changes check, the story-driven development gate (read the story before coding), and the explicit TDD sequence. They also identified the commit message format from your git history and the direct-to-main branching strategy.

Accept these enhanced rules for Development Workflow? (y/n)

### üßë Human (13:43:24)

y

### ü§ñ Assistant (13:43:49)

Development Workflow saved. Last category ‚Äî **Category 7: Critical Don't-Miss Rules**.

Based on the codebase, here are the anti-patterns, edge cases, and gotchas agents must know:

```markdown
### Critical Don't-Miss Rules

**Anti-Patterns to Avoid:**
- **Never use `ObservableObject` / `@Published`** ‚Äî use `@Observable` macro exclusively
- **Never use `@EnvironmentObject`** ‚Äî use `@Environment` with custom `EnvironmentKey`
- **Never use XCTest** ‚Äî no `XCTAssert*`, no `XCTestCase`, no `setUp/tearDown`
- **Never use Combine** ‚Äî no `PassthroughSubject`, `CurrentValueSubject`, `sink`, `assign`
- **Never create a second `AVAudioEngine` instance** ‚Äî single engine in `SineWaveNotePlayer`
- **Never query SwiftData outside `TrainingDataStore`** ‚Äî no direct `ModelContext` usage in views or other services
- **Never over-engineer** ‚Äî no premature abstractions, no speculative feature flags, no backward-compatibility shims

**Edge Cases Agents Must Handle:**
- **Audio interruption mid-comparison** ‚Äî headphone disconnect, phone call; `TrainingSession` must discard incomplete comparison
- **App backgrounding during training** ‚Äî training stops; return to Start Screen on foreground
- **Empty profile (cold start)** ‚Äî `PerceptualProfile` has no data; `NextNoteStrategy` must handle gracefully with exploration mode
- **`TrainingSession` error boundary** ‚Äî audio or data failures caught silently; training loop continues; single comparison data loss is acceptable

**Performance:**
- **`PerceptualProfile` uses Welford's online algorithm** ‚Äî incremental updates only; never re-aggregate from all records
- **Pre-generate next comparison during feedback phase** ‚Äî zero perceived delay between comparisons
```

Any critical rules I'm missing?

**What would you like to do?**
- **[A]** Advanced Elicitation ‚Äî Explore nuanced rules for this category
- **[P]** Party Mode ‚Äî Review from different implementation perspectives
- **[C]** Continue ‚Äî Save these rules and move to finalization

### üßë Human (13:44:10)

p

### ü§ñ Assistant (13:44:55)

Bringing in agents for the final critical review.

---

üèóÔ∏è **Winston (Architect):** This is the "if you forget this, you'll ship a bug" section. It needs to be ruthless. Let me call out what's missing.

**Architectural boundary violations** ‚Äî the most common agent mistake isn't using the wrong API. It's putting logic in the wrong place. The critical boundaries:

- **Views must not contain business logic.** Not "should not" ‚Äî *must not*. No computation, no conditional logic beyond rendering, no direct service calls. If a view needs a derived value, it comes from `TrainingSession` or `PerceptualProfile` as a computed property.
- **`TrainingSession` is the ONLY component that knows what a "comparison" is** as a sequence of two played notes. `NotePlayer` knows frequencies. `NextNoteStrategy` knows note selection. Neither knows about the training loop.
- **`PerceptualProfile` does NOT persist itself.** It's computed in-memory. Agents will try to save it to SwiftData. Wrong. It's rebuilt from `ComparisonRecord` data on startup and updated incrementally during training.

These are the boundaries that, when violated, create architectural rot that's expensive to unwind.

---

üíª **Amelia (Dev):** Practical gotchas from the actual codebase:

**MIDI note range is 0‚Äì127.** Agents will sometimes use 1‚Äì128 or forget bounds checking. The `PerceptualProfile` is indexed by MIDI note (128 slots, 0-based). Out-of-range access = crash.

**Cent offset is on note 2 only.** In a comparison, note 1 is always an exact MIDI note. Note 2 is the same MIDI note shifted by a cent difference. Agents might try to offset both notes or apply the offset to note 1. The model is: `note1` = reference, `note2` = `note1 + centOffset`.

**Frequency calculation precision matters.** The app trains pitch discrimination to 0.1-cent accuracy. Agents must use the existing `FrequencyCalculation.swift` ‚Äî not approximate with `440 * pow(2, (note - 69) / 12)` which loses cent precision. The existing implementation handles the full MIDI-to-Hz-with-cents calculation correctly.

**Feedback duration is 0.4 seconds.** The `showingFeedback` state lasts exactly 0.4s before looping. Agents modifying the training loop must preserve this timing ‚Äî it's designed for perceptual learning, not arbitrary.

---

üß™ **Murat (Test Architect):** From a "don't break the tests" perspective:

**Don't add `import XCTest` to any test file.** It sounds obvious given all the rules above, but agents will do it reflexively. The import is `import Testing`. If you see `import XCTest`, the file is wrong.

**Don't make tests depend on timing.** The mock's `instantPlayback` mode exists precisely so tests don't depend on real audio playback timing. Any new test that involves `TrainingSession` must use mocks with `instantPlayback = true`. Tests that sleep or use fixed delays are forbidden ‚Äî they'll be flaky in CI.

**Don't test private methods.** If something needs testing, it should be accessible through the public/internal protocol interface. Agents sometimes add `@testable import` and then test private implementation details. The existing tests don't do this for service internals ‚Äî they test through the protocol. `@testable import Peach` is fine for accessing `internal` types, but never for reaching into `private`.

---

üî¨ **Dr. Quinn (Creative Problem Solver):** AHA! I see a pattern everyone's missing. The anti-patterns list is reactive ‚Äî "don't do X." But the *root cause* of most agent mistakes is **agents not reading existing code before writing new code.**

The single most impactful rule for this entire section: **Before implementing anything, read the existing implementation of the component you're modifying or the closest analogous component.** An agent adding a new `ComparisonObserver` should first read the existing observers. An agent adding a new screen should first read `TrainingScreen.swift` as a reference. An agent modifying the state machine should first read *all* of `TrainingSession.swift`.

This one rule prevents 80% of the anti-pattern violations because the patterns are self-documenting in the code. The agent just needs to *look first*.

---

üèóÔ∏è **Winston:** Dr. Quinn's meta-rule is the highest-value addition. Let me propose the final version:

```markdown
### Critical Don't-Miss Rules

**The Golden Rule:**
- **Read before writing** ‚Äî before implementing anything, read the existing implementation of the component you're modifying or the closest analogous component; the codebase is the primary source of truth for patterns

**Architectural Boundaries (hard rules):**
- **Views contain zero business logic** ‚Äî no computation, no conditional logic beyond rendering; derived values come from `TrainingSession` or `PerceptualProfile` as computed properties
- **`TrainingSession` is the ONLY component that understands "comparisons" as a training sequence** ‚Äî `NotePlayer` knows frequencies, `NextNoteStrategy` knows note selection, neither knows about the loop
- **`PerceptualProfile` is in-memory only** ‚Äî rebuilt from `ComparisonRecord` on startup, updated incrementally; never persist it to SwiftData

**Domain Rules Agents Will Get Wrong:**
- **MIDI note range: 0‚Äì127** ‚Äî `PerceptualProfile` is indexed by MIDI note (128 slots, 0-based); out-of-range = crash
- **Cent offset applies to note 2 only** ‚Äî note 1 is exact MIDI note, note 2 = note 1 + cent offset; never offset both notes
- **Use `FrequencyCalculation.swift` for all Hz conversions** ‚Äî don't approximate; the app requires 0.1-cent precision
- **Feedback phase is 0.4 seconds** ‚Äî preserve this timing in the training loop; it's a perceptual learning design decision

**Never Do This:**
- `ObservableObject` / `@Published` ‚Üí use `@Observable`
- `@EnvironmentObject` ‚Üí use `@Environment` with custom `EnvironmentKey`
- `import XCTest` ‚Üí use `import Testing`
- Combine (`PassthroughSubject`, `sink`) ‚Üí use `async/await`
- Second `AVAudioEngine` instance ‚Üí use the single injected `SineWaveNotePlayer`
- Direct `ModelContext` queries ‚Üí go through `TrainingDataStore`
- Sleep/fixed delays in tests ‚Üí use `instantPlayback` mocks and `waitForState`
- `@testable import` to test private methods ‚Üí test through protocol interfaces
- Premature abstractions, `Utils/` directories, speculative features ‚Üí keep it simple

**Error Resilience:**
- **`TrainingSession` is the error boundary** ‚Äî catches all service errors; training loop continues gracefully
- **Audio interruption mid-comparison** ‚Üí discard incomplete comparison, stop training
- **App backgrounding** ‚Üí stop training; return to Start Screen on foreground
- **Empty profile (cold start)** ‚Üí `NextNoteStrategy` uses exploration mode; handle gracefully
```

---

Michael, the agents made significant additions: the "read before writing" golden rule (Dr. Quinn), architectural boundary violations (Winston), domain-specific gotchas like MIDI range and cent offset rules (Amelia), and testing anti-patterns like `import XCTest` and timing dependencies (Murat). The "Never Do This" list is now a quick-scan reference table.

Accept these enhanced rules for Critical Don't-Miss Rules? (y/n)

### üßë Human (13:46:18)

y

### ü§ñ Assistant (13:46:33)

All 7 categories are complete. Let me load the finalization step.

### ü§ñ Assistant (13:46:37)

Now let me review the complete file for optimization and finalization.

### ü§ñ Assistant (13:46:42)

The content is clean, well-structured, and lean. I see minimal redundancy ‚Äî a few items appear in both the Technology Stack and Critical Rules sections, but that's intentional reinforcement for the "Never Do This" quick-scan list. Let me finalize the file with the completion frontmatter and usage guidelines.

### ü§ñ Assistant (13:46:58)

**Project Context Generation Complete!**

Your optimized project context file is ready at:
`docs/project-context.md`

**What we created:**

- 85 critical implementation rules across 7 sections
- Technology stack with exact versions and constraints
- Framework-specific patterns (SwiftUI, SwiftData, AVAudioEngine)
- Comprehensive testing rules with mock contracts
- Code quality and naming conventions
- TDD-based development workflow
- Domain-specific "don't-miss" rules and anti-patterns

**Key benefits:**

- AI agents will implement consistently with your standards
- The "Never Do This" quick-scan table catches the most common mistakes
- The "When Adding New Components" checklist gives agents a mechanical process to follow
- Party Mode reviews added ~30 high-value rules that the initial drafts missed

**Next steps:**

1. AI agents should read this file before implementing
2. Update as your project evolves
3. Review periodically to optimize and remove outdated rules

### üßë Human (13:48:17)

Will future (BMAD) agents automatically refer to this file or do they need to be told?

### ü§ñ Assistant (13:48:21)

Good question. Let me check how BMAD agents discover project files.

### ü§ñ Assistant (13:49:18)

Short answer: **it depends on the workflow.**

BMAD agents follow a "load on demand" principle ‚Äî they don't pre-load anything at startup. But several key workflows **do** explicitly check for and load `project-context.md`:

- **Quick-Flow Dev** (`/bmad-quick-flow`) ‚Äî Step 1 checks if `**/project-context.md` exists and loads it as a foundational reference for all implementation decisions
- **Create Architecture / Create PRD / Create UX Design** workflows ‚Äî list it as an optional input document
- **`/bmad-help`** ‚Äî grounds itself in `project_knowledge` docs if available

However, the **standard Dev agent** (`/bmad-dev`) does **not** auto-load it when activated outside a workflow. And **Claude Code itself** (non-BMAD sessions) won't see it unless it's referenced in `CLAUDE.md`.

If you want it picked up universally ‚Äî including plain Claude Code sessions ‚Äî the most reliable approach would be to add a reference in your `CLAUDE.md`. Something like:

```markdown
## Project Context
Before implementing any code, read `docs/project-context.md` for critical rules and patterns.
```

Want me to add that to your `CLAUDE.md`?

### üßë Human (13:50:50)

Yes, add it to CLAUDE.md. Also, I think, we now have redundant information in CLAUDE.md and project-context.md and possibly other places. I think we ought to clean that up.

### ü§ñ Assistant (13:51:21)

Good call. Let me map out the redundancy first.

### ü§ñ Assistant (13:51:28)

Here's the redundancy map:

| Rule | CLAUDE.md | project-context.md |
|---|---|---|
| Uncommitted changes check | Line 3 | Development Workflow > Before Starting Any Task |
| Full test suite command | Lines 5-8 | Testing Rules + Pre-Commit Gate |
| Git workflow (commit style, no push) | Lines 19-24 | Development Workflow > Git Workflow |
| Tool scripts in `tools/` | Lines 10-17 | Development Workflow > Tool Scripts |

Everything in CLAUDE.md is now duplicated in project-context.md. The clean approach: **CLAUDE.md becomes a slim pointer** to project-context.md, keeping only the Tool Scripts rule (which is specific to the Claude Code shell environment and not relevant to other BMAD agents).

### ü§ñ Assistant (13:51:37)

Here's what changed:

**CLAUDE.md** (trimmed from 24 lines to 15):
- Added: Project Context directive pointing to `docs/project-context.md`
- Removed: Uncommitted changes check (now in project-context.md > Development Workflow)
- Removed: Test suite command and rules (now in project-context.md > Testing Rules + Pre-Commit Gate)
- Removed: Git workflow rules (now in project-context.md > Development Workflow > Git Workflow)
- Kept: Tool Scripts section (specific to Claude Code's shell environment, not relevant to other BMAD agents)

**project-context.md** ‚Äî unchanged, it's the single source of truth for all implementation rules.

The Tool Scripts rule stays in CLAUDE.md because it governs how Claude Code specifically uses its shell ‚Äî other BMAD agents (architect, analyst, PM) don't execute scripts. Want me to commit these changes?

### üßë Human (13:52:17)

yes

### ü§ñ Assistant (13:52:34)

Committed. Two files changed:
- `docs/project-context.md` ‚Äî new, 244 lines, 85 rules across 7 sections
- `CLAUDE.md` ‚Äî trimmed from 24 to 14 lines, now points to project-context.md

The `_bmad-output/` directory remains untracked (it was there before we started and appears to be scratch output).

---

[‚Üê Previous (49010d9468)](49010d9468.md) | [Index](index.md) | [Next (90d2b88768) ‚Üí](90d2b88768.md)
