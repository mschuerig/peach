---
commit: "9843da5a5f7c48e77b2b86c74856f26634fc83f7"
date: "2026-02-25T17:31:28+01:00"
author: "Michael Sch√ºrig <michael@schuerig.de>"
subject: "Update planning artifacts for v0.2 pitch matching"
sessions: ["84599448-9fd6-4a74-b9e3-cba1168871ac"]
prev: "b4ff06222a.md"
next: "3e007de7eb.md"
---

[‚Üê Previous (b4ff06222a)](b4ff06222a.md) | [Index](index.md) | [Next (3e007de7eb) ‚Üí](3e007de7eb.md)

# Commit 9843da5a5f

**Date:** 2026-02-25 17:31:28 UTC+01:00  
**Author:** Michael Sch√ºrig <michael@schuerig.de>

## Commit message

Update planning artifacts for v0.2 pitch matching

Architecture amendment: PitchMatchingSession state machine, PlaybackHandle
pattern for NotePlayer, PitchMatchingRecord data model, profile protocol
split (PitchDiscriminationProfile/PitchMatchingProfile), prerequisite
renames (TrainingSession‚ÜíComparisonSession et al.), updated project
structure and requirements mapping.

Glossary: updated renamed terms, added pitch matching concepts, new Audio
section with PlaybackHandle terminology.

PRD and UX spec: pitch matching requirements (FR44-FR52) and UX amendment.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>

## Changed files

```
docs/planning-artifacts/architecture.md            | 460 +++++++++++++++++++-
 docs/planning-artifacts/glossary.md                |  67 ++-
 docs/planning-artifacts/prd.md                     |   2 +-
 docs/planning-artifacts/ux-design-specification.md | 471 ++++++++++++++++++++-
 4 files changed, 973 insertions(+), 27 deletions(-)
```

## Session `84599448‚Ä¶`

*2026-02-25 15:34:03 UTC ‚Üí 2026-02-25 16:31:37 UTC*

### üßë Human (15:34:03)

<command-message>bmad-agent-bmm-architect</command-message>
<command-name>/bmad-agent-bmm-architect</command-name>
<command-args>Update the architecture document ‚Äî Pitch Matching needs architectural decisions (PitchMatchingSession state machine, data model for matching records, audio engine indefinite playback). Look specifically at the (uncommitted) updates in docs/planning-artifacts/prd.md and docs/planning-artifacts/ux-design-specification.md .</command-args>

### ü§ñ Assistant (15:34:20)

Greetings, Michael. Winston here ‚Äî your architect on the Peach project.

I see you've come with a clear mission: updating the architecture document with Pitch Matching decisions. That maps directly to the **Create Architecture** workflow. Before I jump in, here's what I can help with:

---

**[MH]** Redisplay Menu Help
**[CH]** Chat with the Agent about anything
**[CA]** Create Architecture: Guided workflow to document technical decisions
**[IR]** Implementation Readiness: Ensure PRD, UX, Architecture, and Epics are aligned
**[PM]** Start Party Mode
**[DA]** Dismiss Agent

---

You can type `/bmad-help` at any time for guidance ‚Äî e.g., `/bmad-help where should I start with an idea I have that does XYZ`.

Your arguments point squarely at **[CA] Create Architecture** ‚Äî shall I proceed with that workflow, focusing on the Pitch Matching architectural decisions (session state machine, matching data model, indefinite audio playback) using the uncommitted PRD and UX spec changes?

### üßë Human (15:34:56)

yes, go ahead with CA

### ü§ñ Assistant (15:35:04)

Now let me check for existing architecture documents and discover input files.

### ü§ñ Assistant (15:35:08)

An existing architecture document is found. Let me check for continuation state.

### ü§ñ Assistant (15:35:13)

The architecture document exists and is marked as complete. Per the workflow, I need to load the continuation step.

### ü§ñ Assistant (15:35:32)

Welcome back, Michael. I found your Architecture work for Peach.

**Current Progress:**
- Steps completed: 1, 2, 3, 4, 5, 6, 7, 8 ‚Äî **all steps**
- Last step worked on: Step 8
- Status: **Complete** (completed 2026-02-12)
- Input documents loaded: 3 files (prd.md, glossary.md, brainstorming session)

**Document Sections Found:**
- Project Context Analysis (Requirements Overview, Technical Constraints, Cross-Cutting Concerns)
- Starter Template & Technology Foundation (Technology Decisions)
- Core Architectural Decisions (Data Architecture, App Architecture & State Management)
- Implementation Patterns & Consistency Rules (Naming, Organization, Error Handling, SwiftUI)
- Project Structure & Boundaries (Directory Structure, Service Boundaries, FR Mapping)
- Architecture Validation Results (Coherence, Coverage, Gap Analysis, Readiness)

The architecture is **fully complete** and was marked ready for implementation. You're looking to **evolve** it ‚Äî specifically adding Pitch Matching architectural decisions based on uncommitted PRD and UX spec updates.

**What would you like to do?**

**[R]** Resume ‚Äî I'll load the uncommitted PRD and UX changes, analyze the Pitch Matching requirements, and we'll collaboratively update the existing architecture sections that need new decisions (Data model, State machine, Audio engine)

**[C]** Continue to full step-by-step re-run of the workflow from context analysis

**[O]** Overview of all workflow steps so you can pick where to focus

**[X]** Start over (will overwrite existing work)

Given your stated goal, **[R]** seems like the right move ‚Äî surgical updates to the existing architecture rather than a full re-run. Your call.

### üßë Human (15:36:39)

r

### ü§ñ Assistant (15:36:42)

Let me load the uncommitted PRD and UX spec changes, plus the project context for implementation rules.

### ü§ñ Assistant (15:36:49)

Good ‚Äî PRD, project context, and architecture all loaded. The UX spec was truncated. Let me pull the Pitch Matching-specific sections from it.

### ü§ñ Assistant (15:37:01)

Good. I've now loaded all the source material. Let me also check the current codebase to understand what's already implemented ‚Äî the interfaces I'll be designing against.

### ü§ñ Assistant (15:39:36)

Excellent. I now have a complete picture ‚Äî the PRD, UX spec, existing architecture, current codebase, and project context. Let me present my analysis of what the architecture document needs.

---

Here's my analysis of the architectural gaps the Pitch Matching feature introduces, Michael. I've organized this by decision area so we can work through them one at a time.

## Architectural Decisions Needed

### 1. PitchMatchingSession State Machine

The UX spec defines a clear linear loop. I'm proposing this state machine:

```
idle ‚Üí playingReference ‚Üí playingTunable ‚Üí showingFeedback ‚Üí (loop back to playingReference)
```

**States:**
- `idle` ‚Äî not started
- `playingReference` ‚Äî reference note playing for configured duration; slider visible but disabled
- `playingTunable` ‚Äî tunable note playing indefinitely at random offset; slider active; user can listen passively or drag immediately
- `showingFeedback` ‚Äî note stopped, result recorded, arrow + cents displayed (~400ms)

Note: the UX distinguishes "user listening" vs "user dragging" during `playingTunable`, but that's a UI concern (gesture state), not a session state. The session only cares that the tunable note is playing and it's waiting for the user to release. The transition from `playingTunable` ‚Üí `showingFeedback` is triggered by the user releasing the slider.

**Separate class, not extending TrainingSession.** The semantics are too different ‚Äî `TrainingSession` is built around two-note-comparison with binary answers. PitchMatchingSession has indefinite playback, continuous slider input, and continuous results. Sharing a class would create a conditional mess.

**Same patterns:** `@Observable` final class, error boundary, observer injection, environment injection via `@Entry`.

### 2. NotePlayer Protocol Extension

The current `play(frequency:duration:velocity:amplitudeDB:)` assumes fixed duration. Pitch matching needs:

- **Indefinite playback** ‚Äî start a note that plays until explicitly stopped
- **Real-time frequency adjustment** ‚Äî change frequency while a note is playing, without artifacts

Two options I see:

**Option A: Add methods to existing NotePlayer protocol**
```swift
protocol NotePlayer {
    func play(frequency:, duration:, velocity:, amplitudeDB:) async throws  // existing
    func stop() async throws                                                  // existing
    func startContinuousPlayback(frequency:, velocity:, amplitudeDB:) async throws  // new
    func updateFrequency(_ frequency: Double) async throws                         // new
}
```

**Option B: Separate protocol for continuous playback**
```swift
protocol ContinuousNotePlayer {
    func startContinuousPlayback(frequency:, velocity:, amplitudeDB:) async throws
    func updateFrequency(_ frequency: Double) async throws
    func stopContinuousPlayback() async throws
}
```

`SoundFontNotePlayer` would conform to both.

I lean toward **Option A** ‚Äî it's the same audio engine, the same implementation class, and splitting the protocol adds indirection without real benefit. The `SoundFontNotePlayer` already has pitch-bend capability (¬±2 semitones, which covers the ¬±100 cent offset range).

### 3. PitchMatchingRecord Data Model

New SwiftData `@Model`:

```swift
@Model
final class PitchMatchingRecord {
    var referenceNote: Int        // MIDI note (0-127) ‚Äî exact, no cent offset
    var initialCentOffset: Double // Starting offset of tunable note (¬±100 cents)
    var userCentError: Double     // Signed cent error: user's final pitch minus reference
    var timestamp: Date
}
```

The PRD says "reference note, user's final pitch, error in cents, timestamp." I'm proposing we store `initialCentOffset` as well ‚Äî it's cheap and enables future analysis (were users better at matching when starting sharp vs flat?). The "user's final pitch" is derivable from `referenceNote + userCentError`.

**Question for you:** Do we want to store the initial offset, or keep it minimal per PRD? My instinct says store it ‚Äî data you didn't collect is gone forever.

### 4. Observer Pattern ‚Äî PitchMatchingObserver

```swift
protocol PitchMatchingObserver {
    func pitchMatchingCompleted(_ result: CompletedPitchMatching)
}
```

With a value type:

```swift
struct CompletedPitchMatching {
    let referenceNote: Int
    let initialCentOffset: Double
    let userCentError: Double
    let timestamp: Date
}
```

Conforming types: `TrainingDataStore` (saves `PitchMatchingRecord`), and potentially a future `PitchMatchingProfile`. No haptic observer for v0.2 (UX spec says no haptics for pitch matching).

### 5. Separate Profile Tracking

The UX spec is explicit: "Comparison training and pitch matching results are stored and tracked independently." Two skills, two profiles.

For v0.2, I'm thinking we **don't** need a full `PitchMatchingProfile` analogous to `PerceptualProfile`. The PRD has no adaptive algorithm for pitch matching ‚Äî it's random note, random offset. There's no per-note-indexed profile structure feeding back into selection.

What we do need for the Profile Screen is to display matching accuracy (mean/stddev of `|userCentError|`). That can be computed directly from `PitchMatchingRecord` data ‚Äî possibly by extending `TrendAnalyzer` or adding a lightweight `PitchMatchingStats` computed aggregate.

**Proposal:** Defer a full `PitchMatchingProfile` until adaptive pitch matching is needed. For v0.2, compute aggregate stats on the fly from stored records.

### 6. TrainingDataStore Extension

Extend the existing `TrainingDataStore` rather than creating a new store. It's already the sole SwiftData accessor ‚Äî splitting that would create two data access points.

Add:
- `save(_ record: PitchMatchingRecord) throws`
- `fetchAllPitchMatching() throws -> [PitchMatchingRecord]`
- `deleteAllPitchMatching() throws`
- Conformance to `PitchMatchingObserver`

Register `PitchMatchingRecord.self` in the `ModelContainer` schema in `PeachApp.swift`.

### 7. Project Structure

```
PitchMatching/                          # New feature directory
‚îú‚îÄ‚îÄ PitchMatchingSession.swift          # State machine
‚îú‚îÄ‚îÄ PitchMatchingScreen.swift           # UI
‚îú‚îÄ‚îÄ PitchMatchingChallenge.swift        # Value type (reference note + offset)
‚îú‚îÄ‚îÄ PitchMatchingObserver.swift         # Observer protocol
‚îú‚îÄ‚îÄ PitchMatchingFeedbackIndicator.swift # Arrow + cents UI
‚îî‚îÄ‚îÄ VerticalPitchSlider.swift           # Custom DragGesture slider

Core/Data/
‚îú‚îÄ‚îÄ PitchMatchingRecord.swift           # New @Model

PeachTests/PitchMatching/              # Mirror structure
‚îú‚îÄ‚îÄ PitchMatchingSessionTests.swift
‚îî‚îÄ‚îÄ ...
```

### 8. Note Selection (v0.2)

No `NextNoteStrategy` involvement. Random note + random offset is trivially simple ‚Äî it can live as a private method inside `PitchMatchingSession`. No protocol, no abstraction, no separate file. When adaptive matching is needed in the future, extract to a protocol then.

---

**What I'd like your input on before I write the architecture update:**

1. Adding `initialCentOffset` to the record (my recommendation) vs. PRD-minimal?
2. Extending `NotePlayer` directly (Option A) vs. separate protocol (Option B)?
3. Deferring a full `PitchMatchingProfile` for v0.2 ‚Äî agree, or do you want per-note matching stats from day one?
4. Anything I've missed or got wrong?

### üßë Human (15:58:51)

1. PitchMatchingSession State Machine: Looks good for the simple case, but keep in mind that any note playback should stop when the user changes to another screen.
2. NotePlayer Protocol Extension: I don't want a separate protocol. Rather, I'd like to extend the existing protocol to be suitable for the new requirements. I have in mind something where NotePlayer.stop is removed and NotePlayer.play returns an object that can be used to stop the note (only once) and adjust its pitch while it is playing. We need to discuss the details.
3. PitchMatchingRecord Data Model: If there is additional information that could be useful for future analysis, I say we store it.
4. Observer Pattern ‚Äî PitchMatchingObserver: ok
5. Separate Profile Tracking: The original names of some classes are rather broad. I think we need protocols for pitch (difference?) detection and pitch matching. If it is advantageous, both can be conformed to by the same PerceptualProfile.
6. TrainingDataStore Extension: extend the existing store
7. Project Structure: ok
8. Note Selection: ok

Regarding your questions
1: see above
2: see above
3: I'd like to have a profile for pitch matching in scope for v0.2. Ideally, it can be shown on the existing Profile Screen and be integrated with existing data. We still need to do the UX design for this later on.

### ü§ñ Assistant (16:00:59)

Good feedback across the board. Let me dig into the two areas that need collaborative design: the **NotePlayer redesign** and the **profile protocol split**. These are the two decisions with the most architectural ripple.

---

## NotePlayer Redesign ‚Äî PlaybackHandle Pattern

Your instinct is strong here. The current API has an ambient `stop()` that doesn't know *which* note it's stopping. The handle pattern makes ownership explicit: you start a note, you get back an object that controls *that specific playback*.

Here's my concrete proposal:

```swift
protocol PlaybackHandle {
    /// Stops playback. First call sends noteOff; subsequent calls are no-ops.
    func stop() async throws
    /// Adjusts frequency of the currently playing note in real time.
    /// Caller passes absolute frequency in Hz; implementation computes
    /// the relative pitch bend from the base note.
    func adjustFrequency(_ frequency: Double) async throws
}

protocol NotePlayer {
    /// Starts playing a note at the given frequency. Returns immediately
    /// after onset. The caller owns the returned handle and is responsible
    /// for stopping playback.
    func play(frequency: Double, velocity: UInt8, amplitudeDB: Float) async throws -> PlaybackHandle
}
```

**Key design choices:**

1. **Duration removed from `play()`** ‚Äî the caller manages timing. For fixed-duration notes (comparisons), `TrainingSession` does:
   ```swift
   let handle = try await notePlayer.play(frequency: f, velocity: v, amplitudeDB: a)
   try await Task.sleep(for: .seconds(duration))
   try await handle.stop()
   ```
   For indefinite notes (pitch matching), `PitchMatchingSession` holds the handle until slider release.

2. **`play()` is still `async throws`** ‚Äî the `async` covers setup (engine start, preset loading), not duration. It returns as soon as the note is audibly playing.

3. **`adjustFrequency()` takes absolute Hz** ‚Äî the caller doesn't need to know about MIDI pitch bend internals. The `SoundFontPlaybackHandle` internally tracks the base MIDI note and computes the relative pitch bend to reach the target frequency. The ¬±100 cent offset fits comfortably within the standard ¬±2-semitone (¬±200 cent) pitch bend range.

4. **Single-use `stop()`** ‚Äî first call sends MIDI noteOff. Subsequent calls are no-ops. This prevents double-noteOff issues and makes cleanup code idempotent (important for interruption paths where multiple things might try to stop).

5. **`PlaybackHandle` is a protocol** ‚Äî enables `MockPlaybackHandle` in tests. `SoundFontNotePlayer` returns a `SoundFontPlaybackHandle`; `MockNotePlayer` returns a `MockPlaybackHandle`.

**Impact on TrainingSession:**

This is a refactoring of the existing training loop. Currently `play()` awaits the full duration. With the handle pattern, `TrainingSession` explicitly manages note lifetime:

```
playingNote1: handle1 = play(freq1) ‚Üí sleep(duration) ‚Üí handle1.stop()
playingNote2: handle2 = play(freq2) ‚Üí sleep(duration) ‚Üí handle2.stop()
```

The session holds a `currentHandle: PlaybackHandle?` reference for interruption cleanup ‚Äî `stop()` always calls `currentHandle?.stop()`.

**Impact on PitchMatchingSession:**

```
playingReference: refHandle = play(refFreq) ‚Üí sleep(duration) ‚Üí refHandle.stop()
playingTunable:   tunableHandle = play(tunableFreq) ‚Üí user drags ‚Üí tunableHandle.adjustFrequency(newFreq) ‚Üí user releases ‚Üí tunableHandle.stop()
```

**Questions for you:**

- Does the name `PlaybackHandle` feel right? Alternatives: `NoteHandle`, `PlayingNote`, `Playback`.
- Should the handle auto-stop on deallocation (deinit safety net)? I'd lean no for v0.2 ‚Äî all code paths explicitly stop, and `deinit` can't be async. But it's worth discussing.
- The `play()` function no longer `await`s the note's full duration ‚Äî it returns immediately after onset. This changes every call site in `TrainingSession`. Are you comfortable with that scope of refactoring?

---

## Profile Protocol Split

The current `PerceptualProfile` mixes two concerns that are about to diverge. Your suggestion to split into protocols with a shared backing class is the right call.

**Proposed protocols:**

```swift
protocol PitchDiscriminationProfile {
    /// Updates with a comparison result (existing behavior)
    func update(note: Int, centOffset: Double, isCorrect: Bool)
    func weakSpots(count: Int) -> [Int]
    var overallMean: Double? { get }
    var overallStdDev: Double? { get }
    func statsForNote(_ note: Int) -> PerceptualNote
    func averageThreshold(midiRange: ClosedRange<Int>) -> Int?
    func setDifficulty(note: Int, difficulty: Double)
    func reset()
}

protocol PitchMatchingProfile {
    /// Updates with a pitch matching result
    func updateMatching(note: Int, centError: Double)
    /// Overall mean absolute matching error
    var matchingMean: Double? { get }
    /// Overall standard deviation of matching error
    var matchingStdDev: Double? { get }
    /// Sample count for matching
    var matchingSampleCount: Int { get }
    func resetMatching()
}
```

**`PerceptualProfile` conforms to both:**

```swift
@Observable
final class PerceptualProfile: PitchDiscriminationProfile, PitchMatchingProfile {
    // Existing 128-slot noteStats array for discrimination
    // New aggregate stats for matching (overall, not per-note for v0.2)
}
```

**For v0.2 matching stats:** I'd start with overall aggregates only (mean, stddev, count). Per-note matching breakdown can come when/if the data shows meaningful per-note variation. This keeps the matching side of the profile lightweight while the protocol allows expansion.

**The architectural boundary:** Views and services declare which protocol they need:
- `TrainingSession` depends on `PitchDiscriminationProfile`
- `PitchMatchingSession` depends on `PitchMatchingProfile`
- `ProfileScreen` depends on both (shows discrimination visualization + matching stats)
- `NextNoteStrategy` depends on `PitchDiscriminationProfile`

**Loading on startup:** Same pattern ‚Äî `PerceptualProfile` is rebuilt from both `ComparisonRecord` (discrimination) and `PitchMatchingRecord` (matching) on app startup.

**Observer conformance:** `PerceptualProfile` conforms to both `ComparisonObserver` and `PitchMatchingObserver` ‚Äî it receives results from both training modes and updates the appropriate internal state.

---

**Open question:** The naming `PitchDiscriminationProfile` / `PitchMatchingProfile` ‚Äî these align with the PRD language ("passive discrimination vs. active production"). Do they feel right, or do you prefer different terms?

**Once you're happy with the NotePlayer handle pattern and the profile split, I'll write the architecture document update covering all decisions.** Let me know what to adjust.

### üßë Human (16:00:59)

I almost forgot: Some of the old names have become too broad. Before we can work on new features, we ought to bring the existing code and docs into shape while keeping the new features in mind.

### ü§ñ Assistant (16:02:03)

You're absolutely right. With two training modes, several names that were fine for a single-mode app now create ambiguity. Let me audit what needs tightening.

## Naming Audit

**Clearly too broad ‚Äî will cause confusion with Pitch Matching present:**

| Current Name | Problem | Proposed Rename |
|---|---|---|
| `TrainingSession` | Only handles comparisons, but sounds like it handles all training | `ComparisonSession` |
| `TrainingState` (enum inside) | States are comparison-specific | `ComparisonSessionState` |
| `TrainingScreen` | The comparison UI, not all training | `ComparisonScreen` |
| `Training/` directory | Feature directory for comparison training | `Comparison/` |
| `FeedbackIndicator` | Shows thumbs up/down ‚Äî comparison-specific | `ComparisonFeedbackIndicator` |

**Borderline ‚Äî could argue either way:**

| Current Name | Keep or Rename? | Reasoning |
|---|---|---|
| `TrainingDataStore` | **Keep** | Stores all training data ‚Äî both comparison and matching records. "Training" here means "ear training," which encompasses both modes. It's the single data access point. |
| `TrainingSettings` | **Keep for now** | Note range, reference pitch, note duration apply to both modes. `naturalVsMechanical` and `min/maxCentDifference` are comparison-specific, but pitch matching doesn't need its own settings struct yet. Revisit when it does. |
| `NextNoteStrategy` | **Rename ‚Üí `ComparisonStrategy`?** | Its method is `nextComparison()` and it returns a `Comparison`. The name says "note" but it produces comparisons. However, this rename is lower priority ‚Äî the method signature already makes the scope clear. |
| `DifficultyDisplayView` | **Keep or rename** | Shows the cent difference being tested in comparison mode. It's already narrow in purpose. |
| `ComparisonObserver` | **Keep** | Already specific. |
| `Comparison` / `CompletedComparison` | **Keep** | Already specific. |
| `PerceptualProfile` | **Keep as class name** | The concrete class conforms to both `PitchDiscriminationProfile` and `PitchMatchingProfile`. The name is broad, but the class legitimately covers both. |
| `NotePlayer` / `PlaybackHandle` | **Keep** | Generic by design ‚Äî serves both training modes. |

**Already specific enough ‚Äî no change needed:**
- `ComparisonRecord`, `ComparisonObserver`, `Comparison`, `CompletedComparison`
- `KazezNoteStrategy`, `AdaptiveNoteStrategy`
- `SoundFontNotePlayer`, `SoundFontLibrary`, `SF2PresetParser`
- `HapticFeedbackManager` (comparison-only, but the name doesn't claim "training")
- `PerceptualNote`, `TrendAnalyzer`, `ThresholdTimeline`

**Documents that would need updating:**
- `docs/planning-artifacts/architecture.md` ‚Äî references `TrainingSession`, `TrainingScreen` throughout
- `docs/project-context.md` ‚Äî references `TrainingSession` as the central state machine, `TrainingScreen`, state names
- Implementation artifact stories that reference old names

---

**My recommendation for the rename scope:**

The must-do renames are the top five (`TrainingSession` ‚Üí `ComparisonSession`, `TrainingState` ‚Üí `ComparisonSessionState`, `TrainingScreen` ‚Üí `ComparisonScreen`, `Training/` ‚Üí `Comparison/`, `FeedbackIndicator` ‚Üí `ComparisonFeedbackIndicator`). These are the ones where the current name will actively mislead when Pitch Matching exists alongside.

`NextNoteStrategy` ‚Üí `ComparisonStrategy` is nice-to-have but lower priority. The method signature makes its scope unambiguous.

What's your take on the scope? And do you want the rename to be a separate prerequisite step (refactor first, then add Pitch Matching), or documented as part of this architecture update with implementation later?

### üßë Human (16:15:05)

* "Should the handle auto-stop on deallocation (deinit safety net)? I'd lean no for v0.2": ok
* "The play() function no longer awaits the note's full duration ‚Äî it returns immediately after onset. This changes every call site in TrainingSession. Are you comfortable with that scope of refactoring?": For compatibility we should keep the old method in the protocol, but implement it using PlaybackHandle.
* "Profile Protocol Split": agree
* "The naming PitchDiscriminationProfile / PitchMatchingProfile": I like those names
* I almost completely agree With your suggested renamings. Exception: NextNoteStrategy -> NextComparisonStrategy

Did I miss anything?

### ü§ñ Assistant (16:16:03)

I think you've covered everything. Let me confirm the complete decision set:

**Agreed decisions:**

1. **PitchMatchingSession** ‚Äî `idle` ‚Üí `playingReference` ‚Üí `playingTunable` ‚Üí `showingFeedback` ‚Üí loop. Stops on navigation/background/interruption.
2. **NotePlayer redesign** ‚Äî new `play()` returns `PlaybackHandle` (with `stop()` + `adjustFrequency()`). Old `play(frequency:duration:...)` stays in the protocol as a convenience, implemented via the handle internally.
3. **PitchMatchingRecord** ‚Äî referenceNote, initialCentOffset, userCentError, timestamp.
4. **PitchMatchingObserver** protocol + `CompletedPitchMatching` value type.
5. **Profile split** ‚Äî `PitchDiscriminationProfile` + `PitchMatchingProfile` protocols, both conformed to by `PerceptualProfile`.
6. **TrainingDataStore** ‚Äî extend with pitch matching CRUD.
7. **Project structure** ‚Äî `PitchMatching/` feature directory.
8. **Note selection** ‚Äî random, private method in session, no protocol for v0.2.
9. **Prerequisite renames** ‚Äî `ComparisonSession`, `ComparisonSessionState`, `ComparisonScreen`, `Comparison/` directory, `ComparisonFeedbackIndicator`, `NextComparisonStrategy`.
10. **No deinit safety** on PlaybackHandle for v0.2.
11. **PlaybackHandle** as the name.

Anything I'm misrepresenting? If this looks right, I'll write the architecture document update.

### üßë Human (16:17:48)

Looks good. Remember to also update docs/planning-artifacts/glossary.md

### ü§ñ Assistant (16:23:27)

Excellent ‚Äî all decisions locked in. Let me write the architecture document amendment and glossary update now.

### ü§ñ Assistant (16:24:31)

Good ‚Äî frontmatter updated and glossary written. Now appending the v0.2 architecture amendment section.

### ü§ñ Assistant (16:26:33)

All three files updated. Let me do a quick sanity check on the results.

### ü§ñ Assistant (16:26:49)

Everything looks solid. Here's the summary of what was written:

---

**Architecture document** (`docs/planning-artifacts/architecture.md`) ‚Äî 455 ‚Üí 910 lines:
- Frontmatter: status changed to `amended`, added `amendedAt` date and UX spec to input documents
- New section "v0.2 Architecture Amendment ‚Äî Pitch Matching" covering:
  - **Prerequisite Renames** ‚Äî 6 renames with rationale, plus explicit list of unchanged names
  - **NotePlayer Redesign** ‚Äî `PlaybackHandle` protocol, updated `NotePlayer` protocol, default extension for fixed-duration convenience, design rationale
  - **PitchMatchingSession** ‚Äî state machine (4 states), transition flow, interruption handling, dependencies
  - **PitchMatchingRecord** ‚Äî SwiftData model with 4 fields
  - **PitchMatchingObserver** ‚Äî protocol + `CompletedPitchMatching` value type
  - **Profile Protocol Split** ‚Äî `PitchDiscriminationProfile` + `PitchMatchingProfile`, dependency boundaries
  - **TrainingDataStore Extension** ‚Äî new CRUD methods, schema update
  - **Note Selection** ‚Äî random for v0.2, `PitchMatchingChallenge` value type
  - **Updated Project Structure** ‚Äî full directory listing with new/renamed/updated annotations
  - **Updated Requirements Mapping** ‚Äî FR44-FR52 mapped to components
  - **Updated Cross-Cutting Concerns** ‚Äî pitch matching interruption, note ownership
  - **Implementation Sequence** ‚Äî 8 ordered steps
  - **Validation** ‚Äî compatibility, consistency, backward compat, coverage, gap analysis

**Glossary** (`docs/planning-artifacts/glossary.md`) ‚Äî 85 ‚Üí 107 lines:
- Renamed entries: Next Comparison Strategy, Comparison Session, Comparison Session State, Comparison Screen, Comparison Feedback Indicator
- Updated entries: Perceptual Profile (both protocols), Start Screen, Haptic Feedback, Audio Interruption, Reference Pitch, Note Range, Training Settings, Profile Screen
- New section: **Audio** (Note Player, Playback Handle, Indefinite Playback)
- New entries across existing sections: Pitch Matching, Pitch Matching Challenge, Completed Pitch Matching, Initial Cent Offset, User Cent Error, Pitch Discrimination Profile, Pitch Matching Profile, Pitch Matching Session, Pitch Matching Session State, Pitch Matching Observer, Pitch Matching Screen, Pitch Matching Button, Vertical Pitch Slider, Pitch Matching Feedback Indicator

Ready for your review, Michael.

### üßë Human (16:30:46)

commit

### ü§ñ Assistant (16:31:37)

Committed as `9843da5`. Working tree clean.

4 files committed together ‚Äî architecture amendment, glossary update, PRD, and UX spec ‚Äî all part of the same v0.2 pitch matching planning effort.

Anything else you'd like to do with this, Michael? The architecture is ready for implementation ‚Äî the amendment includes an 8-step implementation sequence starting with the prerequisite renames.

---

[‚Üê Previous (b4ff06222a)](b4ff06222a.md) | [Index](index.md) | [Next (3e007de7eb) ‚Üí](3e007de7eb.md)
