---
commit: "aa1f2b899cb5aa466813b3b18b919171acedb1aa"
date: "2026-02-24T01:23:16+01:00"
author: "Michael Sch√ºrig <michael@schuerig.de>"
subject: "Add Epic 9 and story 9.1: Promote KazezNoteStrategy to default"
sessions: ["49dde351-6f8d-4e9c-9b01-90bb22c0ff51"]
prev: "855f825e36.md"
next: "8434cba54a.md"
---

[‚Üê Previous (855f825e36)](855f825e36.md) | [Index](index.md) | [Next (8434cba54a) ‚Üí](8434cba54a.md)

# Commit aa1f2b899c

**Date:** 2026-02-24 01:23:16 UTC+01:00  
**Author:** Michael Sch√ºrig <michael@schuerig.de>

## Commit message

Add Epic 9 and story 9.1: Promote KazezNoteStrategy to default

Based on brainstorming session with perceptual learning literature
review. Pitch discrimination is one unified skill ‚Äî the simpler
KazezNoteStrategy (continuous difficulty chain with frequency roving)
replaces AdaptiveNoteStrategy as the default training strategy.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>

## Changed files

```
.../brainstorming-session-2026-02-24.md            | 156 +++++++++++++++++
 .../9-1-promote-kazeznotestrategy-to-default.md    | 189 +++++++++++++++++++++
 docs/implementation-artifacts/sprint-status.yaml   |   5 +
 docs/planning-artifacts/epics.md                   |  61 +++++++
 4 files changed, 411 insertions(+)
```

## Session `49dde351‚Ä¶`

*2026-02-23 23:03:54 UTC ‚Üí 2026-02-24 00:23:34 UTC*

### üßë Human (23:03:54)

<command-message>bmad-brainstorming</command-message>
<command-name>/bmad-brainstorming</command-name>
<command-args>I'm not yet completely happy with the current AdaptiveNoteStrategy. The distinction between "natural" and "mechanical" is not intuitive. I'd like to explore some other ideas.</command-args>

### ü§ñ Assistant (23:04:35)

Welcome Michael! I'm excited to facilitate your brainstorming session. I'll guide you through proven creativity techniques to generate innovative ideas and breakthrough solutions.

You've already given me a great starting point - you're rethinking the **AdaptiveNoteStrategy** and feel the "natural" vs. "mechanical" distinction isn't intuitive. That's a strong creative instinct to follow.

**Let's set up your session for maximum creativity and productivity:**

**Session Discovery Questions:**

1. **What are we brainstorming about?** From your input, it sounds like we're exploring alternative conceptual models/strategies for how notes are played or rendered - moving beyond the current "natural vs. mechanical" framing. Is that right, or is there a broader scope you'd like to cover?

2. **What specific outcomes are you hoping for?** For example:
   - A single clearer conceptual model to replace natural/mechanical?
   - Multiple alternative naming/framing approaches to evaluate?
   - A rethink of the entire strategy pattern and what dimensions it should capture?
   - Something else entirely?

Take your time - the clearer we frame the challenge, the better our ideation will be.

### üßë Human (23:16:56)

The result should be a story detailed enough to add another implementation of NextNoteStrategy. What I'd like to capture is the idea of an algorithm that drills me with adjustable levels of insistence, for lack of a better word (please make suggestions!).

At one end, only ever moves around +/- 4 semitones (say) from the current note, no matter how many mistakes I make
At the other end, the algorithm jumps to the next weak spot as soon as I make the first mistake.

Mistakes could be counted as number of mistakes in a row or number of mistakes in the last (say) 10 comparisons.

This differs most markedly from our AdaptiveNoteStrategy, in that the AdaptiveNoteStrategy does not take into account the correctness of the previous answer when selecting a note.

### ü§ñ Assistant (23:17:03)

**Session Analysis:**

Based on your input, I understand we're focusing on **designing a new NextNoteStrategy implementation that adjusts note selection based on recent performance** - specifically a "drilling" algorithm with a tunable parameter that controls how aggressively it jumps to weak spots vs. staying in the neighborhood of the current note.

**Session Parameters:**

- **Topic Focus:** A new NextNoteStrategy that reacts to mistake patterns, with a tunable "insistence" dial from gentle neighborhood exploration to aggressive weak-spot targeting
- **Primary Goals:** 
  - Find the right conceptual framing and naming for the tunable parameter
  - Define the algorithm's behavior at both ends of the spectrum
  - Clarify how mistakes are counted (consecutive vs. rolling window)
  - Produce a story detailed enough to implement

**Does this accurately capture what you want to achieve?** Before we dive in, let me also quickly understand the existing codebase so our ideas are grounded.

Let me look at the current strategies to make sure I have the right context.

### ü§ñ Assistant (23:18:05)

Excellent context gathered. Now I have a clear picture of the architecture. Let me update the session document and then we'll dive in.

### ü§ñ Assistant (23:18:31)

Good - session is set up. Now let's get creative.

Given what you've described, I think we have two meaty brainstorming threads to pull on. Let me recommend we tackle them in this order:

**Thread 1: Naming the parameter** - The "insistence" concept needs a name that's intuitive to a musician sitting in a settings screen.

**Thread 2: Mistake-counting model** - Consecutive vs. rolling window has real UX and algorithmic implications.

Let me kick off Thread 1 with some initial provocations. I'll group them by metaphor domain:

---

### Naming the tunable parameter

**Music practice metaphors:**
1. **Tenacity** - how tenaciously the algorithm pursues a weak spot
2. **Focus** - how tightly focused vs. wandering the practice is
3. **Drill Intensity** - straightforward, but two words
4. **Rigor** - how rigorous the practice session is
5. **Persistence** - how persistently it stays on a problem area

**Teacher/coach metaphors:**
6. **Strictness** - a strict teacher jumps on every mistake; a lenient one lets you keep flowing
7. **Patience** - inverted: a patient coach lets you work through it, an impatient one intervenes
8. **Coaching Style** - from "encouraging" to "demanding"
9. **Vigilance** - how closely the algorithm watches for slip-ups

**Physical training metaphors:**
10. **Grip** - loose grip lets you roam, tight grip locks you onto weak spots
11. **Traction** - how much "pull" mistakes exert on note selection
12. **Gravity** - weak spots have gravitational pull; parameter controls field strength

**Navigation metaphors:**
13. **Roaming vs. Homing** - roam freely vs. home in on weaknesses
14. **Drift** - how much the algorithm drifts vs. locks on
15. **Leash Length** - short leash = stays close / corrects fast; long leash = free exploration

**Dial/spectrum labels (for the UI):**
16. **Gentle ... Relentless**
17. **Flowing ... Drilling**
18. **Exploratory ... Targeted**
19. **Patient ... Insistent**
20. **Relaxed ... Intense**

---

That's the first 20 - and as we know, the obvious ones. A few of these spark something for me, but I want to hear from you first:

**Which of these resonate? Which feel completely wrong?** Even a "I hate #7 but I'm drawn to something in the direction of #12" is useful - it helps me understand the vibe you're after. And of course, throw in your own if anything came to mind while reading.

### üßë Human (23:32:20)

Right now, none of them resonate. It sounds all too strict. It is not the case that the one behavior is more demanding than the other. I'm trying to determine if it is a good idea at all, to use the two different behaviors as ends of a scale. Do users get exhausted if the algorithm belabors a task where they do not make any progress? Do users get distracted if the algorithm jumps around with varying difficulties?

We need to widen this brainstorming! Don't get overly attached to my initial statement.

Ideally, the algorithm presents the user with comparisons where they quickly progress to the current threshold of their ability to distinguish notes. The whole aim of the app is to decrease that threshold. What is the best strategy to do that? Stay close by with each new comparison? Narrowing and widening the difficulty as the user answers. When does the algorithm decide that the user is not making any more progress in this note neighborhood and it is time to jump somewhere else with whatever threshold is recorded in the PerceptualProfile for that area?

### ü§ñ Assistant (23:33:08)

You're absolutely right - I was anchoring too hard on your initial framing. Let me blow this wide open. The real question is much more interesting:

**What is the optimal note selection strategy for reducing a user's discrimination threshold as efficiently as possible?**

Let me reframe completely. Here are genuinely different directions for how a strategy could work:

---

### Direction A: Plateau Detection + Rotation

Forget a dial. The algorithm has one job: **converge at the current note, detect when progress stalls, move on.**

- Stay at a note region, letting Kazez do its convergence work
- Detect plateau: "difficulty hasn't moved more than X% in the last N comparisons"
- On plateau: rotate to a different region (nearest undertrained, or weakest, or random)
- Return later with fresh ears - the spacing effect suggests this actually helps

**Key question:** What counts as a plateau? Ideas:
- Statistical: recent variance in difficulty drops below a threshold
- Simple counter: N comparisons without meaningful improvement
- Rate-based: improvement per comparison drops below a floor

---

### Direction B: Explore/Exploit (Multi-Armed Bandit)

Each note region is an "arm." The algorithm maximizes **threshold improvement rate** across the whole profile.

- "Reward" = how much the threshold dropped per comparison in this region
- Explore: try regions we haven't visited recently (uncertain reward)
- Exploit: stay in regions where we're currently making fast progress
- Classic algorithms exist: UCB1, Thompson Sampling, epsilon-greedy

This naturally handles the "when to move on" question - you move when the reward (improvement rate) drops relative to other regions.

---

### Direction C: Spaced Repetition for Ear Training

Borrow from Anki/SuperMemo. Each note gets a "review interval."

- Train a note until it reaches some intermediate milestone
- Schedule it for re-testing later (interval grows with mastery)
- Between reviews, work on other notes
- If a note regresses on review, shorten its interval

This addresses a question you haven't raised yet but matters: **do thresholds at a note degrade over time without practice?** If yes, spaced repetition is exactly the right model.

---

### Direction D: Zone Progression

Think of the MIDI range as a map. The algorithm **expands a frontier of mastery.**

- Start at one note (or a small cluster)
- Master it to some target threshold
- Expand to adjacent notes, borrowing the learned difficulty
- Weak spots behind the frontier get revisited
- The user sees a growing "mastered region" - very motivating

This is closest to the "natural" end of your original idea but with clear progression logic.

---

### Direction E: Interleaved Practice (Learning Science)

Research on motor learning consistently shows: **interleaving similar-but-different tasks beats drilling one task repeatedly**, even though it *feels* less effective in the moment.

- Deliberately rotate between 3-5 note regions per session
- Mix difficulties: some near-threshold, some easier (confidence builders), some exploratory
- The "struggle" of context-switching between regions actually deepens learning
- This would mean the algorithm *never* stays at one note for long - by design

**Counterintuitive implication:** The "exhausting belaboring" you worried about might genuinely be worse for learning, not just for mood.

---

### Direction F: Convergence-Aware Hybrid

Don't make it a setting. Make it **one smart algorithm** that adapts automatically:

- Start each note visit with the Kazez convergence chain
- Monitor convergence rate in real-time
- **Fast convergence** (big threshold drops): stay, this is productive
- **Slow convergence** (plateauing): move to another region
- **Regression** (threshold going back up): the user is fatigued or distracted at this note, definitely move
- Weave in interleaving principles: even during fast convergence, occasionally visit another note to prevent habituation

The "tunable parameter" here isn't about insistence - it's about **how sensitive the plateau detector is** and **how many regions to interleave**.

---

That's six genuinely different directions. Some could be combined. Before I generate more ideas within any of these, I want to hear:

1. **Which directions excite you?** Even partially?
2. **Is threshold regression real in your domain?** (Does a trained note get worse without practice?)
3. **How long is a typical session?** That affects whether interleaving even has room to work.
4. **Do you want one "correct" algorithm, or a user-tunable one?** Your original instinct was tunable, but Direction F suggests maybe the algorithm should just be smart.

### üßë Human (23:45:43)

I expect the threshold to be roughly the same over most of the range, except for the very ends. That means we are not dealing with separated tasks that are learned, but with a single task with one slightly varying parameter. That makes it slightly annoying to have large jumps in difficulty. The perceptual thresholds don't have these differences. Thresholds can vary considerably from day to day, even from session to session on the same day. It is quite possible to achieve 3 cents in one session and get stuck at 8 cents in the next -- or the other way around. This is normal.

### ü§ñ Assistant (23:46:26)

This changes everything. Let me make sure I'm absorbing the full implications:

**If pitch discrimination is essentially one skill with one threshold that applies roughly uniformly across the range, then:**

- "Weak spots" in the profile are mostly **data collection artifacts**, not real perceptual differences
- Jumping to a "weak spot" and encountering a different difficulty is annoying because **the difficulty mismatch is fake** - it's stale or sparse data, not the user actually being worse there
- The Kazez convergence chain is doing the real work - it finds today's threshold
- Session-to-session variance (3 cents vs. 8 cents) means **yesterday's profile data is unreliable** as a starting point for today

This raises a question that might upend the whole strategy design:

---

### Why move between notes at all?

If it's one skill, the most efficient thing might be to:
- Pick a note
- Converge to today's threshold with Kazez
- Done. You now know the user's current ability.

But you obviously don't do that - you move around. So what's the **actual value** of moving between notes? Let me throw out candidates:

1. **Verification** - confirm the threshold is indeed uniform, catch the edge-of-range differences
2. **Boredom prevention** - hearing the same frequency 50 times is numbing
3. **Habituation avoidance** - psychoacoustically, prolonged exposure to one frequency may distort perception
4. **Profile completeness** - collecting data across the range for a meaningful profile display
5. **Training transfer** - maybe practicing discrimination at different frequencies does strengthen the overall skill slightly differently?
6. **Warm-up** - early comparisons at the start of a session are noisy; spreading across notes means no single note eats all the warm-up noise

**Which of these are real reasons for Peach?** This matters because the answer shapes the entire note selection strategy. For instance:

- If it's mainly **(2) and (3)** - boredom and habituation - then you want gentle drift through nearby notes, and the key parameter is **how far apart consecutive notes should be** and **how often to move**. No jumps, no weak spots, just a slow wander.

- If it's mainly **(1) and (4)** - verification and profile completeness - then you want systematic coverage with enough samples per note for statistical confidence, and the key question is **minimum samples per note before moving on**.

- If it's mainly **(5)** - training transfer - then interleaving research applies and you want deliberate variety.

---

### A completely different framing

Given what you've told me, maybe the strategy isn't about "which note has the worst threshold" at all. Maybe it's about:

**How does the algorithm maintain a smooth, converging difficulty chain while gently wandering through the note range?**

The Kazez chain is the star. Note selection is just the stage it performs on. The strategy question becomes:

- **How far to move** between consecutive comparisons (¬±2? ¬±4? ¬±12?)
- **When to move** (every comparison? every N comparisons? randomly?)
- **How to handle the cold-start problem** when visiting a note region for the first time today (borrow the current chain difficulty rather than the stale profile data?)

That last point might be the real insight: **the convergence chain should be continuous across note changes.** Don't reset difficulty when you move to a new note - carry today's converged difficulty with you. The profile's per-note data is for long-term tracking, not for driving today's difficulty.

---

What's your reaction to this reframing? And which of the "why move at all" reasons are the real ones for Peach?

### üßë Human (23:53:10)

What you describe is very close to what we already implemented in Peach/Core/Algorithm/KazezNoteStrategy.swift . That is a much simpler strategy and possibly just what we need.

### ü§ñ Assistant (23:53:25)

Let me re-read it to make sure we're both looking at the same thing.

### ü§ñ Assistant (23:53:43)

Right. So KazezNoteStrategy already does exactly the core of what we've been circling:

- **Single continuous difficulty chain** - carries difficulty across note changes via `lastComparison`
- **Ignores the PerceptualProfile for note selection** - no "weak spots"
- **Stateless** - no internal state to manage

The gaps between this and a "real training strategy" are small and concrete:

1. **Random note selection across the full range** - can jump from MIDI 48 to MIDI 72 in one step. You said that's annoying. Gentle wandering would be better.
2. **Hardcoded range** (C3-C5) - should respect `settings.noteRangeMin/Max`
3. **Cold start always at `maxCentDifference`** (100 cents) - wasteful if the user was at 5 cents yesterday. Could borrow from the profile to start closer.
4. **Doesn't write back to the profile** - the strategy itself doesn't call `setDifficulty`, though the observer chain still records comparisons.

So the brainstorming question has shifted from "what complex new algorithm do we need?" to something much more focused:

**Is the right move to evolve KazezNoteStrategy into a proper training strategy with gentle note wandering and a smarter cold start?**

If yes, the design decisions are:

- **Note movement:** Random within ¬±N semitones of the last note (where N might be 4-6)? Or a slow random walk through the range?
- **Cold start:** Borrow from profile's nearest trained neighbor? Or from `overallMean`? Or just start at `maxCentDifference` and let Kazez converge fast (it takes ~10 correct answers)?
- **Profile interaction:** Still record to the profile via observer (already works). Use profile data only for cold start and UI display, not for note selection?
- **What happens to AdaptiveNoteStrategy?** Replace it? Keep it as an alternative? Deprecate it?

Or are we getting ahead of ourselves - do you want to keep exploring whether something more sophisticated is warranted? Or does "KazezNoteStrategy + gentle wandering + smart cold start" feel like it might just be the answer?

### üßë Human (23:55:38)

Random note selection is not annoying in itself. The annoying thing is that it was combined with jumping difficulty.

### ü§ñ Assistant (23:55:53)

That's a crucial distinction. So the KazezNoteStrategy's random note selection is actually **already fine** - because it carries difficulty across note changes. The chain stays smooth regardless of where the note lands.

Which means KazezNoteStrategy is almost exactly what you want, with only these gaps:

1. **Hardcoded range** (MIDI 48-72) instead of respecting `settings.noteRangeMin/Max`
2. **Cold start at 100 cents** instead of something smarter
3. **Positioned as "evaluation only"** in the code and docs

That's not a new strategy. That's promoting KazezNoteStrategy to production and fixing two small issues.

And it raises a bigger question: **what is AdaptiveNoteStrategy actually buying you over this?** Its whole complexity - weak spots, natural vs. mechanical, weighted effective difficulty, per-note difficulty tracking - seems to be solving a problem that doesn't exist if the threshold is roughly uniform and the chain should be continuous.

So before we write a story for a *new* strategy, should the brainstorming question actually be:

**Should AdaptiveNoteStrategy be replaced by a refined KazezNoteStrategy as the primary training strategy?**

Or is there something AdaptiveNoteStrategy does that you'd miss?

### üßë Human (23:59:52)

I'd like to keep AdaptiveNoteStrategy around in case of new ideas in the future.
Before we switch to KazezNoteStrategy (and improve it), I'd like you to do some research on learning and pitch perception. There are possibly papers about this. Probably mostly regarding players of string instruments, but possibly other orchestral instruments, too. You may delegate this task to another agent if there is one that is particulary suitable.

### ü§ñ Assistant (23:59:56)

Good call - let's ground this in research before committing to a direction. Let me run parallel searches across the relevant domains.

### ü§ñ Assistant (00:08:51)

Excellent research. Let me pull out the findings that directly impact our strategy design:

### Findings that validate the KazezNoteStrategy direction

**Transfer is strong.** Frequency discrimination learning is mostly generalizable across frequencies, with only a small frequency-specific component. This confirms your intuition - it's essentially one skill. A continuous difficulty chain across note changes is the right model.

**Roving is fine (and possibly beneficial).** Amitay et al. (2005) found that wide roving paradoxically didn't hurt compared to narrow roving. Fixed-frequency training converges faster initially but *fails to transfer to roving conditions*. Random note selection isn't just "not harmful" - it may build more robust, generalizable representations.

**Switching frequencies prevents habituation.** Stimulus-specific adaptation is real and frequency-specific. Neural responsiveness to a repeated frequency declines over time. Moving between notes keeps the auditory system fresh. This is a concrete reason to roam.

### Findings that suggest refinements

**Session length matters a lot.** ~100 trials (~8 minutes) maximizes learning-per-trial. Performance *deteriorates* beyond ~400 trials. Between-session consolidation (especially with sleep) does the heavy lifting. This means in a typical session you might only do 100-200 comparisons - the strategy doesn't need to be complex.

**Poor performers benefit from stability.** Amitay found that for poor listeners, any variation slowed learning. This could argue for *less* roving early on - perhaps starting with a narrower note range and widening as the user improves.

**30-minute breaks kill learning, but 6-minute breaks are fine.** Continuous practice within a session matters. The algorithm shouldn't encourage long pauses mid-session.

**Minimum ~360 trials/day for cross-day consolidation.** Below this, learning may not stick across days. Worth knowing for session design, though not directly a strategy concern.

### Implications for the refined KazezNoteStrategy

Given all this, the KazezNoteStrategy approach looks well-supported by the literature. The refinements it needs:

1. **Respect `noteRangeMin/Max`** from settings (trivial fix)
2. **Smarter cold start** - don't waste the first 10 trials converging from 100 cents when the profile says the user was at 5 cents yesterday. Use `overallMean` or nearest trained neighbor as the starting point.
3. **Possibly** narrow the roving range for beginners (high thresholds) and widen it as they improve - but this might be over-engineering given that wide roving wasn't harmful in the research.
4. **The Kazez coefficients** (0.05/0.09) vs. the Adaptive ones (0.08/0.09) - worth considering which are better for a roving paradigm.

### The bigger question for our brainstorming

The research suggests the current KazezNoteStrategy is already close to a scientifically sound training strategy. The `naturalVsMechanical` parameter in AdaptiveNoteStrategy was solving a problem that doesn't really exist.

Should we shift this brainstorming toward **writing the story** for promoting/refining KazezNoteStrategy? Or do any of the research findings spark new ideas you want to explore first?

### üßë Human (00:12:20)

Before we get to a story, document the results of the brainstorming and your research. Include references!

### ü§ñ Assistant (00:13:48)

Done. The session document is at `docs/brainstorming/brainstorming-session-2026-02-24.md`. It covers:

- **The brainstorming journey** - how we went from "design a new complex strategy" to "the simple one is already right"
- **The key reframings** - pitch discrimination as one skill, note jumping vs. difficulty jumping, why move between notes at all
- **Literature review** with findings on transfer, roving, habituation, session length, consolidation, and typical thresholds
- **References** for all cited studies

One thing worth flagging: the research surfaced a tension in session length. Molloy et al. found 100 trials optimal for learning efficiency, but other research suggests a minimum of ~360 trials/day for cross-day consolidation. That's worth keeping in mind for future UX decisions, though it doesn't affect the note selection strategy itself.

Ready to move to the story when you are.

### üßë Human (00:16:36)

Let's write the story. Create a new epic and add it. Later, we will have to rethink how to display and compare the user's ability and progress.

### ü§ñ Assistant (00:17:00)

Now let me check the existing project artifacts to determine epic/story numbering and load the context.

### ü§ñ Assistant (00:17:14)

Now let me load the remaining artifacts I need - the architecture, project context, and the previous story from Epic 8 for recent patterns.

### ü§ñ Assistant (00:17:33)

Now let me check the current settings to understand the `naturalVsMechanical` parameter and how strategies are wired up.

### ü§ñ Assistant (00:17:50)

Good. Now I have all the context. Let me build the epic and story. First, let me update the epics file with Epic 9, then create the story file, then update sprint status.

I'll start with the epic entry. Here's what I'm proposing for **Epic 9: Evidence-Based Training ‚Äî Note Selection Strategy**:

**Stories:**
- **9.1: Promote KazezNoteStrategy to default training strategy** ‚Äî use settings range, smarter cold start, swap default in PeachApp
- **9.2: Rethink profile display and progress tracking** (placeholder) ‚Äî adapt visualization and statistics to reflect the single-skill model

Let me write the epic into the epics file and create the story.

### ü§ñ Assistant (00:17:53)

Now let me append Epic 9 to the epics file.

### ü§ñ Assistant (00:18:19)

Epic 9 added to the epics file. Now let me create the story file. Here's the header section:

### ü§ñ Assistant (00:19:16)

Now let me update the sprint status.

### ü§ñ Assistant (00:19:34)

Now let me validate against the checklist.

### ü§ñ Assistant (00:19:47)

Let me quickly verify a key assumption in the story - that `profile.overallMean` exists.

### ü§ñ Assistant (00:19:51)

Good, `overallMean` exists and returns `Double?`. Let me check its implementation to make sure the story's cold-start logic is correct.

### ü§ñ Assistant (00:19:56)

`overallMean` returns `nil` when no data exists. The story's cold-start logic aligns: use `overallMean` if available (non-nil), fall back to `maxCentDifference` otherwise. Let me update the story's AC #3 wording slightly to match the optional return type.

### ü§ñ Assistant (00:20:12)

Story creation complete. Here's a summary of everything that was created:

**Epic 9: Evidence-Based Training ‚Äî Note Selection Strategy** added to:
- `docs/planning-artifacts/epics.md` ‚Äî epic description + stories 9.1 and 9.2

**Story 9.1: Promote KazezNoteStrategy to Default Training Strategy** created at:
- `docs/implementation-artifacts/9-1-promote-kazeznotestrategy-to-default.md`

**Sprint status updated:**
- `docs/implementation-artifacts/sprint-status.yaml` ‚Äî epic-9 in-progress, 9-1 ready-for-dev, 9-2 backlog

**Story 9.1 scope:**
- 7 acceptance criteria, 7 tasks with subtasks
- Swap `AdaptiveNoteStrategy()` ‚Üí `KazezNoteStrategy()` in PeachApp (one-line change)
- Update KazezNoteStrategy to respect `settings.noteRangeMin/Max`
- Add cold-start-from-profile using `profile.overallMean`
- Remove "Natural vs. Mechanical" slider from Settings UI
- Update docs and comments ‚Äî remove "evaluation only" language
- AdaptiveNoteStrategy stays in the codebase untouched

**Story 9.2** is a placeholder for rethinking profile display after 9.1 is implemented.

### üßë Human (00:23:01)

ok. commit it.

### ü§ñ Assistant (00:23:11)

Four files to commit: the brainstorming session, the story file, the updated epics, and the sprint status.

### ü§ñ Assistant (00:23:23)

Committed as `aa1f2b8`. Working tree is clean. Four files committed:

- `docs/brainstorming/brainstorming-session-2026-02-24.md` ‚Äî brainstorming session with literature review
- `docs/planning-artifacts/epics.md` ‚Äî Epic 9 with stories 9.1 and 9.2
- `docs/implementation-artifacts/9-1-promote-kazeznotestrategy-to-default.md` ‚Äî detailed story
- `docs/implementation-artifacts/sprint-status.yaml` ‚Äî epic-9 in-progress, 9-1 ready-for-dev

### üßë Human (00:23:34)

<command-name>/exit</command-name>
            <command-message>exit</command-message>
            <command-args></command-args>

### üßë Human (00:23:34)

<local-command-stdout>Goodbye!</local-command-stdout>

---

[‚Üê Previous (855f825e36)](855f825e36.md) | [Index](index.md) | [Next (8434cba54a) ‚Üí](8434cba54a.md)
